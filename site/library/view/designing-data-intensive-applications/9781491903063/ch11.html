<!--[if IE]><![endif]--><!DOCTYPE html><!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/designing-data-intensive-applications/9781491903063/ch11.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="3905629"
  data-user-uuid="f04af719-1c84-4fc3-9be3-1f1b4622ab99"
  data-username="safaribooksonline122"
  data-account-type="Trial"
  
  data-activated-trial-date="12/09/2018"


  data-archive="9781491903063"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch11.html"
  data-epub-title="Designing Data-Intensive Applications" data-debug=0 data-testing=0><![endif]--><!--[if gt IE 8]><!--><html class="js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom gr__safaribooksonline_com" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/designing-data-intensive-applications/9781491903063/ch11.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="3905629" data-user-uuid="f04af719-1c84-4fc3-9be3-1f1b4622ab99" data-username="safaribooksonline122" data-account-type="Trial" data-activated-trial-date="12/09/2018" data-archive="9781491903063" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch11.html" data-epub-title="Designing Data-Intensive Applications" data-debug="0" data-testing="0" style=""><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491903063"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.0c29511d2d72.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900,200italic,300italic,400italic,600italic,700italic,900italic" rel="stylesheet" type="text/css"><title>11. Stream Processing - Designing Data-Intensive Applications</title><link rel="stylesheet" href="https://www.safaribooksonline.com/static/CACHE/css/5e586a47a3b7.css" type="text/css"><link rel="stylesheet" type="text/css" href="https://www.safaribooksonline.com/static/css/annotator.e3b0c44298fc.css"><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"><style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000 !important;padding-top:10px !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:1em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div.map-ebook{page-break-after:always}
    </style><link rel="canonical" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html"><meta name="description" content=" Chapter 11. Stream Processing A complex system that works is invariably found to have evolved from a simple system that works. The inverse proposition also appears to be true: A ... "><meta property="og:title" content="11. Stream Processing"><meta itemprop="isPartOf" content="/library/view/designing-data-intensive-applications/9781491903063/"><meta itemprop="name" content="11. Stream Processing"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/ch11.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491903063/"><meta property="og:description" itemprop="description" content=" Chapter 11. Stream Processing A complex system that works is invariably found to have evolved from a simple system that works. The inverse proposition also appears to be true: A ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781449373320"><meta property="og:book:author" itemprop="author" content="Martin Kleppmann"><meta property="og:book:tag" itemprop="about" content="Core Programming"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: <%= font_size %> !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: <%= font_family %> !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: <%= column_width %>% !important; margin: 0 auto !important; }"></style><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  
  



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#container" class="skip">Skip to content</a><header class="topbar t-topbar" style="display:None"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/playlists/" class="t-queue-nav l0 nav-icn None"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="21px" height="17px" viewBox="0 0 21 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch --><title>icon_Playlist_sml</title><desc>Created with Sketch.</desc><defs></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="icon_Playlist_sml" fill-rule="nonzero" fill="#000000"><g id="playlist-icon"><g id="Group-6"><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle></g><g id="Group-5" transform="translate(0.000000, 7.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g><g id="Group-5-Copy" transform="translate(0.000000, 14.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g></g></g></g></svg><span>
               Playlists
            </span></a></li><li class="search"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://get.oreilly.com/email-signup.html" target="_blank" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/f04af719-1c84-4fc3-9be3-1f1b4622ab99/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/preferences/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/preferences/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Designing Data-Intensive Applications
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><div class="js-content-uri" data-content-uri="/api/v1/book/9781491903063/chapter/ch11.html"><div class="js-collections-dropdown collections-dropdown menu-bit-cards"><div data-reactroot="" class="menu-dropdown-wrapper js-menu-dropdown-wrapper align-right"><img class="hidden" src="https://www.safaribooksonline.com/static/images/ajax-transp.gif" alt="loading spinner"><div class="menu-control"><div class="control "><div class="js-playlists-menu"><button class="js-playlist-icon"><svg class="icon-add-to-playlist-sml" viewBox="0 0 16 14" version="1.1" xmlns="http://www.w3.org/2000/svg"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill-rule="nonzero" fill="#000000"><g transform="translate(-1.000000, 0.000000)"><rect x="5" y="0" width="12" height="2"></rect><title>Playlists</title><path d="M4.5,14 C6.43299662,14 8,12.4329966 8,10.5 C8,8.56700338 6.43299662,7 4.5,7 C2.56700338,7 1,8.56700338 1,10.5 C1,12.4329966 2.56700338,14 4.5,14 Z M2.5,10 L4,10 L4,8.5 L5,8.5 L5,10 L6.5,10 L6.5,11 L5,11 L5,12.5 L4,12.5 L4,11 L2.5,11 L2.5,10 Z"></path><circle cx="2" cy="5" r="1"></circle><circle cx="1.94117647" cy="1" r="1"></circle><rect x="5" y="4" width="12" height="2"></rect><rect x="9" y="8" width="8" height="2"></rect><rect x="9" y="12" width="8" height="2"></rect></g></g></g></svg><div class="js-playlist-addto-label">Add&nbsp;To</div></button></div></div></div></div></div></div></li><li class="js-font-control-panel font-control-activator"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/ch11.html&amp;text=Designing%20Data-Intensive%20Applications&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/ch11.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/ch11.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%2011.%20Stream%20Processing&amp;body=https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/ch11.html%0D%0Afrom%20Designing%20Data-Intensive%20Applications%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
        
        



 <!--[if lt IE 9]>
  
<![endif]-->



  


        
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">10. Batch Processing</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch12.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">12. The Future of Data Systems</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content" style="transform: none;"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 11. Stream Processing"><div class="chapter" id="ch_stream">
<h1><span class="label">Chapter 11. </span>Stream Processing</h1>

<blockquote data-type="epigraph" epub:type="epigraph">
  <p><em>A complex system that works is invariably found to have evolved from a simple system that works.
The inverse proposition also appears to be true: A complex system designed from scratch never works
and cannot be made to work.</em></p>
  <p data-type="attribution">John Gall, <em>Systemantics</em> (1975)</p>
</blockquote>

<div class="map-ebook">
 <img id="c277" src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ch11-map-ebook.png" width="2756" height="2100" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ch11-map-ebook.png">
</div>

<p><a data-type="indexterm" data-primary="derived data" id="idm140417548178240"></a>
In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a> we discussed batch processing—techniques that read a set of files as input and
produce a new set of output files. The output is a form of <em>derived data</em>; that is, a dataset that
can be recreated by running the batch process again if necessary. We saw how this simple but
powerful idea can be used to create search indexes, recommendation systems, analytics, and more.</p>

<p><a data-type="indexterm" data-primary="bounded datasets" data-seealso="batch processing" id="idm140417548175520"></a>
However, one big assumption remained throughout <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a>: namely, that the input is bounded—i.e., of a
known and finite size—so the batch process knows when it has finished reading its input. For
example, the sorting operation that is central to MapReduce must read its entire input before it can
start producing output: it could happen that the very last input record is the one with the lowest
key, and thus needs to be the very first output record, so starting the output early is not an
option.</p>

<p><a data-type="indexterm" data-primary="unbounded datasets" data-seealso="streams" id="idm140417548172896"></a>
In reality, a lot of data is unbounded because it arrives gradually over time: your users produced
data yesterday and today, and they will continue to produce more data tomorrow. Unless you go out of
business, this process never ends, and so the dataset is never “complete” in any meaningful way
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Akidau2015gh-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2015gh" class="totri-footnote">1</a>].
Thus, batch processors must artificially divide the data into chunks of fixed duration: for example,
processing a day’s worth of data at the end of every day, or processing an hour’s worth of data at
the end of every hour.</p>

<p>The problem with daily batch processes is that changes in the input are only reflected in the output
a day later, which is too slow for many impatient users. To reduce the delay, we can run the
processing more frequently—say, processing a second’s worth of data at the end of every second—or
even continuously, abandoning the fixed time slices entirely and simply processing every event as it
happens. That is the idea behind <em>stream processing</em>.</p>

<p><a data-type="indexterm" data-primary="streams" id="ix_streams"></a>
<a data-type="indexterm" data-primary="event streams" data-see="streams" id="idm140417548165376"></a>
<a data-type="indexterm" data-primary="messaging systems" data-seealso="streams" id="ix_eventstrmess"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="messaging systems" data-see="messaging systems" id="idm140417548162896"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="messaging systems" data-see="messaging systems" id="idm140417548161520"></a>
In general, a “stream” refers to data that is incrementally made available over time. The concept
appears in many places: in the <code>stdin</code> and <code>stdout</code> of Unix, programming languages (lazy lists)
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Abelson1996ut-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Abelson1996ut" class="totri-footnote">2</a>],
filesystem APIs (such as Java’s <code>FileInputStream</code>), TCP connections, delivering audio and video over
the internet, and so on.</p>

<p>In this chapter we will look at <em>event streams</em> as a data management mechanism: the unbounded,
incrementally processed counterpart to the batch data we saw in the
<span class="keep-together">last chapter</span>. We will first discuss how streams are
represented, stored, and transmitted over a network. In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_databases">“Databases and Streams”</a> we will investigate
<span class="keep-together">the relationship</span> between streams and databases. And
finally, in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_processing">“Processing Streams”</a> we will explore approaches and tools for processing those
streams <span class="keep-together">continually</span>, and ways that they can be used to
build applications.</p>






<section data-type="sect1" data-pdf-bookmark="Transmitting Event Streams"><div class="sect1" id="sec_stream_transmit">
<h1>Transmitting Event Streams</h1>

<p>In the batch processing world, the inputs and outputs of a job are files (perhaps on a distributed
filesystem). What does the streaming equivalent look like?</p>

<p><a data-type="indexterm" data-primary="events" id="idm140417548149248"></a>
<a data-type="indexterm" data-primary="records" data-secondary="events in stream processing" id="idm140417548148416"></a>
When the input is a file (a sequence of bytes), the first processing step is usually to parse it
into a sequence of records. In a stream processing context, a record is more commonly known as an
<em>event</em>, but it is essentially the same thing: a small, self-contained, immutable object containing
the details of something that happened at some point in time. An event usually contains a timestamp
indicating when it happened according to a time-of-day clock (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch08.html#sec_distributed_monotonic_timeofday">“Monotonic Versus Time-of-Day Clocks”</a>).</p>

<p>For example, the thing that happened might be an action that a user took, such as viewing a page or
making a purchase. It might also originate from a machine, such as a periodic measurement from a
temperature sensor, or a CPU utilization metric. In the example of <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_unix">“Batch Processing with Unix Tools”</a>, each line of
the web server log is an event.</p>

<p>An event may be encoded as a text string, or JSON, or perhaps in some binary form, as discussed in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch04.html#ch_encoding">Chapter&nbsp;4</a>. This encoding allows you to store an event, for example by appending it to a file,
inserting it into a relational table, or writing it to a document database. It also allows you to
send the event over the network to another node in order to process it.</p>

<p><a data-type="indexterm" data-primary="producers (message streams)" id="idm140417548142080"></a>
<a data-type="indexterm" data-primary="publishers (message streams)" id="idm140417548140864"></a>
<a data-type="indexterm" data-primary="consumers (message streams)" id="idm140417548140048"></a>
<a data-type="indexterm" data-primary="subscribers (message streams)" data-seealso="consumers" id="idm140417548139200"></a>
<a data-type="indexterm" data-primary="topics (messaging)" id="idm140417548138080"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="topics" id="idm140417548137248"></a>
In batch processing, a file is written once and then potentially read by multiple jobs. Analogously,
in streaming terminology, an event is generated once by a <em>producer</em> (also known as a <em>publisher</em> or
<em>sender</em>), and then potentially processed by multiple <em>consumers</em> (<em>subscribers</em> or <em>recipients</em>)
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Eugster2003ih_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Eugster2003ih_ch11" class="totri-footnote">3</a>].
In a filesystem, a filename identifies a set of related records; in a streaming system, related
events are usually grouped together into a <em>topic</em> or <em>stream</em>.</p>

<p>In principle, a file or database is sufficient to connect producers and consumers: a producer writes
every event that it generates to the datastore, and each consumer periodically polls the datastore
to check for events that have appeared since it last ran. This is essentially what a batch process
does when it processes a day’s worth of data at the end of every day.</p>

<p>However, when moving toward continual processing with low delays, polling becomes expensive if the
datastore is not designed for this kind of usage. The more often you poll, the lower the percentage
of requests that return new events, and thus the higher the overheads become. Instead, it is better
for consumers to be notified when new events appear.</p>

<p><a data-type="indexterm" data-primary="triggers (databases)" id="idm140417548127824"></a>
Databases have traditionally not supported this kind of notification mechanism very well: relational
databases commonly have <em>triggers</em>, which can react to a change (e.g., a row being inserted into a
table), but they are very limited in what they can do and have been somewhat of an afterthought in
database design
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Hellerstein2005tj-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hellerstein2005tj" class="totri-footnote">4</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Carney2002um-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Carney2002um" class="totri-footnote">5</a>]. Instead, specialized tools have been developed for the purpose of
delivering event notifications.</p>








<section data-type="sect2" data-pdf-bookmark="Messaging Systems"><div class="sect2" id="sec_stream_messaging">
<h2>Messaging Systems</h2>

<p>A common approach for notifying consumers about new events is to use a <em>messaging system</em>: a
producer sends a message containing the event, which is then pushed to consumers. We touched on
these systems previously in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch04.html#sec_encoding_dataflow_msg">“Message-Passing Dataflow”</a>, but we will now go into more detail.</p>

<p>A direct communication channel like a Unix pipe or TCP connection between producer and consumer
would be a simple way of implementing a messaging system. However, most messaging systems expand on
this basic model. In particular, Unix pipes and TCP connect exactly one sender with one recipient,
whereas a messaging system allows multiple producer nodes to send messages to the same topic and
allows multiple consumer nodes to receive messages in a topic.</p>

<p><a data-type="indexterm" data-primary="publish/subscribe model" id="idm140417548116832"></a>
Within this <em>publish/subscribe</em> model, different systems take a wide range of approaches, and there
is no one right answer for all purposes. To differentiate the systems, it is particularly helpful to
ask the following two questions:</p>
<ol>
<li>
<p><a data-type="indexterm" data-primary="backpressure" id="idm140417548114432"></a><a data-type="indexterm" data-primary="flow control" id="idm140417548113504"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="backpressure, buffering, or dropping messages" id="idm140417548112704"></a>
<a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="backpressure" id="idm140417548111504"></a>
<a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="not keeping up with producers" id="idm140417548110384"></a>
<a data-type="indexterm" data-primary="TCP (Transmission Control Protocol)" data-secondary="flow control" id="idm140417548109248"></a>
<em>What happens if the producers send messages faster than the consumers can process them?</em>
Broadly speaking, there are three options: the system can drop messages, buffer messages in a queue,
or apply <em>backpressure</em> (also known as <em>flow control</em>; i.e., blocking the producer from sending more
messages). For example, Unix pipes and TCP use backpressure: they have a small fixed-size buffer,
and if it fills up, the sender is blocked until the recipient takes data out of the buffer (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch08.html#sec_distributed_congestion">“Network congestion and queueing”</a>).</p>

<p>If messages are buffered in a queue, it is important to understand what happens as that queue grows.
Does the system crash if the queue no longer fits in memory, or does it write messages to disk? If
so, how does the disk access affect the performance of the messaging system
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Sackman2016ws-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Sackman2016ws" class="totri-footnote">6</a>]?</p>
</li>
<li>
<p><a data-type="indexterm" data-primary="messages" data-secondary="loss of" id="idm140417548101856"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="reliability" id="idm140417548100752"></a>
<a data-type="indexterm" data-primary="reliability" data-secondary="of messaging systems" id="idm140417548099648"></a>
<em>What happens if nodes crash or temporarily go offline—are any messages lost?</em> As with databases,
durability may require some combination of writing to disk and/or replication (see the sidebar
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch07.html#sidebar_transactions_durability">“Replication and Durability”</a>), which has a cost. If you can afford to sometimes lose
messages, you can probably get higher throughput and lower latency on the same hardware.</p>
</li>

</ol>

<p>Whether message loss is acceptable depends very much on the application. For example, with sensor
readings and metrics that are transmitted periodically, an occasional missing data point is perhaps
not important, since an updated value will be sent a short time later anyway. However, beware that
if a large number of messages are dropped, it may not be immediately apparent that the metrics are
incorrect [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Marti2015ww-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Marti2015ww" class="totri-footnote">7</a>]. If you are counting
events, it is more important that they are delivered reliably, since every lost message means
incorrect counters.</p>

<p><a data-type="indexterm" data-primary="batch processing" data-secondary="fault tolerance" id="idm140417548093456"></a>
A nice property of the batch processing systems we explored in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a> is that they provide a
strong reliability guarantee: failed tasks are automatically retried, and partial output from failed
tasks is automatically discarded. This means the output is the same as if no failures had occurred,
which helps simplify the programming model. Later in this chapter we will examine how we can provide
similar guarantees in a streaming context.</p>










<section data-type="sect3" data-pdf-bookmark="Direct messaging from producers to consumers"><div class="sect3" id="idm140417548091168">
<h3>Direct messaging from producers to consumers</h3>

<p><a data-type="indexterm" data-primary="messaging systems" data-secondary="brokerless messaging" id="idm140417548089776"></a>
A number of messaging systems use direct network communication between producers and consumers
without going via intermediary nodes:</p>

<ul>
<li>
<p><a data-type="indexterm" data-primary="UDP (User Datagram Protocol)" data-secondary="multicast" id="idm140417548087536"></a>
<a data-type="indexterm" data-primary="stock market feeds" id="idm140417548086368"></a>
<a data-type="indexterm" data-primary="packets" data-secondary="sending via UDP" id="idm140417548085536"></a>
UDP multicast is widely used in the financial industry for streams such as stock market feeds,
where low latency is important [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Lowenberger2009ac-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Lowenberger2009ac" class="totri-footnote">8</a>]. Although UDP itself is
unreliable, application-level protocols can recover lost packets (the producer must remember
packets it has sent so that it can retransmit them on demand).</p>
</li>
<li>
<p><a data-type="indexterm" data-primary="brokerless messaging" id="idm140417548080912"></a>
<a data-type="indexterm" data-primary="ZeroMQ (messaging library)" id="idm140417548080192"></a>
<a data-type="indexterm" data-primary="nanomsg (messaging library)" id="idm140417548079296"></a>
Brokerless messaging libraries such as ZeroMQ
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Hintjens2013wf-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hintjens2013wf" class="totri-footnote">9</a>] and nanomsg take a similar
approach, implementing publish/subscribe messaging over TCP or IP multicast.</p>
</li>
<li>
<p><a data-type="indexterm" data-primary="StatsD (metrics aggregator)" id="idm140417548075600"></a>
<a data-type="indexterm" data-primary="Brubeck (metrics aggregator)" id="idm140417548074576"></a>
StatsD [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Malpass2011wb-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Malpass2011wb">10</a>] and Brubeck
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Marti2015ww" class="totri-footnote">7</a>] use unreliable UDP messaging for
collecting metrics from all machines on the network and monitoring them. (In the StatsD protocol,
counter metrics are only correct if all messages are received; using UDP makes the metrics at best
approximate [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Plaetinck2016ta-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Plaetinck2016ta">11</a>]. See also
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch08.html#sidebar_distributed_tcp_udp">“TCP Versus UDP”</a>.)</p>
</li>
<li>
<p><a data-type="indexterm" data-primary="webhooks" id="idm140417548066768"></a> If the consumer exposes a service on the network, producers can make a direct
HTTP or RPC request (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch04.html#sec_encoding_dataflow_rpc">“Dataflow Through Services: REST and RPC”</a>) to push messages to the consumer. This is
the idea behind webhooks [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Lindsay2007tl-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Lindsay2007tl">12</a>], a pattern in which a
callback URL of one service is registered with another service, and it makes a request to that URL
whenever an event occurs.</p>
</li>
</ul>

<p>Although these direct messaging systems work well in the situations for which they are designed,
they generally require the application code to be aware of the possibility of message loss. The
faults they can tolerate are quite limited: even if the protocols detect and retransmit packets that
are lost in the network, they generally assume that producers and consumers are constantly online.</p>

<p>If a consumer is offline, it may miss messages that were sent while it is unreachable. Some
protocols allow the producer to retry failed message deliveries, but this approach may break down if
the producer crashes, losing the buffer of messages that it was supposed to retry.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Message brokers"><div class="sect3" id="idm140417548060768">
<h3>Message brokers</h3>

<p><a data-type="indexterm" data-primary="messaging systems" data-secondary="message brokers" id="ix_messagebrokers"></a>
<a data-type="indexterm" data-primary="message brokers" data-see="messaging systems" id="idm140417548058192"></a>
A widely used alternative is to send messages via a <em>message broker</em> (also known as a <em>message
queue</em>), which is essentially a kind of database that is optimized for handling message streams
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Gray1995tn-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gray1995tn">13</a>]. It runs as a server,
with producers and consumers connecting to it as clients. Producers write messages to the broker,
and consumers receive them by reading them from the broker.</p>

<p>By centralizing the data in the broker, these systems can more easily tolerate clients that come and
go (connect, disconnect, and crash), and the question of durability is moved to the broker instead.
Some message brokers only keep messages in memory, while others (depending on configuration) write
them to disk so that they are not lost in case of a broker crash. Faced with slow consumers, they
generally allow unbounded queueing (as opposed to dropping messages or backpressure), although this choice
may also depend on the configuration.</p>

<p>A consequence of queueing is also that consumers are generally <em>asynchronous</em>: when a producer sends
a message, it normally only waits for the broker to confirm that it has buffered the message and
does not wait for the message to be processed by consumers. The delivery to consumers will happen at
some undetermined future point in time—often within a fraction of a second, but sometimes
significantly later if there is a queue backlog.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Message brokers compared to databases"><div class="sect3" id="idm140417548051536">
<h3>Message brokers compared to databases</h3>

<p><a data-type="indexterm" data-primary="databases" data-secondary="comparison of message brokers to" id="idm140417548050368"></a>
Some message brokers can even participate in two-phase commit protocols using XA or JTA (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_dist_trans">“Distributed Transactions in Practice”</a>). This feature makes them quite similar in nature to databases, although
there are still important practical differences between message brokers and databases:</p>

<ul>
<li>
<p>Databases usually keep data until it is explicitly deleted, whereas most message brokers
automatically delete a message when it has been successfully delivered to its consumers. Such
message brokers are not suitable for long-term data storage.</p>
</li>
<li>
<p>Since they quickly delete messages, most message brokers assume that their working set is fairly
small—i.e., the queues are short. If the broker needs to buffer a lot of messages because the
consumers are slow (perhaps spilling messages to disk if they no longer fit in memory), each
individual message takes longer to process, and the overall throughput may degrade
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Sackman2016ws" class="totri-footnote">6</a>].</p>
</li>
<li>
<p>Databases often support secondary indexes and various ways of searching for data, while message
brokers often support some way of subscribing to a subset of topics matching some pattern. The
mechanisms are different, but both are essentially ways for a client to select the portion of the
data that it wants to know about.</p>
</li>
<li>
<p>When querying a database, the result is typically based on a point-in-time snapshot of the data;
if another client subsequently writes something to the database that changes the query result, the
first client does not find out that its prior result is now outdated (unless it repeats the query,
or polls for changes). By contrast, message brokers do not support arbitrary queries, but they do
notify clients when data changes (i.e., when new messages become available).</p>
</li>
</ul>

<p><a data-type="indexterm" data-primary="Java Message Service (JMS)" data-seealso="messaging systems" id="idm140417548041648"></a>
<a data-type="indexterm" data-primary="AMQP (Advanced Message Queuing Protocol)" data-seealso="messaging systems" id="idm140417548040192"></a>
<a data-type="indexterm" data-primary="Advanced Message Queuing Protocol" data-see="AMQP" id="idm140417548039056"></a>
<a data-type="indexterm" data-primary="RabbitMQ (messaging)" id="idm140417548037936"></a>
<a data-type="indexterm" data-primary="ActiveMQ (messaging)" id="idm140417548037104"></a>
<a data-type="indexterm" data-primary="HornetQ (messaging)" id="idm140417548036272"></a>
<a data-type="indexterm" data-primary="Qpid (messaging)" id="idm140417548035440"></a><a data-type="indexterm" data-primary="Apache Qpid" data-see="Qpid" id="idm140417548034736"></a>
<a data-type="indexterm" data-primary="TIBCO" data-secondary="Enterprise Message Service" id="idm140417548033664"></a>
<a data-type="indexterm" data-primary="IBM" data-secondary="MQ (messaging)" id="idm140417548032544"></a>
<a data-type="indexterm" data-primary="Microsoft" data-secondary="Azure Service Bus (messaging)" id="idm140417548031440"></a>
<a data-type="indexterm" data-primary="Google" data-secondary="Cloud Pub/Sub (messaging)" id="idm140417548030320"></a>
This is the traditional view of message brokers, which is encapsulated in standards like JMS
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Hapner2013uk-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hapner2013uk">14</a>] and AMQP
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Aiyagari2008th-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Aiyagari2008th">15</a>] and implemented in software
like RabbitMQ, ActiveMQ, HornetQ, Qpid, TIBCO Enterprise Message Service, IBM MQ, Azure Service
Bus, and Google Cloud Pub/Sub
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="GooglePubSub-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#GooglePubSub">16</a>].</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Multiple consumers"><div class="sect3" id="idm140417548022816">
<h3>Multiple consumers</h3>

<p><a data-type="indexterm" data-primary="messaging systems" data-secondary="message brokers" data-tertiary="multiple consumers of same topic" id="idm140417548021440"></a>
When multiple consumers read messages in the same topic, two main patterns of messaging are
used, as illustrated in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_multi_consumer">Figure&nbsp;11-1</a>:</p>
<dl>
<dt>Load balancing</dt>
<dd>
<p><a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="load balancing" id="idm140417548017728"></a>
<a data-type="indexterm" data-primary="load balancing (messaging)" id="idm140417548016608"></a>
Each message is delivered to <em>one</em> of the consumers, so the consumers can share the work of
processing the messages in the topic. The broker may assign messages to consumers arbitrarily.
This pattern is useful when the messages are expensive to process, and so you want to be able to
add consumers to parallelize the processing. (In AMQP, you can implement load balancing by having
multiple clients consuming from the same queue, and in JMS it is called a <em>shared</em> <span class="keep-together"><em>subscription</em></span>.)</p>
</dd>
<dt>Fan-out</dt>
<dd>
<p><a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="fan-out" id="idm140417548012464"></a>
<a data-type="indexterm" data-primary="fan-out (messaging systems)" id="idm140417548011296"></a>
Each message is delivered to <em>all</em> of the consumers. Fan-out allows several independent consumers
to each “tune in” to the same broadcast of messages, without affecting each other—the streaming
equivalent of having several different batch jobs that read the same input file. (This feature is
provided by topic subscriptions in JMS, and exchange bindings in AMQP.)</p>
</dd>
</dl>

<figure><div id="fig_stream_multi_consumer" class="figure">
<img src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1101.png" alt="ddia 1101" width="2880" height="1379" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1101.png">
<h6><span class="label">Figure 11-1. </span>(a) Load balancing: sharing the work of consuming a topic among consumers; (b) fan-out: delivering each message to multiple consumers.</h6>
</div></figure>

<p>The two patterns can be combined: for example, two separate groups of consumers may each subscribe
to a topic, such that each group collectively receives all messages, but within each group only one
of the nodes receives each message.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Acknowledgments and redelivery"><div class="sect3" id="sec_stream_reordering">
<h3>Acknowledgments and redelivery</h3>

<p><a data-type="indexterm" data-primary="acknowledgements (messaging)" id="idm140417548004864"></a>
<a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="failures" id="idm140417548004016"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="message brokers" data-tertiary="acknowledgements and redelivery" id="idm140417548002896"></a>
Consumers may crash at any time, so it could happen that a broker delivers a message to a consumer
but the consumer never processes it, or only partially processes it before crashing. In order to
ensure that the message is not lost, message brokers use <em>acknowledgments</em>: a client must
explicitly tell the broker when it has finished processing a message so that the broker can remove
it from the queue.</p>

<p><a data-type="indexterm" data-primary="redelivery (messaging)" id="idm140417548000416"></a>
If the connection to a client is closed or times out without the broker receiving an acknowledgment,
it assumes that the message was not processed, and therefore it delivers the message again to
another consumer. (Note that it could happen that the message actually <em>was</em> fully processed, but
the acknowledgment was lost in the network. Handling this case requires an atomic commit protocol,
as discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_dist_trans">“Distributed Transactions in Practice”</a>.)</p>

<p>When combined with load balancing, this redelivery behavior has an interesting effect on the
ordering of messages. In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_redelivery">Figure&nbsp;11-2</a>, the consumers generally process messages in the
order they were sent by producers. However, consumer 2 crashes while processing message <em>m3</em>, at the
same time as consumer 1 is processing message <em>m4</em>. The unacknowledged message <em>m3</em> is subsequently
redelivered to consumer 1, with the result that consumer 1 processes messages in the order <em>m4</em>, <em>m3</em>,
<em>m5</em>. Thus, <em>m3</em> and <em>m4</em> are not delivered in the same order as they were sent by producer 1.</p>

<figure><div id="fig_stream_redelivery" class="figure">
<img src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1102.png" alt="ddia 1102" width="2880" height="1457" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1102.png">
<h6><span class="label">Figure 11-2. </span>Consumer 2 crashes while processing m3, so it is redelivered to consumer 1 at a later time.</h6>
</div></figure>

<p><a data-type="indexterm" data-primary="AMQP (Advanced Message Queuing Protocol)" data-secondary="message ordering" id="idm140417547990208"></a>
<a data-type="indexterm" data-primary="Java Message Service (JMS)" data-secondary="message ordering" id="idm140417547989008"></a>
Even if the message broker otherwise tries to preserve the order of messages (as required by both
the JMS and AMQP standards), the combination of load balancing with redelivery inevitably leads to
messages being reordered. To avoid this issue, you can use a separate queue per consumer (i.e., not
use the load balancing feature). Message reordering is not a problem if messages are completely
independent of each other, but it can be important if there are causal dependencies between
messages, as we shall see later in the chapter.
<a data-type="indexterm" data-primary="messaging systems" data-secondary="message brokers" data-startref="ix_messagebrokers" id="idm140417547987392"></a></p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Partitioned Logs"><div class="sect2" id="sec_stream_log">
<h2>Partitioned Logs</h2>

<p><a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" id="ix_logpartmess"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="event logs" id="ix_eventstrlog"></a>
Sending a packet over a network or making a request to a network service is normally a transient
operation that leaves no permanent trace. Although it is possible to record it permanently (using
packet capture and logging), we normally don’t think of it that way. Even message brokers that
durably write messages to disk quickly delete them again after they have been delivered to
consumers, because they are built around a transient messaging mindset.</p>

<p>Databases and filesystems take the opposite approach: everything that is written to a database or
file is normally expected to be permanently recorded, at least until someone explicitly chooses to
delete it again.</p>

<p>This difference in mindset has a big impact on how derived data is created. A key feature of batch
processes, as discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a>, is that you can run them repeatedly, experimenting with the
processing steps, without risk of damaging the input (since the input is read-only). This is not the
case with AMQP/JMS-style messaging: receiving a message is destructive if the acknowledgment causes
it to be deleted from the broker, so you cannot run the same consumer again and expect to get the
same result.</p>

<p>If you add a new consumer to a messaging system, it typically only starts receiving messages sent
after the time it was registered; any prior messages are already gone and cannot be recovered.
Contrast this with files and databases, where you can add a new client at any time, and it can read
data written arbitrarily far in the past (as long as it has not been explicitly overwritten or
deleted by the application).</p>

<p>Why can we not have a hybrid, combining the durable storage approach of databases with the
low-latency notification facilities of messaging? This is the idea behind <em>log-based message
brokers</em>.</p>










<section data-type="sect3" data-pdf-bookmark="Using logs for message storage"><div class="sect3" id="idm140417547976912">
<h3>Using logs for message storage</h3>

<p><a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-tertiary="using logs for message storage" id="idm140417547975568"></a>
A log is simply an append-only sequence of records on disk. We previously discussed logs in the
context of log-structured storage engines and write-ahead logs in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#ch_storage">Chapter&nbsp;3</a>, and in the context
of replication in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#ch_replication">Chapter&nbsp;5</a>.</p>

<p><a data-type="indexterm" data-primary="tail (Unix tool)" id="idm140417547972064"></a>
The same structure can be used to implement a message broker: a producer sends a message by
appending it to the end of the log, and a consumer receives messages by reading the log
sequentially. If a consumer reaches the end of the log, it waits for a notification that a new
message has been appended. The Unix tool <code>tail -f</code>, which watches a file for data being appended,
essentially works like this.</p>

<p>In order to scale to higher throughput than a single disk can offer, the log can be <em>partitioned</em>
(in the sense of <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch06.html#ch_partitioning">Chapter&nbsp;6</a>). Different partitions can then be hosted on different
machines, making each partition a separate log that can be read and written independently from other
partitions. A topic can then be defined as a group of partitions that all carry messages of the same
type. This approach is illustrated in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_kafka_partitions">Figure&nbsp;11-3</a>.</p>

<p><a data-type="indexterm" data-primary="offsets" data-secondary="messages in partitioned logs" id="idm140417547967344"></a>
<a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="message offsets" id="idm140417547966224"></a>
Within each partition, the broker assigns a monotonically increasing sequence number, or <em>offset</em>,
to every message (in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_kafka_partitions">Figure&nbsp;11-3</a>, the numbers in boxes are message offsets).
Such a sequence number makes sense because a partition is append-only, so the messages within a
partition are totally ordered. There is no ordering guarantee across different partitions.</p>

<figure><div id="fig_stream_kafka_partitions" class="figure">
<img src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1103.png" alt="ddia 1103" width="2880" height="1528" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1103.png">
<h6><span class="label">Figure 11-3. </span>Producers send messages by appending them to a topic-partition file, and consumers read these files sequentially.</h6>
</div></figure>

<p><a data-type="indexterm" data-primary="Kafka (messaging)" id="idm140417547961136"></a>
<a data-type="indexterm" data-primary="Amazon Web Services (AWS)" data-secondary="Kinesis Streams (messaging)" id="idm140417547959968"></a>
<a data-type="indexterm" data-primary="Twitter" data-secondary="DistributedLog (event log)" id="idm140417547958832"></a>
<a data-type="indexterm" data-primary="Google" data-secondary="Cloud Pub/Sub (messaging)" id="idm140417547957712"></a>
Apache Kafka
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kafka2015-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kafka2015">17</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kreps2011wl-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2011wl">18</a>], Amazon Kinesis Streams
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kinesis2016-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kinesis2016">19</a>], and Twitter’s
DistributedLog [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Stewart2015vb-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Stewart2015vb">20</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="DistributedLog-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#DistributedLog">21</a>] are log-based message
brokers that work like this. Google Cloud Pub/Sub is architecturally similar but exposes a
JMS-style API rather than a log abstraction [<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#GooglePubSub">16</a>].
Even though these message brokers write all messages to disk, they are able to achieve throughput of
millions of messages per second by partitioning across multiple machines, and fault tolerance by
replicating messages [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kreps2014wz-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014wz">22</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Paramasivam2015um-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Paramasivam2015um">23</a>].</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Logs compared to traditional messaging"><div class="sect3" id="sec_stream_logs_vs_messaging">
<h3>Logs compared to traditional messaging</h3>

<p><a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="fan-out" id="idm140417547938336"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="event logs" data-tertiary="comparison to traditional messaging" id="idm140417547936992"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="message brokers" data-tertiary="comparison to event logs" id="idm140417547935600"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-tertiary="comparison to traditional messaging" id="idm140417547934208"></a>
<a data-type="indexterm" data-primary="AMQP (Advanced Message Queuing Protocol)" data-secondary="comparison to log-based messaging" id="idm140417547932816"></a>
<a data-type="indexterm" data-primary="Java Message Service (JMS)" data-secondary="comparison to log-based messaging" id="idm140417547931600"></a>
The log-based approach trivially supports fan-out messaging, because several consumers can
independently read the log without affecting each other—reading a message does not delete it from
the log. To achieve load balancing across a group of consumers, instead of assigning individual
messages to consumer clients, the broker can assign entire partitions to nodes in the consumer
group.</p>

<p><a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="load balancing" id="idm140417547929936"></a>
<a data-type="indexterm" data-primary="single-threaded execution" data-secondary="in stream processing" id="idm140417547928864"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="single-threaded execution" id="idm140417547927744"></a>
Each client then consumes <em>all</em> the messages in the partitions it has been assigned. Typically, when
a consumer has been assigned a log partition, it reads the messages in the partition sequentially,
in a straightforward single-threaded manner. This coarse-grained load balancing approach has some
downsides:</p>

<ul>
<li>
<p>The number of nodes sharing the work of consuming a topic can be at most the number of log
partitions in that topic, because messages within the same partition are delivered to the same
node.<sup xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook"><a data-type="noteref" id="idm140417547924592-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#idm140417547924592" class="totri-footnote">i</a></sup></p>
</li>
<li>
<p>If a single message is slow to process, it holds up the processing of subsequent messages in that
partition (a form of head-of-line blocking; see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch01.html#sec_introduction_percentiles">“Describing Performance”</a>).</p>
</li>
</ul>

<p>Thus, in situations where messages may be expensive to process and you want to parallelize
processing on a message-by-message basis, and where message ordering is not so important, the
JMS/AMQP style of message broker is preferable. On the other hand, in situations with high message
throughput, where each message is fast to process and where message ordering is important, the
log-based approach works very well.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Consumer offsets"><div class="sect3" id="sec_stream_log_offsets">
<h3>Consumer offsets</h3>

<p><a data-type="indexterm" data-primary="messaging systems" data-secondary="event logs" data-tertiary="consumer offsets" id="idm140417547918336"></a>
<a data-type="indexterm" data-primary="offsets" data-secondary="consumer offsets in partitioned logs" id="idm140417547916960"></a>
<a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="consumer offsets in logs" id="idm140417547915888"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-tertiary="consumer offsets" id="idm140417547914752"></a>
Consuming a partition sequentially makes it easy to tell which messages have been processed: all
messages with an offset less than a consumer’s current offset have already been processed, and all
messages with a greater offset have not yet been seen. Thus, the broker does not need to track
acknowledgments for every single message—it only needs to periodically record the consumer
offsets. The reduced bookkeeping overhead and the opportunities for batching and pipelining in this
approach help increase the throughput of log-based systems.</p>

<p><a data-type="indexterm" data-primary="log sequence number" id="idm140417547912560"></a>
<a data-type="indexterm" data-primary="leader-based replication" data-secondary="log sequence number" id="idm140417547911728"></a>
This offset is in fact very similar to the <em>log sequence number</em> that is commonly found in
single-leader database replication, and which we discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_new_replica">“Setting Up New Followers”</a>. In
database replication, the log sequence number allows a follower to reconnect to a leader after it
has become disconnected, and resume replication without skipping any writes. Exactly the same
principle is used here: the message broker behaves like a leader database, and the consumer like a
follower.</p>

<p><a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="failures" id="idm140417547908688"></a>
If a consumer node fails, another node in the consumer group is assigned the failed consumer’s
partitions, and it starts consuming messages at the last recorded offset. If the consumer had
processed subsequent messages but not yet recorded their offset, those messages will be processed a
second time upon restart. We will discuss ways of dealing with this issue later in the chapter.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Disk space usage"><div class="sect3" id="sec_stream_disk_usage">
<h3>Disk space usage</h3>

<p><a data-type="indexterm" data-primary="consumers (message streams)" data-secondary="not keeping up with producers" id="idm140417547905456"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-tertiary="disk space usage" id="idm140417547904320"></a>
If you only ever append to the log, you will eventually run out of disk space. To reclaim disk
space, the log is actually divided into segments, and from time to time old segments are deleted or
moved to archive storage. (We’ll discuss a more sophisticated way of freeing disk space later.)</p>

<p><a data-type="indexterm" data-primary="circular buffers" id="idm140417547902384"></a><a data-type="indexterm" data-primary="ring buffers" id="idm140417547901680"></a>
This means that if a slow consumer cannot keep up with the rate of messages, and it falls so far
behind that its consumer offset points to a deleted segment, it will miss some of the messages.
Effectively, the log implements a bounded-size buffer that discards old messages when it gets full,
also known as a <em>circular buffer</em> or <em>ring buffer</em>. However, since that buffer is on disk, it can be
quite large.</p>

<p><a data-type="indexterm" data-primary="hard disks" data-secondary="sequential write throughput" id="idm140417547899360"></a>
Let’s do a back-of-the-envelope calculation. At the time of writing, a typical large hard drive has
a capacity of 6&nbsp;TB and a sequential write throughput of 150&nbsp;MB/s. If you are writing
messages at the fastest possible rate, it takes about 11 hours to fill the drive. Thus, the disk can
buffer 11 hours’ worth of messages, after which it will start overwriting old messages. This ratio
remains the same, even if you use many hard drives and machines. In practice, deployments rarely use
the full write bandwidth of the disk, so the log can typically keep a buffer of several days’ or even
weeks’ worth of messages.</p>

<p>Regardless of how long you retain messages, the throughput of a log remains more or less constant,
since every message is written to disk anyway [<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2011wl">18</a>].
This behavior is in contrast to messaging systems that keep messages in memory by default and only
write them to disk if the queue grows too large: such systems are fast when queues are short and
become much slower when they start writing to disk, so the throughput depends on the amount of
history retained.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="When consumers cannot keep up with producers"><div class="sect3" id="idm140417547895776">
<h3>When consumers cannot keep up with producers</h3>

<p><a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-tertiary="slow consumers" id="idm140417547894432"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="event logs" data-tertiary="slow consumers" id="idm140417547893056"></a>
At the beginning of <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_messaging">“Messaging Systems”</a> we discussed three choices of what to do if a consumer
cannot keep up with the rate at which producers are sending messages: dropping messages, buffering,
or applying backpressure. In this taxonomy, the log-based approach is a form of buffering with a
large but fixed-size buffer (limited by the available disk space).</p>

<p>If a consumer falls so far behind that the messages it requires are older than what is retained on
disk, it will not be able to read those messages—so the broker effectively drops old messages that
go back further than the size of the buffer can accommodate. You can monitor how far a consumer is
behind the head of the log, and raise an alert if it falls behind significantly. As the buffer is
large, there is enough time for a human operator to fix the slow consumer and allow it to catch up
before it starts missing messages.</p>

<p>Even if a consumer does fall too far behind and starts missing messages, only that consumer is
affected; it does not disrupt the service for other consumers. This fact is a big operational
advantage: you can experimentally consume a production log for development, testing, or debugging
purposes, without having to worry much about disrupting production services. When a consumer is shut
down or crashes, it stops consuming resources—the only thing that remains is its consumer offset.</p>

<p>This behavior also contrasts with traditional message brokers, where you need to be careful to delete
any queues whose consumers have been shut down—otherwise they continue unnecessarily accumulating
messages and taking away memory from consumers that are still active.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Replaying old messages"><div class="sect3" id="sec_stream_replay">
<h3>Replaying old messages</h3>

<p><a data-type="indexterm" data-primary="reprocessing data" data-secondary="from log-based messaging" id="idm140417547886192"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-tertiary="replaying old messages" id="idm140417547884896"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="event logs" data-tertiary="replaying old messages" id="idm140417547883520"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="event logs" data-tertiary="comparison to traditional messaging" id="idm140417547882144"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="message brokers" data-tertiary="comparison to event logs" id="idm140417547880800"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-tertiary="comparison to traditional messaging" id="idm140417547879408"></a>
<a data-type="indexterm" data-primary="AMQP (Advanced Message Queuing Protocol)" data-secondary="comparison to log-based messaging" id="idm140417547878016"></a>
<a data-type="indexterm" data-primary="Java Message Service (JMS)" data-secondary="comparison to log-based messaging" id="idm140417547876800"></a>
We noted previously that with AMQP- and JMS-style message brokers, processing and acknowledging
messages is a destructive operation, since it causes the messages to be deleted on the broker. On
the other hand, in a log-based message broker, consuming messages is more like reading from a file:
it is a read-only operation that does not change the log.</p>

<p>The only side effect of processing, besides any output of the consumer, is that the consumer offset
moves forward. But the offset is under the consumer’s control, so it can easily be manipulated if
necessary: for example, you can start a copy of a consumer with yesterday’s offsets and write the
output to a different location, in order to reprocess the last day’s worth of messages. You can
repeat this any number of times, varying the processing code.</p>

<p><a data-type="indexterm" data-primary="batch processing" data-secondary="log-based messaging and" id="idm140417547874304"></a>
This aspect makes log-based messaging more like the batch processes of the last chapter, where
derived data is clearly separated from input data through a repeatable transformation process. It
allows more experimentation and easier recovery from errors and bugs, making it a good tool for
integrating dataflows within an organization [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kreps2013vs_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2013vs_ch11">24</a>].
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="log-based messaging" data-startref="ix_logpartmess" id="idm140417547870288"></a>
<a data-type="indexterm" data-primary="streams" data-startref="ix_streams" id="idm140417547868912"></a>
<a data-type="indexterm" data-primary="messaging systems" data-secondary="event logs" data-startref="ix_eventstrlog" id="idm140417547867808"></a>
<a data-type="indexterm" data-primary="messaging systems" data-startref="ix_eventstrmess" id="idm140417547866432"></a></p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Databases and Streams"><div class="sect1" id="sec_stream_databases">
<h1>Databases and Streams</h1>

<p><a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-seealso="changelogs" id="ix_dbstream"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-seealso="changelogs" id="ix_strmprdb"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="relation to databases" data-see="streams" id="idm140417547860816"></a>
We have drawn some comparisons between message brokers and databases. Even though they have
traditionally been considered separate categories of tools, we saw that log-based message
brokers have been successful in taking ideas from databases and applying them to messaging. We can
also go in reverse: take ideas from messaging and streams, and apply them to databases.</p>

<p>We said previously that an event is a record of something that happened at some point in time. The
thing that happened may be a user action (e.g., typing a search query), or a sensor reading, but it
may also be a <em>write to a database</em>. The fact that something was written to a database is an event
that can be captured, stored, and processed. This observation suggests that the connection between
databases and streams runs deeper than just the physical storage of logs on disk—it is quite
fundamental.</p>

<p><a data-type="indexterm" data-primary="changelogs" data-secondary="maintaining derived state" id="idm140417547857456"></a>
<a data-type="indexterm" data-primary="derived data" data-secondary="maintaining derived state through logs" id="ix_derivedstatelogs"></a>
In fact, a replication log (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_implementation">“Implementation of Replication Logs”</a>) is a stream of database write
events, produced by the leader as it processes transactions. The followers apply that stream of
writes to their own copy of the database and thus end up with an accurate copy of the same data.
The events in the replication log describe the data changes that occurred.</p>

<p><a data-type="indexterm" data-primary="state machine replication" id="idm140417547853600"></a>
<a data-type="indexterm" data-primary="replication" data-secondary="state machine replication" id="idm140417547852752"></a>
<a data-type="indexterm" data-primary="deterministic operations" data-secondary="in state machine replication" id="idm140417547851632"></a>
We also came across the <em>state machine replication</em> principle in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_total_order">“Total Order Broadcast”</a>,
which states: if every event represents a write to the database, and every replica processes the
same events in the same order, then the replicas will all end up in the same final state.
(Processing an event is assumed to be a deterministic operation.) It’s just another case of event
streams!</p>

<p>In this section we will first look at a problem that arises in heterogeneous data systems, and then
explore how we can solve it by bringing ideas from event streams to databases.</p>








<section data-type="sect2" data-pdf-bookmark="Keeping Systems in Sync"><div class="sect2" id="sec_stream_sync">
<h2>Keeping Systems in Sync</h2>

<p><a data-type="indexterm" data-primary="data systems" data-secondary="heterogeneous, keeping in sync" id="idm140417547846336"></a>
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="keeping systems in sync" id="ix_dbstrkeepsync"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="keeping systems in sync" id="ix_strdbkeepsync"></a>
As we have seen throughout this book, there is no single system that can satisfy all data storage,
querying, and processing needs. In practice, most nontrivial applications need to combine
several different technologies in order to satisfy their requirements: for example, using an OLTP
database to serve user requests, a cache to speed up common requests, a full-text index to handle
search queries, and a data warehouse for analytics. Each of these has its own copy of the data,
stored in its own representation that is optimized for its own purposes.</p>

<p><a data-type="indexterm" data-primary="indexes" data-secondary="updating when data changes" id="idm140417547841072"></a>
<a data-type="indexterm" data-primary="caches" data-secondary="invalidation and maintenance" id="idm140417547839776"></a>
<a data-type="indexterm" data-primary="data warehousing" data-secondary="keeping data systems in sync" id="idm140417547838656"></a>
<a data-type="indexterm" data-primary="data warehousing" data-secondary="ETL (extract-transform-load)" id="idm140417547837536"></a>
<a data-type="indexterm" data-primary="ETL (extract-transform-load)" id="idm140417547836416"></a>
As the same or related data appears in several different places, they need to be kept in sync with
one another: if an item is updated in the database, it also needs to be updated in the cache, search
indexes, and data warehouse. With data warehouses this synchronization is usually performed by ETL
processes (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#sec_storage_dwh">“Data Warehousing”</a>), often by taking a full copy of a database, transforming it, and
bulk-loading it into the data warehouse—in other words, a batch process. Similarly, we saw in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_output">“The Output of Batch Workflows”</a> how search indexes, recommendation systems, and other derived data systems
might be created using batch processes.</p>

<p><a data-type="indexterm" data-primary="dual writes, problems with" id="idm140417547833200"></a>
If periodic full database dumps are too slow, an alternative that is sometimes used is <em>dual
writes</em>, in which the application code explicitly writes to each of the systems when data changes:
for example, first writing to the database, then updating the search index, then invalidating the
cache entries (or even performing those writes concurrently).</p>

<p><a data-type="indexterm" data-primary="consistency" data-secondary="across different databases" id="idm140417547831344"></a>
<a data-type="indexterm" data-primary="race conditions" data-secondary="caused by dual writes" id="idm140417547830224"></a>
<a data-type="indexterm" data-primary="indexes" data-secondary="secondary" data-tertiary="problems with dual writes" id="idm140417547829120"></a>
<a data-type="indexterm" data-primary="secondary indexes" data-secondary="problems with dual writes" id="idm140417547827728"></a>
However, dual writes have some serious problems, one of which is a race condition illustrated in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_write_order">Figure&nbsp;11-4</a>. In this example, two clients concurrently want to update an item X:
client 1 wants to set the value to A, and client 2 wants to set it to B. Both clients first write
the new value to the database, then write it to the search index. Due to unlucky timing, the
requests are interleaved: the database first sees the write from client 1 setting the value to A,
then the write from client 2 setting the value to B, so the final value in the database is B. The
search index first sees the write from client 2, then client 1, so the final value in the search
index is A. The two systems are now permanently inconsistent with each other, even though no error
occurred.</p>

<figure><div id="fig_stream_write_order" class="figure">
<img src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1104.png" alt="ddia 1104" width="2880" height="1132" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1104.png">
<h6><span class="label">Figure 11-4. </span>In the database, X is first set to A and then to B, while at the search index the writes arrive in the opposite order.</h6>
</div></figure>

<p><a data-type="indexterm" data-primary="concurrency" data-secondary="dual writes, problems with" id="idm140417547822672"></a>
Unless you have some additional concurrency detection mechanism, such as the version vectors we
discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_concurrent">“Detecting Concurrent Writes”</a>, you will not even notice that concurrent writes
occurred—one value will simply silently overwrite another value.</p>

<p><a data-type="indexterm" data-primary="atomicity (transactions)" data-secondary="atomic commit" data-tertiary="maintaining derived data" id="idm140417547820448"></a>
Another problem with dual writes is that one of the writes may fail while the other succeeds. This
is a fault-tolerance problem rather than a concurrency problem, but it also has the effect of the
two systems becoming inconsistent with each other. Ensuring that they either both succeed or both
fail is a case of the atomic commit problem, which is expensive to solve (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_2pc">“Atomic Commit and Two-Phase Commit (2PC)”</a>).</p>

<p><a data-type="indexterm" data-primary="replication" data-secondary="with heterogeneous data systems" id="idm140417547817584"></a>
If you only have one replicated database with a single leader, then that leader determines the order
of writes, so the state machine replication approach works among replicas of the database. However,
in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_write_order">Figure&nbsp;11-4</a> there isn’t a single leader: the database may have a leader and the
search index may have a leader, but neither follows the other, and so conflicts can occur (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_multi_leader">“Multi-Leader Replication”</a>).</p>

<p>The situation would be better if there really was only one leader—for example, the database—and if
we could make the search index a follower of the database. But is this possible in practice?
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="keeping systems in sync" data-startref="ix_dbstrkeepsync" id="idm140417547813824"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="keeping systems in sync" data-startref="ix_strdbkeepsync" id="idm140417547812160"></a></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Change Data Capture"><div class="sect2" id="sec_stream_cdc">
<h2>Change Data Capture</h2>

<p><a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="change data capture" id="dbstrcdc"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="change data capture" id="ix_strdbcdc"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="replication" data-tertiary="change data capture" data-seealso="changelogs" id="ix_logsreplcdc"></a>
<a data-type="indexterm" data-primary="leader-based replication" data-secondary="implementation of replication logs" data-tertiary="change data capture" data-seealso="changelogs" id="ix_repllogcdc"></a>
The problem with most databases’ replication logs is that they have long been considered to be an
internal implementation detail of the database, not a public API. Clients are supposed to query the
database through its data model and query language, not parse the replication logs and try to
extract data from them.</p>

<p>For decades, many databases simply did not have a documented way of getting the log of changes
written to them. For this reason it was difficult to take all the changes made in a database and
replicate them to a different storage technology such as a search index, cache, or data warehouse.</p>

<p><a data-type="indexterm" data-primary="change data capture" id="idm140417547800400"></a>
<a data-type="indexterm" data-primary="changelogs" data-secondary="change data capture" id="idm140417547799568"></a>
More recently, there has been growing interest in <em>change data capture</em> (CDC), which is the process
of observing all data changes written to a database and extracting them in a form in which they can
be replicated to other systems. CDC is especially interesting if changes are made available as a
stream, immediately as they are written.</p>

<p>For example, you can capture the changes in a database and continually apply the same changes to a
search index. If the log of changes is applied in the same order, you can expect the data in the
search index to match the data in the database. The search index and any other derived data systems
are just consumers of the change stream, as illustrated in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_change_capture">Figure&nbsp;11-5</a>.</p>

<figure><div id="fig_stream_change_capture" class="figure">
<img src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1105.png" alt="ddia 1105" width="2880" height="1206" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1105.png">
<h6><span class="label">Figure 11-5. </span>Taking data in the order it was written to one database, and applying the changes to other systems in the same order.</h6>
</div></figure>










<section data-type="sect3" data-pdf-bookmark="Implementing change data capture"><div class="sect3" id="idm140417547793904">
<h3>Implementing change data capture</h3>

<p><a data-type="indexterm" data-primary="change data capture" data-secondary="implementing" id="idm140417547792560"></a>
<a data-type="indexterm" data-primary="derived data" data-secondary="from change data capture" id="idm140417547791456"></a>
<a data-type="indexterm" data-primary="systems of record" data-secondary="change data capture" id="idm140417547790288"></a>
We can call the log consumers <em>derived data systems</em>, as discussed in the introduction to
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/part03.html#part_systems">Part&nbsp;III</a>: the data stored in the search index and the data warehouse is just another view
onto the data in the system of record. Change data capture is a mechanism for ensuring that all
changes made to the system of record are also reflected in the derived data systems so that the
derived systems have an accurate copy of the data.</p>

<p>Essentially, change data capture makes one database the leader (the one from which the changes are
captured), and turns the others into followers. A log-based message broker is well suited for
transporting the change events from the source database, since it preserves the ordering of messages
(avoiding the reordering issue of <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_redelivery">Figure&nbsp;11-2</a>).</p>

<p><a data-type="indexterm" data-primary="triggers (databases)" data-secondary="implementing change data capture" id="idm140417547785728"></a>
<a data-type="indexterm" data-primary="changelogs" data-secondary="generating with triggers" id="idm140417547784560"></a>
<a data-type="indexterm" data-primary="database triggers" data-see="triggers" id="idm140417547783440"></a>
Database triggers can be used to implement change data capture (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_trigger">“Trigger-based replication”</a>) by
registering triggers that observe all changes to data tables and add corresponding entries to a
changelog table.  However, they tend to be fragile and have significant performance overheads.
Parsing the replication log can be a more robust approach, although it also comes with challenges,
such as handling schema changes.</p>

<p><a data-type="indexterm" data-primary="LinkedIn" data-secondary="Databus (change data capture)" id="idm140417547780848"></a>
<a data-type="indexterm" data-primary="Facebook" data-secondary="Wormhole (change data capture)" id="idm140417547779040"></a>
<a data-type="indexterm" data-primary="Yahoo!" data-secondary="Sherpa (database)" id="idm140417547777952"></a>
<a data-type="indexterm" data-primary="Bottled Water (change data capture)" id="idm140417547776848"></a>
<a data-type="indexterm" data-primary="PostgreSQL (database)" data-secondary="Bottled Water (change data capture)" id="idm140417547776000"></a>
<a data-type="indexterm" data-primary="Maxwell (change data capture)" id="idm140417547774880"></a>
<a data-type="indexterm" data-primary="Debezium (change data capture)" id="idm140417547774032"></a>
<a data-type="indexterm" data-primary="MySQL (database)" data-secondary="binlog parsing for change data capture" id="idm140417547773184"></a>
<a data-type="indexterm" data-primary="Mongoriver (change data capture)" id="idm140417547772064"></a>
<a data-type="indexterm" data-primary="MongoDB (database)" data-secondary="oplog parsing" id="idm140417547771216"></a>
<a data-type="indexterm" data-primary="GoldenGate (change data capture)" data-seealso="Oracle" id="idm140417547770112"></a>
<a data-type="indexterm" data-primary="Oracle (database)" data-secondary="GoldenGate (change data capture)" id="idm140417547768992"></a>
LinkedIn’s Databus
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Das2012uf_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Das2012uf_ch11">25</a>], Facebook’s Wormhole
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Sharma2015te_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Sharma2015te_ch11">26</a>], and Yahoo!’s Sherpa
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Narayan2010wq-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Narayan2010wq">27</a>] use this idea at large
scale. Bottled Water implements CDC for PostgreSQL using an API that decodes the write-ahead log
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kleppmann2015vl-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kleppmann2015vl">28</a>],
Maxwell and Debezium do something similar for MySQL by parsing the binlog
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Osheroff2015uy-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Osheroff2015uy">29</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Debezium2016-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Debezium2016">30</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Shankar2016ug-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Shankar2016ug">31</a>],
Mongoriver reads the MongoDB oplog
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Mongoriver2016-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Mongoriver2016">32</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Harvey2015vl-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Harvey2015vl">33</a>],
and GoldenGate provides similar facilities for Oracle
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="GoldenGate2013ub-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#GoldenGate2013ub">34</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="GoldenGate2012ct-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#GoldenGate2012ct">35</a>].</p>

<p>Like message brokers, change data capture is usually asynchronous: the system of record database
does not wait for the change to be applied to consumers before committing it. This design has the
operational advantage that adding a slow consumer does not affect the system of record too much, but it
has the downside that all the issues of replication lag apply (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_lag">“Problems with Replication Lag”</a>).</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Initial snapshot"><div class="sect3" id="sec_stream_cdc_snapshot">
<h3>Initial snapshot</h3>

<p><a data-type="indexterm" data-primary="change data capture" data-secondary="initial snapshot" id="idm140417547740384"></a>
<a data-type="indexterm" data-primary="consistency" data-secondary="consistent snapshots" id="idm140417547739280"></a>
<a data-type="indexterm" data-primary="snapshots (databases)" data-secondary="in change data capture" id="idm140417547738176"></a>
If you have the log of all changes that were ever made to a database, you can reconstruct the entire
state of the database by replaying the log. However, in many cases, keeping all changes forever
would require too much disk space, and replaying it would take too long, so the log needs to be
truncated.</p>

<p>Building a new full-text index, for example, requires a full copy of the entire database—it is
not sufficient to only apply a log of recent changes, since it would be missing items that were not
recently updated. Thus, if you don’t have the entire log history, you need to start with a
consistent snapshot, as previously discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_new_replica">“Setting Up New Followers”</a>.</p>

<p>The snapshot of the database must correspond to a known position or offset in the change log, so
that you know at which point to start applying changes after the snapshot has been processed. Some
CDC tools integrate this snapshot facility, while others leave it as a manual operation.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Log compaction"><div class="sect3" id="sec_stream_log_compaction">
<h3>Log compaction</h3>

<p><a data-type="indexterm" data-primary="compaction" data-secondary="of changelogs" data-seealso="log compaction" id="idm140417547732704"></a>
<a data-type="indexterm" data-primary="change data capture" data-secondary="log compaction" id="idm140417547731328"></a>
<a data-type="indexterm" data-primary="changelogs" data-secondary="log compaction" id="idm140417547730224"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="compaction" id="idm140417547729120"></a>
If you can only keep a limited amount of log history, you need to go through the snapshot process
every time you want to add a new derived data system. However, <em>log compaction</em> provides a good
alternative.</p>

<p>We discussed log compaction previously in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#sec_storage_hash_index">“Hash Indexes”</a>, in the context of
log-structured storage engines (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#fig_storage_compaction">Figure&nbsp;3-2</a> for an example). The principle is
simple: the storage engine periodically looks for log records with the same key, throws away any
duplicates, and keeps only the most recent update for each key. This compaction and merging process
runs in the background.</p>

<p><a data-type="indexterm" data-primary="tombstones" id="idm140417547724800"></a>
In a log-structured storage engine, an update with a special null value (a <em>tombstone</em>) indicates
that a key was deleted, and causes it to be removed during log compaction. But as long as a key is
not overwritten or deleted, it stays in the log forever. The disk space required for such a
compacted log depends only on the current contents of the database, not the number of writes that
have ever occurred in the database. If the same key is frequently overwritten, previous values will
eventually be garbage-collected, and only the latest value will be retained.</p>

<p>The same idea works in the context of log-based message brokers and change data capture. If the CDC
system is set up such that every change has a primary key, and every update for a key replaces the
previous value for that key, then it’s sufficient to keep just the most recent write for a
particular key.</p>

<p>Now, whenever you want to rebuild a derived data system such as a search index, you can start a new
consumer from offset 0 of the log-compacted topic, and sequentially scan over all messages in the
log. The log is guaranteed to contain the most recent value for every key in the database (and maybe
some older values)—in other words, you can use it to obtain a full copy of the database contents without
having to take another snapshot of the CDC source database.</p>

<p><a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="log compaction" id="idm140417547721072"></a>
This log compaction feature is supported by Apache Kafka. As we shall see later in this chapter, it
allows the message broker to be used for durable storage, not just for transient messaging.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="API support for change streams"><div class="sect3" id="sec_stream_change_api">
<h3>API support for change streams</h3>

<p><a data-type="indexterm" data-primary="Application Programming Interfaces (APIs)" data-secondary="for change streams" id="idm140417547718032"></a>
<a data-type="indexterm" data-primary="change data capture" data-secondary="API support for change streams" id="idm140417547716496"></a>
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="API support for change streams" id="idm140417547715328"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="API support for change streams" id="idm140417547713920"></a>
<a data-type="indexterm" data-primary="RethinkDB (database)" data-secondary="subscribing to changes" id="idm140417547712528"></a>
<a data-type="indexterm" data-primary="Firebase (database)" id="idm140417547711424"></a>
<a data-type="indexterm" data-primary="CouchDB (database)" data-secondary="change feed" id="idm140417547710592"></a>
<a data-type="indexterm" data-primary="MongoDB (database)" data-secondary="oplog parsing" id="idm140417547709488"></a>
<a data-type="indexterm" data-primary="Meteor (web framework)" id="idm140417547708384"></a>
Increasingly, databases are beginning to support change streams as a first-class interface, rather
than the typical retrofitted and reverse-engineered CDC efforts. For example, RethinkDB allows
queries to subscribe to notifications when the results of a query change
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Akhmechet2015tq-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akhmechet2015tq">36</a>], Firebase
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Firebase2016-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Firebase2016">37</a>] and CouchDB
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="CouchDB2014_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#CouchDB2014_ch11">38</a>] provide data
synchronization based on a change feed that is also made available to applications, and Meteor uses
the MongoDB oplog to subscribe to data changes and update the user interface
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="DeBergalis2013vd-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#DeBergalis2013vd">39</a>].</p>

<p><a data-type="indexterm" data-primary="VoltDB (database)" data-secondary="output streams" id="idm140417547698336"></a>
VoltDB allows transactions to continuously export data from a database in the form of a stream
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="VoltDBCh15-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#VoltDBCh15">40</a>].
The database represents an output stream in the relational data model as a table into which
transactions can insert tuples, but which cannot be queried. The stream then consists of the log of
tuples that committed transactions have written to this special table, in the order they were
committed. External consumers can asynchronously consume this log and use it to update derived data
systems.</p>

<p><a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="Kafka Connect (database integration)" id="idm140417547694160"></a>
Kafka Connect [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Narkhede2016uo-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Narkhede2016uo">41</a>] is an effort to integrate change data capture tools for a wide range of
database systems with Kafka. Once the stream of change events is in Kafka, it can be used to update
derived data systems such as search indexes, and also feed into stream processing systems as
discussed later in this chapter.
<a data-type="indexterm" data-primary="derived data" data-secondary="maintaining derived state through logs" data-startref="ix_derivedstatelogs" id="idm140417547690208"></a>
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="change data capture" data-startref="dbstrcdc" id="idm140417547688928"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="change data capture" data-startref="ix_strdbcdc" id="idm140417547687264"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="replication" data-tertiary="change data capture" data-seealso="changelogs" data-startref="ix_logsreplcdc" id="idm140417547685808"></a>
<a data-type="indexterm" data-primary="leader-based replication" data-secondary="implementation of replication logs" data-tertiary="change data capture" data-startref="ix_repllogcdc" id="idm140417547683888"></a></p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Event Sourcing"><div class="sect2" id="sec_stream_event_sourcing">
<h2>Event Sourcing</h2>

<p><a data-type="indexterm" data-primary="event sourcing" id="ix_eventsourc"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="event sourcing" id="ix_strmprdbevent"></a>
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="event sourcing" id="ix_dbstreamevent"></a>
<a data-type="indexterm" data-primary="domain-driven design (DDD)" id="idm140417547676064"></a>
There are some parallels between the ideas we’ve discussed here and <em>event sourcing</em>, a technique
that was developed in the domain-driven design (DDD) community
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Young2014wp-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Young2014wp">42</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Fowler2005vd-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Fowler2005vd">43</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Vernon2013ww-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Vernon2013ww">44</a>]. We will discuss event
sourcing briefly, because it incorporates some useful and relevant ideas for streaming systems.</p>

<p><a data-type="indexterm" data-primary="change data capture" data-secondary="comparison to event sourcing" id="idm140417547667904"></a>
<a data-type="indexterm" data-primary="event sourcing" data-secondary="comparison to change data capture" id="idm140417547666832"></a>
<a data-type="indexterm" data-primary="immutability" data-secondary="in event sourcing" id="idm140417547665712"></a>
Similarly to change data capture, event sourcing involves storing all changes to the application
state as a log of change events. The biggest difference is that event sourcing applies the idea at a
different level of abstraction:</p>

<ul>
<li>
<p>In change data capture, the application uses the database in a mutable way, updating and deleting
records at will. The log of changes is extracted from the database at a low level (e.g., by parsing
the replication log), which ensures that the order of writes extracted from the database matches
the order in which they were actually written, avoiding the race condition in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_write_order">Figure&nbsp;11-4</a>. The application writing to the database does not need to be aware that
CDC is occurring.</p>
</li>
<li>
<p>In event sourcing, the application logic is explicitly built on the basis of immutable events that
are written to an event log. In this case, the event store is append-only, and updates or deletes
are discouraged or prohibited. Events are designed to reflect things that happened at the
application level, rather than low-level state changes.</p>
</li>
</ul>

<p>Event sourcing is a powerful technique for data modeling: from an application point of view it is
more meaningful to record the user’s actions as immutable events, rather than recording the effect
of those actions on a mutable database. Event sourcing makes it easier to evolve applications over
time, helps with debugging by making it easier to understand after the fact why something happened,
and guards against application bugs (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_immutability_pros">“Advantages of immutable events”</a>).</p>

<p>For example, storing the event “student cancelled their course enrollment” clearly expresses the
intent of a single action in a neutral fashion, whereas the side effects “one entry was deleted from
the enrollments table, and one cancellation reason was added to the student feedback table” embed a
lot of assumptions about the way the data is later going to be used. If a new application feature is
introduced—for example, “the place is offered to the next person on the waiting list”—the event
sourcing approach allows that new side effect to easily be chained off the existing event.</p>

<p><a data-type="indexterm" data-primary="chronicle data model" id="idm140417547657536"></a>
<a data-type="indexterm" data-primary="star schemas" data-secondary="similarity to event sourcing" id="idm140417547656704"></a>
Event sourcing is similar to the chronicle data model
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Jagadish1995ee-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Jagadish1995ee">45</a>], and there
are also similarities between an event log and the fact table that you find in a star schema (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#sec_storage_analytics_schemas">“Stars and Snowflakes: Schemas for Analytics”</a>).</p>

<p><a data-type="indexterm" data-primary="Event Store (database)" id="idm140417547651408"></a>
Specialized databases such as Event Store
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="EventStore2016-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#EventStore2016">46</a>]
have been developed to support applications using event sourcing, but in general the approach is
independent of any particular tool. A conventional database or a log-based message broker can also
be used to build applications in this style.</p>










<section data-type="sect3" data-pdf-bookmark="Deriving current state from the event log"><div class="sect3" id="sec_stream_state_from_log">
<h3>Deriving current state from the event log</h3>

<p><a data-type="indexterm" data-primary="derived data" data-secondary="in event sourcing" id="ix_derivedeventsrc"></a>
<a data-type="indexterm" data-primary="event sourcing" data-secondary="deriving current state from event log" id="idm140417547644928"></a>
<a data-type="indexterm" data-primary="state" data-secondary="deriving current state from the event log" id="idm140417547643808"></a>
An event log by itself is not very useful, because users generally expect to see the current state
of a system, not the history of modifications. For example, on a shopping website, users expect to
be able to see the current contents of their cart, not an append-only list of all the changes they
have ever made to their cart.</p>

<p><a data-type="indexterm" data-primary="deterministic operations" data-secondary="in state machine replication" id="idm140417547642016"></a>
Thus, applications that use event sourcing need to take the log of events (representing the data
<em>written</em> to the system) and transform it into application state that is suitable for showing to
a user (the way in which data is <em>read</em> from the system
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kleppmann2016ug-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kleppmann2016ug">47</a>]).
This transformation can use arbitrary logic, but it should be deterministic so that you can run it
again and derive the same application state from the event log.</p>

<p>Like with change data capture, replaying the event log allows you to reconstruct the current state
of the system. However, log compaction needs to be handled differently:</p>

<ul>
<li>
<p>A CDC event for the update of a record typically contains the entire new version of the record, so
the current value for a primary key is entirely determined by the most recent event for that
primary key, and log compaction can discard previous events for the same key.</p>
</li>
<li>
<p>On the other hand, with event sourcing, events are modeled at a higher level: an event typically
expresses the intent of a user action, not the mechanics of the state update that occurred as a
result of the action. In this case, later events typically do not override prior events, and so
you need the full history of events to reconstruct the final state. Log compaction is not possible
in the same way.</p>
</li>
</ul>

<p>Applications that use event sourcing typically have some mechanism for storing snapshots of the
current state that is derived from the log of events, so they don’t need to repeatedly reprocess
the full log. However, this is only a performance optimization to speed up reads and recovery from
crashes; the intention is that the system is able to store all raw events forever and reprocess
the full event log whenever required. We discuss this assumption in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_immutability_limitations">“Limitations of immutability”</a>.
<a data-type="indexterm" data-primary="derived data" data-secondary="in event sourcing" data-startref="ix_derivedeventsrc" id="idm140417547632416"></a></p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Commands and events"><div class="sect3" id="idm140417547631040">
<h3>Commands and events</h3>

<p><a data-type="indexterm" data-primary="event sourcing" data-secondary="commands and events" id="idm140417547629728"></a>
<a data-type="indexterm" data-primary="commands (event sourcing)" id="idm140417547628400"></a>
<a data-type="indexterm" data-primary="events" data-secondary="difference to commands" id="idm140417547627600"></a>
The event sourcing philosophy is careful to distinguish between <em>events</em> and <em>commands</em>
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Mak2014ta-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Mak2014ta">48</a>]. When a request from a
user first arrives, it is initially a command: at this point it may still fail, for example because
some integrity condition is violated. The application must first validate that it can execute the
command. If the validation is successful and the command is accepted, it becomes an event, which is
durable and immutable.</p>

<p>For example, if a user tries to register a particular username, or reserve a seat on an airplane or
in a theater, then the application needs to check that the username or seat is not already taken.
(We previously discussed this example in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_consensus_ft">“Fault-Tolerant Consensus”</a>.) When that check has
succeeded, the application can generate an event to indicate that a particular username was
registered by a particular user ID, or that a particular seat has been reserved for a particular
customer.</p>

<p>At the point when the event is generated, it becomes a <em>fact</em>. Even if the customer later decides to
change or cancel the reservation, the fact remains true that they formerly held a reservation for a
particular seat, and the change or cancellation is a separate event that is added later.</p>

<p>A consumer of the event stream is not allowed to reject an event: by the time the consumer sees the
event, it is already an immutable part of the log, and it may have already been seen by other
consumers. Thus, any validation of a command needs to happen synchronously, before it becomes an
event—for example, by using a serializable transaction that atomically validates the command and
publishes the event.</p>

<p>Alternatively, the user request to reserve a seat could be split into two events: first a tentative
reservation, and then a separate confirmation event once the reservation has been validated (as
discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_abcast_to_lin">“Implementing linearizable storage using total order broadcast”</a>). This split allows the validation to take place in
an asynchronous process.
<a data-type="indexterm" data-primary="event sourcing" data-startref="ix_eventsourc" id="idm140417547618112"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="event sourcing" data-startref="ix_strmprdbevent" id="idm140417547617040"></a>
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="event sourcing" data-startref="ix_dbstreamevent" id="idm140417547615392"></a></p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="State, Streams, and Immutability"><div class="sect2" id="sec_stream_immutability">
<h2>State, Streams, and Immutability</h2>

<p><a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="philosophy of immutable events" id="ix_dbstreamstate"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="philosophy of immutable events" id="ix_strmprdbstate"></a>
<a data-type="indexterm" data-primary="immutability" data-secondary="deriving state from event log" id="ix_immutstatederiv"></a>
<a data-type="indexterm" data-primary="event sourcing" data-secondary="immutability and auditability" id="idm140417547607440"></a>
We saw in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a> that batch processing benefits from the immutability of its input files, so
you can run experimental processing jobs on existing input files without fear of damaging them. This
principle of immutability is also what makes event sourcing and change data capture so powerful.</p>

<p><a data-type="indexterm" data-primary="derived data" data-secondary="maintaining derived state through logs" id="ix_derivedimmutable"></a>
<a data-type="indexterm" data-primary="state" data-secondary="derived from log of immutable events" id="idm140417547603552"></a>
<a data-type="indexterm" data-primary="application state" data-see="state" id="idm140417547602432"></a>
We normally think of databases as storing the current state of the application—this
representation is optimized for reads, and it is usually the most convenient for serving queries.
The nature of state is that it changes, so databases support updating and deleting data as
well as inserting it. How does this fit with immutability?</p>

<p>Whenever you have state that changes, that state is the result of the events that mutated it over
time. For example, your list of currently available seats is the result of the reservations you have
processed, the current account balance is the result of the credits and debits on the account, and
the response time graph for your web server is an aggregation of the individual response times of
all web requests that have occurred.</p>

<p><a data-type="indexterm" data-primary="changelogs" id="idm140417547599856"></a>
No matter how the state changes, there was always a sequence of events that caused those changes.
Even as things are done and undone, the fact remains true that those events occurred. The key idea
is that mutable state and an append-only log of immutable events do not contradict each other: they
are two sides of the same coin. The log of all changes, the <em>changelog</em>, represents the evolution of
state over time.</p>

<p><a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="derivative of state by time" id="idm140417547597920"></a>
If you are mathematically inclined, you might say that the application state is what you get when
you integrate an event stream over time, and a change stream is what you get when you differentiate
the state by time, as shown in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_integral">Figure&nbsp;11-6</a>
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Hyde2016-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hyde2016">49</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Gupta1999uz-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gupta1999uz">50</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Griffin1995gr-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Griffin1995gr">51</a>].
The analogy has limitations (for example, the second derivative of state does not seem to be
meaningful), but it’s a useful starting point for thinking about data.</p>

<figure><div id="fig_stream_integral" class="figure">
<img src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1106.png" alt="ddia 1106" width="2880" height="522" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1106.png">
<h6><span class="label">Figure 11-6. </span>The relationship between the current application state and an event stream.</h6>
</div></figure>

<p><a data-type="indexterm" data-primary="systems of record" data-secondary="treating event log as" id="idm140417547586832"></a>
If you store the changelog durably, that simply has the effect of making the state reproducible. If
you consider the log of events to be your system of record, and any mutable state as being derived
from it, it becomes easier to reason about the flow of data through a system. As Pat Helland puts it
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Helland2015vx-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2015vx">52</a>]:</p>
<blockquote>
<p><a data-type="indexterm" data-primary="caches" data-secondary="database as cache of transaction log" id="idm140417547582464"></a>
Transaction logs record all the changes made to the database. High-speed appends are the only way to
change the log. From this perspective, the contents of the database hold a caching of the latest
record values in the logs. The truth is the log. The database is a cache of a subset of the log.
That cached subset happens to be the latest value of each record and index value from the log.</p></blockquote>

<p><a data-type="indexterm" data-primary="logs (data structure)" data-secondary="compaction" id="idm140417547580640"></a>
Log compaction, as discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_log_compaction">“Log compaction”</a>, is one way of bridging the
distinction between log and database state: it retains only the latest version of each record, and
discards overwritten versions.</p>










<section data-type="sect3" data-pdf-bookmark="Advantages of immutable events"><div class="sect3" id="sec_stream_immutability_pros">
<h3>Advantages of immutable events</h3>

<p><a data-type="indexterm" data-primary="immutability" data-secondary="advantages of" id="idm140417547576800"></a>
<a data-type="indexterm" data-primary="events" data-secondary="immutable, advantages of" id="idm140417547575472"></a>
<a data-type="indexterm" data-primary="auditability" data-secondary="through immutability" id="idm140417547574352"></a>
<a data-type="indexterm" data-primary="ledgers" id="idm140417547573248"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="advantages of immutability" id="idm140417547572416"></a>
<a data-type="indexterm" data-primary="corruption of data" data-secondary="recovering from" id="idm140417547571296"></a>
<a data-type="indexterm" data-primary="financial data" id="idm140417547570192"></a>
Immutability in databases is an old idea. For example, accountants have been using immutability for
centuries in financial bookkeeping. When a transaction occurs, it is recorded in an append-only
<em>ledger</em>, which is essentially a log of events describing money, goods, or services that have changed
hands. The accounts, such as profit and loss or the balance sheet, are derived from the transactions
in the ledger by adding them up [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kleppmann2011vr-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kleppmann2011vr">53</a>].</p>

<p><a data-type="indexterm" data-primary="compensating transactions" id="idm140417547566304"></a>
<a data-type="indexterm" data-primary="correctness" data-secondary="of immutable data" id="idm140417547565408"></a>
If a mistake is made, accountants don’t erase or change the incorrect transaction in the
ledger—instead, they add another transaction that compensates for the mistake, for example refunding
an incorrect charge. The incorrect transaction still remains in the ledger forever, because it might
be important for auditing reasons. If incorrect figures, derived from the incorrect ledger, have
already been published, then the figures for the next accounting period include a correction. This
process is entirely normal in accounting [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Helland2007vk-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2007vk">54</a>].</p>

<p>Although such auditability is particularly important in financial systems, it is also beneficial for
many other systems that are not subject to such strict regulation. As discussed in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_philosophy">“Philosophy of batch process outputs”</a>, if you accidentally deploy buggy code that writes bad data to a database,
recovery is much harder if the code is able to destructively overwrite data. With an append-only log
of immutable events, it is much easier to diagnose what happened and recover from the problem.</p>

<p>Immutable events also capture more information than just the current state. For example, on a
shopping website, a customer may add an item to their cart and then remove it again. Although the
second event cancels out the first event from the point of view of order fulfillment, it may be
useful to know for analytics purposes that the customer was considering a particular item but then
decided against it. Perhaps they will choose to buy it in the future, or perhaps they found a
substitute. This information is recorded in an event log, but would be lost in a database that
deletes items when they are removed from the cart
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Young2014wp">42</a>].</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Deriving several views from the same event log"><div class="sect3" id="sec_stream_deriving_views">
<h3>Deriving several views from the same event log</h3>

<p><a data-type="indexterm" data-primary="events" data-secondary="deriving views from event log" id="idm140417547556096"></a>
<a data-type="indexterm" data-primary="Druid (database)" id="idm140417547554800"></a>
<a data-type="indexterm" data-primary="Yahoo!" data-secondary="Pistachio (database)" id="idm140417547553968"></a>
<a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="Kafka Connect (database integration)" id="idm140417547552864"></a>
Moreover, by separating mutable state from the immutable event log, you can derive several different
read-oriented representations from the same log of events. This works just like having multiple
consumers of a stream (<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_change_capture">Figure&nbsp;11-5</a>): for example, the analytic database Druid
ingests directly from Kafka using this approach [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Yang2015ui-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Yang2015ui">55</a>],
Pistachio is a distributed key-value store that uses Kafka as a commit log
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Li2015vm-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Li2015vm">56</a>],
and Kafka Connect sinks can export data from Kafka to various different databases and indexes
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Narkhede2016uo">41</a>]. It would make sense for many other
storage and indexing systems, such as search servers, to similarly take their input from a
distributed log (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_sync">“Keeping Systems in Sync”</a>).</p>

<p><a data-type="indexterm" data-primary="evolvability" data-secondary="of databases" id="idm140417547544080"></a>
<a data-type="indexterm" data-primary="migrating (rewriting) data" id="idm140417547542944"></a>
Having an explicit translation step from an event log to a database makes it easier to evolve your
application over time: if you want to introduce a new feature that presents your existing data in
some new way, you can use the event log to build a separate read-optimized view for the new feature,
and run it alongside the existing systems without having to modify them. Running old and new systems
side by side is often easier than performing a complicated schema migration in an existing system.
Once the old system is no longer needed, you can simply shut it down and reclaim its resources
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kleppmann2016ug">47</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Paramasivam2016th-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Paramasivam2016th">57</a>].</p>

<p><a data-type="indexterm" data-primary="command query responsibility segregation (CQRS)" id="idm140417547537936"></a>
Storing data is normally quite straightforward if you don’t have to worry about how it is going to
be queried and accessed; many of the complexities of schema design, indexing, and storage engines
are the result of wanting to support certain query and access patterns (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#ch_storage">Chapter&nbsp;3</a>). For
this reason, you gain a lot of flexibility by separating the form in which data is written from the
form it is read, and by allowing several different read views. This idea is sometimes known as
<em>command query responsibility segregation</em> (CQRS) [<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Young2014wp">42</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Fowler2011xt-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Fowler2011xt">58</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Young2010td-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Young2010td">59</a>].</p>

<p><a data-type="indexterm" data-primary="consistency" data-secondary="across different databases" id="idm140417547529888"></a>
<a data-type="indexterm" data-primary="normalization (data representation)" data-secondary="versus denormalization" id="idm140417547528736"></a>
<a data-type="indexterm" data-primary="denormalization (data representation)" data-secondary="versus normalization" id="idm140417547527616"></a>
<a data-type="indexterm" data-primary="schemas" data-secondary="traditional approach to design, fallacy in" id="idm140417547526496"></a>
The traditional approach to database and schema design is based on the fallacy that data must be
written in the same form as it will be queried. Debates about normalization and denormalization (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch02.html#sec_datamodels_many_to_many">“Many-to-One and Many-to-Many Relationships”</a>) become largely irrelevant if you can translate data from a
write-optimized event log to read-optimized application state: it is entirely reasonable to
denormalize data in the read-optimized views, as the translation process gives you a mechanism for
keeping it consistent with the event log.</p>

<p><a data-type="indexterm" data-primary="Twitter" data-secondary="constructing home timelines (example)" id="idm140417547523712"></a>
In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch01.html#sec_introduction_scalability_load">“Describing Load”</a> we discussed Twitter’s home timelines, a cache of
recently written tweets by the people a particular user is following (like a mailbox). This is
another example of read-optimized state: home timelines are highly denormalized, since your tweets
are duplicated in all of the timelines of the people following you. However, the fan-out service
keeps this duplicated state in sync with new tweets and new following relationships, which keeps the
duplication manageable.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Concurrency control"><div class="sect3" id="sec_stream_concurrency">
<h3>Concurrency control</h3>

<p><a data-type="indexterm" data-primary="concurrency" data-secondary="reducing, through event logs" id="idm140417547519552"></a>
<a data-type="indexterm" data-primary="race conditions" data-secondary="preventing with event logs" id="idm140417547518432"></a>
The biggest downside of event sourcing and change data capture is that the consumers of the event
log are usually asynchronous, so there is a possibility that a user may make a write to the log,
then read from a log-derived view and find that their write has not yet been reflected in the read
view. We discussed this problem and potential solutions previously in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#sec_replication_ryw">“Reading Your Own Writes”</a>.</p>

<p>One solution would be to perform the updates of the read view synchronously with appending the event
to the log. This requires a transaction to combine the writes into an atomic unit, so either you
need to keep the event log and the read view in the same storage system, or you need a distributed
transaction across the different systems. Alternatively, you could use the approach discussed in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_abcast_to_lin">“Implementing linearizable storage using total order broadcast”</a>.</p>

<p>On the other hand, deriving the current state from an event log also simplifies some aspects of
concurrency control. Much of the need for multi-object transactions (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch07.html#sec_transactions_multi_object">“Single-Object and Multi-Object Operations”</a>) stems from a single user action requiring data to be changed in
several different places. With event sourcing, you can design an event such that it is a
self-contained description of a user action. The user action then requires only a single write in
one place—namely appending the events to the log—which is easy to make atomic.</p>

<p><a data-type="indexterm" data-primary="single-threaded execution" data-secondary="in stream processing" id="idm140417547512384"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="single-threaded execution" id="idm140417547511088"></a>
If the event log and the application state are partitioned in the same way (for example, processing
an event for a customer in partition 3 only requires updating partition 3 of the application state),
then a straightforward single-threaded log consumer needs no concurrency control for writes—by
construction, it only processes a single event at a time (see also <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch07.html#sec_transactions_serial">“Actual Serial Execution”</a>). The
log removes the nondeterminism of concurrency by defining a serial order of events in a partition
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2013vs_ch11">24</a>]. If an event touches multiple state
partitions, a bit more work is required, which we will discuss in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch12.html#ch_future">Chapter&nbsp;12</a>.
<a data-type="indexterm" data-primary="derived data" data-secondary="maintaining derived state through logs" data-startref="ix_derivedimmutable" id="idm140417547506912"></a></p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Limitations of immutability"><div class="sect3" id="sec_stream_immutability_limitations">
<h3>Limitations of immutability</h3>

<p><a data-type="indexterm" data-primary="immutability" data-secondary="limitations of" id="idm140417547504128"></a>
<a data-type="indexterm" data-primary="version control systems, reliance on immutable data" id="idm140417547502800"></a>
<a data-type="indexterm" data-primary="Git (version control system)" id="idm140417547501936"></a>
<a data-type="indexterm" data-primary="Mercurial (version control system)" id="idm140417547501088"></a>
<a data-type="indexterm" data-primary="Fossil (version control system)" id="idm140417547500240"></a>
Many systems that don’t use an event-sourced model nevertheless rely on immutability: various
databases internally use immutable data structures or multi-version data to support point-in-time
snapshots (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch07.html#sec_transactions_snapshot_indexes">“Indexes and snapshot isolation”</a>). Version control systems such as Git,
Mercurial, and Fossil also rely on immutable data to preserve version history of files.</p>

<p><a data-type="indexterm" data-primary="garbage collection" data-secondary="immutability and" id="idm140417547498080"></a>
To what extent is it feasible to keep an immutable history of all changes forever? The answer
depends on the amount of churn in the dataset. Some workloads mostly add data and rarely update or
delete; they are easy to make immutable. Other workloads have a high rate of updates and deletes on
a comparatively small dataset; in these cases, the immutable history may grow prohibitively large,
fragmentation may become an issue, and the performance of compaction and garbage collection becomes
crucial for operational robustness [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Schwartz2013ur_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Schwartz2013ur_ch11">60</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Eloff2015xu-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Eloff2015xu">61</a>].</p>

<p><a data-type="indexterm" data-primary="deleting data" id="idm140417547491680"></a>
<a data-type="indexterm" data-primary="privacy" data-secondary="deleting data" id="idm140417547490848"></a>
Besides the performance reasons, there may also be circumstances in which you need data to be
deleted for administrative reasons, in spite of all immutability. For example, privacy regulations
may require deleting a user’s personal information after they close their account, data protection
legislation may require erroneous information to be removed, or an accidental leak of sensitive
information may need to be contained.</p>

<p><a data-type="indexterm" data-primary="Datomic (database)" data-secondary="excision (deleting data)" id="idm140417547489040"></a>
<a data-type="indexterm" data-primary="Fossil (version control system)" data-secondary="shunning (deleting data)" id="idm140417547487744"></a>
In these circumstances, it’s not sufficient to just append another event to the log to indicate that
the prior data should be considered deleted—you actually want to rewrite history and pretend that
the data was never written in the first place. For example, Datomic calls this feature <em>excision</em>
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="DatomicExcision-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#DatomicExcision">62</a>], and the Fossil
version control system has a similar concept called <em>shunning</em>
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="FossilShun-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#FossilShun">63</a>].</p>

<p>Truly deleting data is surprisingly hard [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kreps2015zt-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2015zt">64</a>], since copies can live in many places: for example, storage engines, filesystems, and
SSDs often write to a new location rather than overwriting in place
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2015vx">52</a>], and backups are often deliberately
immutable to prevent accidental deletion or corruption. Deletion is more a matter of “making it
harder to retrieve the data” than actually “making it impossible to retrieve the data.”
Nevertheless, you sometimes have to try, as we shall see in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch12.html#sec_future_legislation">“Legislation and self-regulation”</a>.
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-tertiary="philosophy of immutable events" data-startref="ix_dbstreamstate" id="idm140417547476096"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-tertiary="philosophy of immutable events" data-startref="ix_strmprdbstate" id="idm140417547474416"></a>
<a data-type="indexterm" data-primary="databases" data-secondary="relation to event streams" data-startref="ix_dbstream" id="idm140417547472752"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="relation to databases" data-startref="ix_strmprdb" id="idm140417547471360"></a>
<a data-type="indexterm" data-primary="immutability" data-secondary="deriving state from event log" data-startref="ix_immutstatederiv" id="idm140417547469984"></a></p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Processing Streams"><div class="sect1" id="sec_stream_processing">
<h1>Processing Streams</h1>

<p><a data-type="indexterm" data-primary="stream processing" id="ix_streamproc"></a>
<a data-type="indexterm" data-primary="streams" data-secondary="processing" data-see="stream processing" id="idm140417547466240"></a>
So far in this chapter we have talked about where streams come from (user activity events, sensors,
and writes to databases), and we have talked about how streams are transported (through direct
messaging, via message brokers, and in event logs).</p>

<p>What remains is to discuss what you can do with the stream once you have it—namely, you can
process it. Broadly, there are three options:</p>
<ol>
<li>
<p>You can take the data in the events and write it to a database, cache, search index, or similar
storage system, from where it can then be queried by other clients. As shown in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_change_capture">Figure&nbsp;11-5</a>, this is a good way of keeping a database in sync with changes
happening in other parts of the system—especially if the stream consumer is the only client
writing to the database. Writing to a storage system is the streaming equivalent of what we
discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_output">“The Output of Batch Workflows”</a>.</p>
</li>
<li>
<p>You can push the events to users in some way, for example by sending email alerts or push
notifications, or by streaming the events to a real-time dashboard where they are visualized.
In this case, a human is the ultimate consumer of the stream.</p>
</li>
<li>
<p>You can process one or more input streams to produce one or more output streams. Streams may go
through a pipeline consisting of several such processing stages before they eventually end up at
an output (option 1 or 2).</p>
</li>

</ol>

<p><a data-type="indexterm" data-primary="operators" data-secondary="in stream processing" id="idm140417547458176"></a>
<a data-type="indexterm" data-primary="Unix philosophy" data-secondary="comparison to stream processing" id="idm140417547457072"></a>
In the rest of this chapter, we will discuss option 3: processing streams to produce other, derived
streams. A piece of code that processes streams like this is known as an <em>operator</em> or a <em>job</em>. It
is closely related to the Unix processes and MapReduce jobs we discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a>, and
the pattern of dataflow is similar: a stream processor consumes input streams in a read-only
fashion and writes its output to a different location in an append-only fashion.</p>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="comparison to batch processing" id="idm140417547453696"></a>
<a data-type="indexterm" data-primary="batch processing" data-secondary="comparison to stream processing" id="idm140417547452576"></a>
<a data-type="indexterm" data-primary="MapReduce (batch processing)" data-secondary="comparison to stream processing" id="idm140417547451456"></a>
<a data-type="indexterm" data-primary="dataflow engines" data-secondary="comparison to stream processing" id="idm140417547450320"></a>
The patterns for partitioning and parallelization in stream processors are also very similar to
those in MapReduce and the dataflow engines we saw in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a>, so we won’t repeat those topics
here. Basic mapping operations such as transforming and filtering records also work the same.</p>

<p>The one crucial difference to batch jobs is that a stream never ends. This difference has many
implications: as discussed at the start of this chapter, sorting does not make sense with an
unbounded dataset, and so sort-merge joins (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_reduce_joins">“Reduce-Side Joins and Grouping”</a>) cannot be used.
Fault-tolerance mechanisms must also change: with a batch job that has been running for a few
minutes, a failed task can simply be restarted from the beginning, but with a stream job that has
been running for several years, restarting from the beginning after a crash may not be a viable option.</p>








<section data-type="sect2" data-pdf-bookmark="Uses of Stream Processing"><div class="sect2" id="sec_stream_uses">
<h2>Uses of Stream Processing</h2>

<p>Stream processing has long been used for monitoring purposes, where an organization wants to be
alerted if certain things happen. For example:</p>

<ul>
<li>
<p>Fraud detection systems need to determine if the usage patterns of a credit card have unexpectedly
changed, and block the card if it is likely to have been stolen.</p>
</li>
<li>
<p>Trading systems need to examine price changes in a financial market and execute trades according
to specified rules.</p>
</li>
<li>
<p>Manufacturing systems need to monitor the status of machines in a factory, and quickly identify
the problem if there is a malfunction.</p>
</li>
<li>
<p>Military and intelligence systems need to track the activities of a potential aggressor, and raise
the alarm if there are signs of an attack.</p>
</li>
</ul>

<p>These kinds of applications require quite sophisticated pattern matching and correlations. However,
other uses of stream processing have also emerged over time. In this section we will briefly compare
and contrast some of these applications.</p>










<section data-type="sect3" data-pdf-bookmark="Complex event processing"><div class="sect3" id="idm140417547438720">
<h3>Complex event processing</h3>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="complex event processing (CEP)" id="idm140417547437328"></a>
<a data-type="indexterm" data-primary="complex event processing (CEP)" id="idm140417547435984"></a>
<a data-type="indexterm" data-primary="CEP" data-see="complex event processing" id="idm140417547435136"></a>
<em>Complex event processing</em> (CEP) is an approach developed in the 1990s for analyzing event streams,
especially geared toward the kind of application that requires searching for certain event patterns
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Luckham2006tv-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Luckham2006tv">65</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Perera2015tz-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Perera2015tz">66</a>].
Similarly to the way that a regular expression allows you to search for certain patterns of
characters in a string, CEP allows you to specify rules to search for certain patterns of events in
a stream.</p>

<p>CEP systems often use a high-level declarative query language like SQL, or a graphical user
interface, to describe the patterns of events that should be detected. These queries are submitted to
a processing engine that consumes the input streams and internally maintains a state machine that
performs the required matching. When a match is found, the engine emits a <em>complex event</em> (hence the
name) with the details of the event pattern that was detected
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Arasu2006df-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Arasu2006df">67</a>].</p>

<p>In these systems, the relationship between queries and data is reversed compared to normal
databases. Usually, a database stores data persistently and treats queries as transient: when a
query comes in, the database searches for data matching the query, and then forgets about the query
when it has finished.  CEP engines reverse these roles: queries are stored long-term, and events
from the input streams continuously flow past them in search of a query that matches an event pattern
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Hyde2009jm-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hyde2009jm">68</a>].</p>

<p><a data-type="indexterm" data-primary="Esper (CEP engine)" id="idm140417547420544"></a>
<a data-type="indexterm" data-primary="IBM" data-secondary="InfoSphere Streams (CEP engine)" id="idm140417547419488"></a>
<a data-type="indexterm" data-primary="Apama (stream analytics)" id="idm140417547418368"></a>
<a data-type="indexterm" data-primary="TIBCO" data-secondary="StreamBase (stream analytics)" id="idm140417547417520"></a>
<a data-type="indexterm" data-primary="SQLstream (stream analytics)" id="idm140417547416480"></a>
<a data-type="indexterm" data-primary="Samza (stream processor)" data-secondary="streaming SQL support" id="idm140417547415744"></a><a data-type="indexterm" data-primary="Apache Samza" data-see="Samza" id="idm140417547414752"></a>
Implementations of CEP include Esper
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Esper2016-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Esper2016">69</a>],
IBM InfoSphere Streams
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Nabi2014wu-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Nabi2014wu">70</a>],
Apama, TIBCO StreamBase, and SQLstream. Distributed stream processors like Samza are also gaining
SQL support for declarative queries on streams
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Pathirage2016fr-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Pathirage2016fr">71</a>].</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Stream analytics"><div class="sect3" id="idm140417547405888">
<h3>Stream analytics</h3>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="stream analytics" id="idm140417547404576"></a>
<a data-type="indexterm" data-primary="analytics" data-secondary="stream analytics" id="idm140417547403472"></a>
<a data-type="indexterm" data-primary="aggregation" data-secondary="in stream processes" id="idm140417547402368"></a>
Another area in which stream processing is used is for <em>analytics</em> on streams. The boundary between
CEP and stream analytics is blurry, but as a general rule, analytics tends to be less interested in
finding specific event sequences and is more oriented toward aggregations and statistical metrics
over a large number of events—for example:</p>

<ul>
<li>
<p>Measuring the rate of some type of event (how often it occurs per time interval)</p>
</li>
<li>
<p>Calculating the rolling average of a value over some time period</p>
</li>
<li>
<p>Comparing current statistics to previous time intervals (e.g., to detect trends or to alert on
metrics that are unusually high or low compared to the same time last week)</p>
</li>
</ul>

<p><a data-type="indexterm" data-primary="windows (stream processing)" id="idm140417547396720"></a>
Such statistics are usually computed over fixed time intervals—for example, you might want to
know the average number of queries per second to a service over the last 5 minutes, and their
99th percentile response time during that period. Averaging over a few minutes smoothes out
irrelevant fluctuations from one second to the next, while still giving you a timely picture of any
changes in traffic pattern. The time interval over which you aggregate is known as a <em>window</em>, and
we will look into windowing in more detail in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_time">“Reasoning About Time”</a>.</p>

<p><a data-type="indexterm" data-primary="probabilistic algorithms" id="idm140417547393888"></a>
<a data-type="indexterm" data-primary="Bloom filter (algorithm)" id="idm140417547392864"></a>
<a data-type="indexterm" data-primary="HyperLogLog (algorithm)" id="idm140417547392016"></a>
Stream analytics systems sometimes use probabilistic algorithms, such as Bloom filters (which we
encountered in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#sec_storage_lsm_optimize">“Performance optimizations”</a>) for set membership, HyperLogLog
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Flajolet2007um-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Flajolet2007um">72</a>] for cardinality estimation, and various
percentile estimation algorithms (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch01.html#sidebar_percentiles">“Percentiles in Practice”</a>). Probabilistic algorithms produce
approximate results, but have the advantage of requiring significantly less memory in the stream
processor than exact algorithms. This use of approximation algorithms sometimes leads people to
believe that stream processing systems are always lossy and inexact, but that is wrong: there is
nothing inherently approximate about stream processing, and probabilistic algorithms are merely an
optimization [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kreps2014wv_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014wv_ch11">73</a>].</p>

<p><a data-type="indexterm" data-primary="Storm (stream processor)" id="idm140417547384352"></a><a data-type="indexterm" data-primary="Apache Storm" data-see="Storm" id="idm140417547383408"></a>
<a data-type="indexterm" data-primary="Spark (processing framework)" data-secondary="Spark Streaming" id="idm140417547382336"></a>
<a data-type="indexterm" data-primary="Flink (processing framework)" data-secondary="stream processing" id="idm140417547381216"></a>
<a data-type="indexterm" data-primary="Concord (stream processor)" id="idm140417547380096"></a>
<a data-type="indexterm" data-primary="Samza (stream processor)" id="idm140417547379248"></a>
<a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="Kafka Streams (stream processor)" id="idm140417547378400"></a>
<a data-type="indexterm" data-primary="Google" data-secondary="Cloud Dataflow (stream processor)" data-seealso="Beam" id="idm140417547377280"></a>
<a data-type="indexterm" data-primary="Microsoft" data-secondary="Azure Stream Analytics" id="idm140417547375888"></a>
Many open source distributed stream processing frameworks are designed with analytics in mind: for
example, Apache Storm, Spark Streaming, Flink, Concord, Samza, and Kafka Streams
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Hellstrom2016ub-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hellstrom2016ub">74</a>].
Hosted services include Google Cloud Dataflow and Azure Stream Analytics.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Maintaining materialized views"><div class="sect3" id="sec_stream_mat_view">
<h3>Maintaining materialized views</h3>

<p><a data-type="indexterm" data-primary="caches" data-secondary="invalidation and maintenance" id="idm140417547370768"></a>
<a data-type="indexterm" data-primary="indexes" data-secondary="updating when data changes" id="idm140417547369472"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="maintenance of materialized views" id="idm140417547368400"></a>
<a data-type="indexterm" data-primary="materialization" data-secondary="materialized views" data-tertiary="maintaining, using stream processing" id="idm140417547367280"></a>
We saw in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_databases">“Databases and Streams”</a> that a stream of changes to a database can be used to keep
derived data systems, such as caches, search indexes, and data warehouses, up to date with a source
database. We can regard these examples as specific cases of maintaining <em>materialized views</em> (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#sec_storage_materialized_views">“Aggregation: Data Cubes and Materialized Views”</a>): deriving an alternative view onto some dataset so that you can
query it efficiently, and updating that view whenever the underlying data changes
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gupta1999uz">50</a>].</p>

<p><a data-type="indexterm" data-primary="windows (stream processing)" data-secondary="infinite windows for changelogs" id="idm140417547362448"></a>
Similarly, in event sourcing, application state is maintained by applying a log of events; here the
application state is also a kind of materialized view. Unlike stream analytics scenarios, it is
usually not sufficient to consider only events within some time window: building the materialized
view potentially requires <em>all</em> events over an arbitrary time period, apart from any obsolete events
that may be discarded by log compaction (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_log_compaction">“Log compaction”</a>). In effect, you need a
window that stretches all the way back to the beginning of time.</p>

<p><a data-type="indexterm" data-primary="Samza (stream processor)" id="idm140417547359168"></a>
<a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="Kafka Streams (stream processor)" id="idm140417547358320"></a>
<a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="log compaction" id="idm140417547357200"></a>
In principle, any stream processor could be used for materialized view maintenance, although the
need to maintain events forever runs counter to the assumptions of some analytics-oriented
frameworks that mostly operate on windows of a limited duration. Samza and Kafka Streams support
this kind of usage, building upon Kafka’s support for log compaction
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kreps2014wm_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014wm_ch11">75</a>].</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Search on streams"><div class="sect3" id="idm140417547353168">
<h3>Search on streams</h3>

<p><a data-type="indexterm" data-primary="searches" data-secondary="on streams" id="idm140417547352080"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="search on streams" id="idm140417547350976"></a>
Besides CEP, which allows searching for patterns consisting of multiple events, there is also
sometimes a need to search for individual events based on complex criteria, such as full-text search
queries.</p>

<p><a data-type="indexterm" data-primary="media monitoring" id="idm140417547349392"></a>
<a data-type="indexterm" data-primary="Elasticsearch (search server)" data-secondary="percolator (stream search)" id="idm140417547348560"></a>
For example, media monitoring services subscribe to feeds of news articles and broadcasts from media
outlets, and search for any news mentioning companies, products, or topics of interest. This is done
by formulating a search query in advance, and then continually matching the stream of news items
against this query. Similar features exist on some websites: for example, users of real estate
websites can ask to be notified when a new property matching their search criteria appears on the
market. The percolator feature of Elasticsearch
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Banon2011hw-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Banon2011hw">76</a>] is one option for implementing this kind of stream search.</p>

<p>Conventional search engines first index the documents and then run queries over the index. By
contrast, searching a stream turns the processing on its head: the queries are stored, and the
documents run past the queries, like in CEP. In the simplest case, you can test every document
against every query, although this can get slow if you have a large number of queries. To optimize
the process, it is possible to index the queries as well as the documents, and thus narrow down the
set of queries that may match
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Woodward2015vy-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Woodward2015vy">77</a>].</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Message passing and RPC"><div class="sect3" id="sec_stream_actors_drpc">
<h3>Message passing and RPC</h3>

<p><a data-type="indexterm" data-primary="actor model" data-secondary="comparison to stream processing" id="idm140417547339472"></a>
<a data-type="indexterm" data-primary="concurrency" data-secondary="actor programming model" id="idm140417547338352"></a>
<a data-type="indexterm" data-primary="threads (concurrency)" data-secondary="actor model" id="idm140417547337248"></a>
In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch04.html#sec_encoding_dataflow_msg">“Message-Passing Dataflow”</a> we discussed message-passing systems as an alternative to RPC—i.e.,
as a mechanism for services to communicate, as used for example in the actor model. Although these
systems are also based on messages and events, we normally don’t think of them as stream processors:</p>

<ul>
<li>
<p>Actor frameworks are primarily a mechanism for managing concurrency and distributed execution of
communicating modules, whereas stream processing is primarily a data management technique.</p>
</li>
<li>
<p>Communication between actors is often ephemeral and one-to-one, whereas event logs are durable and
multi-subscriber.</p>
</li>
<li>
<p>Actors can communicate in arbitrary ways (including cyclic request/response patterns), but stream
processors are usually set up in acyclic pipelines where every stream is the output of one
particular job, and derived from a well-defined set of input streams.</p>
</li>
</ul>

<p><a data-type="indexterm" data-primary="Storm (stream processor)" data-secondary="distributed RPC" id="idm140417547331104"></a>
That said, there is some crossover area between RPC-like systems and stream processing. For
example, Apache Storm has a feature called <em>distributed RPC</em>, which allows user queries to be farmed
out to a set of nodes that also process event streams; these queries are then interleaved with
events from the input streams, and results can be aggregated and sent back to the user
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="StormDocs-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#StormDocs">78</a>].
(See also <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch12.html#sec_future_unbundled_multi_partition">“Multi-partition data processing”</a>.)</p>

<p>It is also possible to process streams using actor frameworks. However, many such frameworks do not
guarantee message delivery in the case of crashes, so the processing is not fault-tolerant unless
you implement additional retry logic.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Reasoning About Time"><div class="sect2" id="sec_stream_time">
<h2>Reasoning About Time</h2>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="reasoning about time" id="ix_streamtime"></a>
<a data-type="indexterm" data-primary="time" data-secondary="reasoning about, in stream processors" id="ix_timestream"></a>
<a data-type="indexterm" data-primary="windows (stream processing)" id="ix_windowstream"></a>
Stream processors often need to deal with time, especially when used for analytics purposes, which
frequently use time windows such as “the average over the last five minutes.” It might seem that the
meaning of “the last five minutes” should be unambiguous and clear, but unfortunately the notion is
surprisingly tricky.</p>

<p>In a batch process, the processing tasks rapidly crunch through a large collection of historical
events. If some kind of breakdown by time needs to happen, the batch process needs to look at the
timestamp embedded in each event. There is no point in looking at the system clock of the machine
running the batch process, because the time at which the process is run has nothing to do with the
time at which the events actually occurred.</p>

<p>A batch process may read a year’s worth of historical events within a few minutes; in most cases, the
timeline of interest is the year of history, not the few minutes of processing. Moreover, using the
timestamps in the events allows the processing to be deterministic: running the same process again on
the same input yields the same result (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_materialize_ft">“Fault tolerance”</a>).</p>

<p><a data-type="indexterm" data-primary="processing time (of events)" id="idm140417547316704"></a>
On the other hand, many stream processing frameworks use the local system clock on the processing
machine (the <em>processing time</em>) to determine windowing
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Akidau2016tb-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2016tb">79</a>].
This approach has the advantage of being simple, and it is reasonable if the delay between event
creation and event processing is negligibly short. However, it breaks down if there is any
significant processing lag—i.e., if the processing may happen noticeably later than the time at
which the event actually occurred.</p>










<section data-type="sect3" data-pdf-bookmark="Event time versus processing time"><div class="sect3" id="idm140417547312688">
<h3>Event time versus processing time</h3>

<p><a data-type="indexterm" data-primary="time" data-secondary="reasoning about, in stream processors" data-tertiary="event time versus processing time" id="idm140417547311296"></a>
<a data-type="indexterm" data-primary="events" data-secondary="event time versus processing time" id="idm140417547309840"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="reasoning about time" data-tertiary="event time versus processing time" id="idm140417547308720"></a>
There are many reasons why processing may be delayed: queueing, network faults (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch08.html#sec_distributed_networks">“Unreliable Networks”</a>), a performance issue leading to contention in the message broker or
processor, a restart of the stream consumer, or reprocessing of past events (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_replay">“Replaying old messages”</a>) while recovering from a fault or after fixing a bug in the code.</p>

<p>Moreover, message delays can also lead to unpredictable ordering of messages. For example, say a user
first makes one web request (which is handled by web server A), and then a second request (which is
handled by server B). A and B emit events describing the requests they handled, but B’s event
reaches the message broker before A’s event does. Now stream processors will first see the B event
and then the A event, even though they actually occurred in the opposite order.</p>

<p><a data-type="indexterm" data-primary="Star Wars analogy (event time versus processing time)" id="idm140417547304304"></a>
If it helps to have an analogy, consider the <em>Star Wars</em> movies: Episode IV was released in 1977,
Episode V in 1980, and Episode VI in 1983, followed by Episodes I, II, and III in 1999, 2002, and 2005,
respectively, and Episode VII in 2015 [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Ewen2016tz-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Ewen2016tz">80</a>].<sup xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook"><a data-type="noteref" id="idm140417547300656-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#idm140417547300656">ii</a></sup> If you watched the movies in the order
they came out, the order in which you processed the movies is inconsistent with the order of their
narrative. (The episode number is like the event timestamp, and the date when you watched the movie
is the processing time.) As humans, we are able to cope with such discontinuities, but stream
processing algorithms need to be specifically written to accommodate such timing and ordering
issues.</p>

<p>Confusing event time and processing time leads to bad data. For example, say you have a stream
processor that measures the rate of requests (counting the number of requests per second). If you
redeploy the stream processor, it may be shut down for a minute and process the backlog of events
when it comes back up. If you measure the rate based on the processing time, it will look as if
there was a sudden anomalous spike of requests while processing the backlog, when in fact the real
rate of requests was steady (<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_processing_time">Figure&nbsp;11-7</a>).</p>

<figure><div id="fig_stream_processing_time" class="figure">
<img src="https://www.safaribooksonline.com/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1107.png" alt="ddia 1107" width="2880" height="1619" data-mfp-src="/library/view/designing-data-intensive-applications/9781491903063/assets/ddia_1107.png">
<h6><span class="label">Figure 11-7. </span>Windowing by processing time introduces artifacts due to variations in processing rate.</h6>
</div></figure>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Knowing when you’re ready"><div class="sect3" id="idm140417547295296">
<h3>Knowing when you’re ready</h3>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="reasoning about time" data-tertiary="knowing when window is ready" id="idm140417547293952"></a>
<a data-type="indexterm" data-primary="time" data-secondary="reasoning about, in stream processors" data-tertiary="knowing when window is ready" id="idm140417547292560"></a>
<a data-type="indexterm" data-primary="windows (stream processing)" data-secondary="knowing when all events have arrived" id="idm140417547291152"></a>
A tricky problem when defining windows in terms of event time is that you can never be sure when you
have received all of the events for a particular window, or whether there are some events still to
come.</p>

<p>For example, say you’re grouping events into one-minute windows so that you can count the number of
requests per minute. You have counted some number of events with timestamps that fall in the 37th
minute of the hour, and time has moved on; now most of the incoming events fall within the
38th and 39th minutes of the hour. When do you declare that you have finished the window for the 37th
minute, and output its counter value?</p>

<p><a data-type="indexterm" data-primary="straggler events" id="idm140417547288672"></a><a data-type="indexterm" data-primary="events" data-secondary="stragglers" id="idm140417547287968"></a>
You can time out and declare a window ready after you have not seen any new events for a while, but
it could still happen that some events were buffered on another machine somewhere, delayed due to a
network interruption. You need to be able to handle such <em>straggler</em> events that arrive after the
window has already been declared complete. Broadly, you have two options
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2015gh" class="totri-footnote">1</a>]:</p>
<ol>
<li>
<p>Ignore the straggler events, as they are probably a small percentage of events in normal
circumstances. You can track the number of dropped events as a metric, and alert if you start
dropping a significant amount of data.</p>
</li>
<li>
<p>Publish a <em>correction</em>, an updated value for the window with stragglers included. You may also
need to retract the previous output.</p>
</li>

</ol>

<p class="pagebreak-before">In some cases it is possible to use a special message to indicate, “From now on there will be no more
messages with a timestamp earlier than <em>t</em>,” which can be used by consumers to trigger windows
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Akidau2013uz-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2013uz">81</a>]. However, if several producers on different machines are generating events,
each with their own minimum timestamp thresholds, the consumers need to keep track of each producer
individually. Adding and removing producers is trickier in this case.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Whose clock are you using, anyway?"><div class="sect3" id="idm140417547278048">
<h3>Whose clock are you using, anyway?</h3>

<p><a data-type="indexterm" data-primary="time" data-secondary="reasoning about, in stream processors" data-tertiary="timestamp of events" id="idm140417547276768"></a>
<a data-type="indexterm" data-primary="events" data-secondary="timestamp of, in stream processing" id="idm140417547275328"></a>
<a data-type="indexterm" data-primary="timestamps" data-secondary="assigning to events in stream processing" id="idm140417547274208"></a>
<a data-type="indexterm" data-primary="clocks" data-secondary="timestamping events" id="idm140417547273008"></a>
Assigning timestamps to events is even more difficult when events can be buffered at several points
in the system. For example, consider a mobile app that reports events for usage metrics to a server.
The app may be used while the device is offline, in which case it will buffer events locally on the
device and send them to a server when an internet connection is next available (which may be hours
or even days later). To any consumers of this stream, the events will appear as extremely delayed
stragglers.</p>

<p>In this context, the timestamp on the events should really be the time at which the user interaction
occurred, according to the mobile device’s local clock. However, the clock on a user-controlled
device often cannot be trusted, as it may be accidentally or deliberately set to the wrong time (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch08.html#sec_distributed_clock_accuracy">“Clock Synchronization and Accuracy”</a>). The time at which the event was received by the server
(according to the server’s clock) is more likely to be accurate, since the server is under your
control, but less meaningful in terms of describing the user interaction.</p>

<p>To adjust for incorrect device clocks, one approach is to log three timestamps
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Dean2015tn-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Dean2015tn">82</a>]:</p>

<ul>
<li>
<p>The time at which the event occurred, according to the device clock</p>
</li>
<li>
<p>The time at which the event was sent to the server, according to the device clock</p>
</li>
<li>
<p>The time at which the event was received by the server, according to the server clock</p>
</li>
</ul>

<p>By subtracting the second timestamp from the third, you can estimate the offset between the device
clock and the server clock (assuming the network delay is negligible compared to the required
timestamp accuracy). You can then apply that offset to the event timestamp, and thus estimate the
true time at which the event actually occurred (assuming the device clock offset did not change
between the time the event occurred and the time it was sent to the server).</p>

<p>This problem is not unique to stream processing—batch processing suffers from exactly the same
issues of reasoning about time. It is just more noticeable in a streaming context, where we are more
aware of the passage of time.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Types of windows"><div class="sect3" id="idm140417547262016">
<h3>Types of windows</h3>

<p><a data-type="indexterm" data-primary="time" data-secondary="reasoning about, in stream processors" data-tertiary="types of windows" id="idm140417547260816"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="reasoning about time" data-tertiary="types of windows" id="idm140417547259472"></a>
<a data-type="indexterm" data-primary="windows (stream processing)" data-secondary="types of windows" id="idm140417547258096"></a>
Once you know how the timestamp of an event should be determined, the next step is to decide how
windows over time periods should be defined. The window can then be used for aggregations, for
example to count events, or to calculate the average of values within the window. Several types of
windows are in common use [<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2016tb">79</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="AzureWindowing-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#AzureWindowing">83</a>]:</p>
<dl>
<dt>Tumbling window</dt>
<dd>
<p><a data-type="indexterm" data-primary="tumbling windows (stream processing)" data-seealso="windows" id="idm140417547251856"></a>
A tumbling window has a fixed length, and every event belongs to exactly one window. For example,
if you have a 1-minute tumbling window, all the events with timestamps between 10:03:00 and
10:03:59 are grouped into one window, events between 10:04:00 and 10:04:59 into the next window,
and so on. You could implement a 1-minute tumbling window by taking each event timestamp and
rounding it down to the nearest minute to determine the window that it belongs to.</p>
</dd>
<dt>Hopping window</dt>
<dd>
<p><a data-type="indexterm" data-primary="hopping windows (stream processing)" data-seealso="windows" id="idm140417547249104"></a>
A hopping window also has a fixed length, but allows windows to overlap in order to provide some
smoothing. For example, a 5-minute window with a hop size of 1 minute would contain the events
between 10:03:00 and 10:07:59, then the next window would cover events between 10:04:00 and
10:08:59, and so on. You can implement this hopping window by first calculating 1-minute tumbling
windows, and then aggregating over several adjacent windows.</p>
</dd>
<dt>Sliding window</dt>
<dd>
<p><a data-type="indexterm" data-primary="sliding windows (stream processing)" data-seealso="windows" id="idm140417547246368"></a>
A sliding window contains all the events that occur within some interval of each other. For
example, a 5-minute sliding window would cover events at 10:03:39 and 10:08:12, because they are
less than 5 minutes apart (note that tumbling and hopping 5-minute windows would not have put
these two events in the same window, as they use fixed boundaries). A sliding window can be
implemented by keeping a buffer of events sorted by time and removing old events when they expire
from the window.</p>
</dd>
<dt>Session window</dt>
<dd>
<p><a data-type="indexterm" data-primary="session windows (stream processing)" data-seealso="windows" id="idm140417547243584"></a>
Unlike the other window types, a session window has no fixed duration. Instead, it is defined by
grouping together all events for the same user that occur closely together in time, and the window
ends when the user has been inactive for some time (for example, if there have been no events for
30 minutes). Sessionization is a common requirement for website analytics (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_grouping">“GROUP BY”</a>).
<a data-type="indexterm" data-primary="stream processing" data-secondary="reasoning about time" data-startref="ix_streamtime" id="idm140417547241280"></a>
<a data-type="indexterm" data-primary="time" data-secondary="reasoning about, in stream processors" data-startref="ix_timestream" id="idm140417547239904"></a>
<a data-type="indexterm" data-primary="windows (stream processing)" data-startref="ix_windowstream" id="idm140417547238512"></a></p>
</dd>
</dl>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Stream Joins"><div class="sect2" id="sec_stream_joins">
<h2>Stream Joins</h2>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="stream joins" id="ix_strmprjoin"></a>
<a data-type="indexterm" data-primary="joins" data-secondary="stream joins" id="ix_joinstream"></a>
In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a> we discussed how batch jobs can join datasets by key, and how such joins form an
important part of data pipelines. Since stream processing generalizes data pipelines to incremental
processing of unbounded datasets, there is exactly the same need for joins on streams.</p>

<p>However, the fact that new events can appear anytime on a stream makes joins on streams more
challenging than in batch jobs. To understand the situation better, let’s distinguish three
different types of joins: <em>stream-stream</em> joins, <em>stream-table</em> joins, and <em>table-table</em> joins
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="SamzaState-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#SamzaState">84</a>].
In the following sections we’ll illustrate each by example.</p>










<section data-type="sect3" data-pdf-bookmark="Stream-stream join (window join)"><div class="sect3" id="idm140417547227696">
<h3>Stream-stream join (window join)</h3>

<p><a data-type="indexterm" data-primary="windows (stream processing)" data-secondary="stream joins within a window" id="idm140417547226272"></a>
<a data-type="indexterm" data-primary="joins" data-secondary="stream joins" data-tertiary="stream-stream join" id="idm140417547225088"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="stream joins" data-tertiary="stream-stream join" id="idm140417547223712"></a>
Say you have a search feature on your website, and you want to detect recent trends in searched-for
URLs. Every time someone types a search query, you log an event containing the query and the results
returned. Every time someone clicks one of the search results, you log another event
recording the click. In order to calculate the click-through rate for each URL in the search
results, you need to bring together the events for the search action and the click action, which are
connected by having the same session ID. Similar analyses are needed in advertising systems
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Ananthanarayanan2013hw-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Ananthanarayanan2013hw">85</a>].</p>

<p>The click may never come if the user abandons their search, and even if it comes, the time between
the search and the click may be highly variable: in many cases it might be a few seconds, but it
could be as long as days or weeks (if a user runs a search, forgets about that browser tab, and then
returns to the tab and clicks a result sometime later). Due to variable network delays, the click
event may even arrive before the search event. You can choose a suitable window for the join—for
example, you may choose to join a click with a search if they occur at most one hour apart.</p>

<p>Note that embedding the details of the search in the click event is not equivalent to joining the
events: doing so would only tell you about the cases where the user clicked a search result, not
about the searches where the user did not click any of the results. In order to measure search
quality, you need accurate click-through rates, for which you need both the search events and the
click events.</p>

<p><a data-type="indexterm" data-primary="state" data-secondary="maintenance by stream processor in stream-stream joins" id="idm140417547216688"></a>
To implement this type of join, a stream processor needs to maintain <em>state</em>: for example, all the
events that occurred in the last hour, indexed by session ID. Whenever a search event or click event
occurs, it is added to the appropriate index, and the stream processor also checks the other index
to see if another event for the same session ID has already arrived. If there is a matching event,
you emit an event saying which search result was clicked. If the search event expires without you
seeing a matching click event, you emit an event saying which search results were not clicked.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Stream-table join (stream enrichment)"><div class="sect3" id="sec_stream_table_joins">
<h3>Stream-table join (stream enrichment)</h3>

<p><a data-type="indexterm" data-primary="joins" data-secondary="stream joins" data-tertiary="stream-table join" id="idm140417547212816"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="stream joins" data-tertiary="stream-table join" id="idm140417547211216"></a>
<a data-type="indexterm" data-primary="enrichment (stream)" id="idm140417547209840"></a>
In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_join_example">“Example: analysis of user activity events”</a> (<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#fig_batch_join_example">Figure&nbsp;10-2</a>) we saw an example of a batch job joining
two datasets: a set of user activity events and a database of user profiles. It is natural to think
of the user activity events as a stream, and to perform the same join on a continuous basis in a
stream processor: the input is a stream of activity events containing a user ID, and the output is a
stream of activity events in which the user ID has been augmented with profile information about the
user. This process is sometimes known as <em>enriching</em> the activity events with information from the
database.</p>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="accessing external services within job" id="idm140417547206256"></a>
To perform this join, the stream process needs to look at one activity event at a time, look up the
event’s user ID in the database, and add the profile information to the activity event. The database
lookup could be implemented by querying a remote database; however, as discussed in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_join_example">“Example: analysis of user activity events”</a>, such remote queries are likely to be slow and risk overloading the database
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014wm_ch11">75</a>].</p>

<p><a data-type="indexterm" data-primary="locality (data access)" data-secondary="in stream processing" id="idm140417547202960"></a>
Another approach is to load a copy of the database into the stream processor so that it can be
queried locally without a network round-trip. This technique is very similar to the hash joins we
discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#sec_batch_map_joins">“Map-Side Joins”</a>: the local copy of the database might be an in-memory hash
table if it is small enough, or an index on the local disk.</p>

<p><a data-type="indexterm" data-primary="changelogs" data-secondary="in stream joins" id="idm140417547200448"></a>
The difference to batch jobs is that a batch job uses a point-in-time snapshot of the database as
input, whereas a stream processor is long-running, and the contents of the database are likely to
change over time, so the stream processor’s local copy of the database needs to be kept up to date.
This issue can be solved by change data capture: the stream processor can subscribe to a changelog
of the user profile database as well as the stream of activity events. When a profile is created or
modified, the stream processor updates its local copy. Thus, we obtain a join between two streams:
the activity events and the profile updates.</p>

<p><a data-type="indexterm" data-primary="windows (stream processing)" data-secondary="infinite windows for changelogs" id="idm140417547198432"></a>
A stream-table join is actually very similar to a stream-stream join; the biggest difference is that
for the table changelog stream, the join uses a window that reaches back to the “beginning of time”
(a conceptually infinite window), with newer versions of records overwriting older ones. For the
stream input, the join might not maintain a window at all.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Table-table join (materialized view maintenance)"><div class="sect3" id="idm140417547196784">
<h3>Table-table join (materialized view maintenance)</h3>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="stream joins" data-tertiary="table-table join" id="idm140417547195504"></a>
<a data-type="indexterm" data-primary="joins" data-secondary="stream joins" data-tertiary="table-table join" id="idm140417547194128"></a>
<a data-type="indexterm" data-primary="table-table joins" id="idm140417547192752"></a>
<a data-type="indexterm" data-primary="Twitter" data-secondary="constructing home timelines (example)" id="idm140417547191920"></a>
Consider the Twitter timeline example that we discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch01.html#sec_introduction_scalability_load">“Describing Load”</a>. We
said that when a user wants to view their home timeline, it is too expensive to iterate over all the
people the user is following, find their recent tweets, and merge them.</p>

<p>Instead, we want a timeline cache: a kind of per-user “inbox” to which tweets are written as they
are sent, so that reading the timeline is a single lookup. Materializing and maintaining this cache
requires the following event processing:</p>

<ul>
<li>
<p>When user <em>u</em> sends a new tweet, it is added to the timeline of every user who is following <em>u</em>.</p>
</li>
<li>
<p>When a user deletes a tweet, it is removed from all users’ timelines.</p>
</li>
<li>
<p>When user <em>u</em><sub>1</sub> starts following user <em>u</em><sub>2</sub>, recent tweets by <em>u</em><sub>2</sub> are added to
<em>u</em><sub>1</sub>’s <span class="keep-together">timeline.</span></p>
</li>
<li>
<p>When user <em>u</em><sub>1</sub> unfollows user <em>u</em><sub>2</sub>, tweets by <em>u</em><sub>2</sub> are removed from <em>u</em><sub>1</sub>’s
timeline.</p>
</li>
</ul>

<p>To implement this cache maintenance in a stream processor, you need streams of events for tweets
(sending and deleting) and for follow relationships (following and unfollowing). The stream process
needs to maintain a database containing the set of followers for each user so that it knows which
timelines need to be updated when a new tweet arrives
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="SamzaNewsfeed-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#SamzaNewsfeed">86</a>].</p>

<p><a data-type="indexterm" data-primary="materialization" data-secondary="materialized views" data-tertiary="maintaining, using stream processing" id="idm140417547174000"></a>
Another way of looking at this stream process is that it maintains a materialized view for a query
that joins two tables (tweets and follows), something like the following:</p>

<pre data-type="programlisting" data-code-language="sql"><code class="k">SELECT</code> <code class="n">follows</code><code class="p">.</code><code class="n">follower_id</code> <code class="k">AS</code> <code class="n">timeline_id</code><code class="p">,</code>
  <code class="n">array_agg</code><code class="p">(</code><code class="n">tweets</code><code class="p">.</code><code class="o">*</code> <code class="k">ORDER</code> <code class="k">BY</code> <code class="n">tweets</code><code class="p">.</code><code class="k">timestamp</code> <code class="k">DESC</code><code class="p">)</code>
<code class="k">FROM</code> <code class="n">tweets</code>
<code class="k">JOIN</code> <code class="n">follows</code> <code class="k">ON</code> <code class="n">follows</code><code class="p">.</code><code class="n">followee_id</code> <code class="o">=</code> <code class="n">tweets</code><code class="p">.</code><code class="n">sender_id</code>
<code class="k">GROUP</code> <code class="k">BY</code> <code class="n">follows</code><code class="p">.</code><code class="n">follower_id</code></pre>

<p>The join of the streams corresponds directly to the join of the tables in that query. The timelines
are effectively a cache of the result of this query, updated every time the underlying tables
change.<sup xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook"><a data-type="noteref" id="idm140417547170144-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#idm140417547170144">iii</a></sup></p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Time-dependence of joins"><div class="sect3" id="sec_stream_join_time">
<h3>Time-dependence of joins</h3>

<p><a data-type="indexterm" data-primary="joins" data-secondary="stream joins" data-tertiary="time-dependence of" id="idm140417547125920"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="stream joins" data-tertiary="time-dependence of" id="idm140417547124544"></a>
<a data-type="indexterm" data-primary="time" data-secondary="time-dependence in stream joins" id="idm140417547123168"></a>
The three types of joins described here (stream-stream, stream-table, and table-table) have a lot in
common: they all require the stream processor to maintain some state (search and click events, user
profiles, or follower list) based on one join input, and query that state on messages from the other
join input.</p>

<p>The order of the events that maintain the state is important (it matters whether you first follow
and then unfollow, or the other way round). In a partitioned log, the ordering of events within a
single partition is preserved, but there is typically no ordering guarantee across different streams
or partitions.</p>

<p>This raises a question: if events on different streams happen around a similar time, in which order
are they processed? In the stream-table join example, if a user updates their profile, which
activity events are joined with the old profile (processed before the profile update), and which are
joined with the new profile (processed after the profile update)? Put another way: if state changes
over time, and you join with some state, what point in time do you use for the join
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Jagadish1995ee">45</a>]?</p>

<p>Such time dependence can occur in many places. For example, if you sell things, you need to apply
the right tax rate to invoices, which depends on the country or state, the type of product, and the
date of sale (since tax rates change from time to time). When joining sales to a table of tax rates,
you probably want to join with the tax rate at the time of the sale, which may be different from the
current tax rate if you are reprocessing historical data.</p>

<p>If the ordering of events across streams is undetermined, the join becomes nondeterministic
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kirwin2014vm-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kirwin2014vm">87</a>], which means you cannot
rerun the same job on the same input and necessarily get the same result: the events on the input
streams may be interleaved in a different way when you run the job again.</p>

<p><a data-type="indexterm" data-primary="data warehousing" data-secondary="slowly changing dimension (SCD)" id="idm140417547115264"></a>
<a data-type="indexterm" data-primary="slowly changing dimension (data warehouses)" id="idm140417547113968"></a>
<a data-type="indexterm" data-primary="SCD (slowly changing dimension)" id="idm140417547113104"></a>
<a data-type="indexterm" data-primary="deterministic operations" data-secondary="joins" id="idm140417547112304"></a>
In data warehouses, this issue is known as a <em>slowly changing dimension</em> (SCD), and it is often
addressed by using a unique identifier for a particular version of the joined record: for example,
every time the tax rate changes, it is given a new identifier, and the invoice includes the
identifier for the tax rate at the time of sale
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Helland2005tc_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2005tc_ch11">88</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kimball2013tb_ch11-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kimball2013tb_ch11">89</a>]. This change makes the join
deterministic, but has the consequence that log compaction is not possible, since all versions of
the records in the table need to be retained.
<a data-type="indexterm" data-primary="joins" data-secondary="stream joins" data-startref="ix_joinstream" id="idm140417547106832"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="stream joins" data-startref="ix_strmprjoin" id="idm140417547105520"></a></p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Fault Tolerance"><div class="sect2" id="sec_stream_fault_tolerance">
<h2>Fault Tolerance</h2>

<p><a data-type="indexterm" data-primary="fault tolerance" data-secondary="in stream processing" id="ix_faultstrm"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="fault tolerance" id="ix_strmprfault"></a>
In the final section of this chapter, let’s consider how stream processors can tolerate faults. We
saw in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a> that batch processing frameworks can tolerate faults fairly easily: if a task in
a MapReduce job fails, it can simply be started again on another machine, and the output of the
failed task is discarded. This transparent retry is possible because input files are immutable, each
task writes its output to a separate file on HDFS, and output is only made visible when a task
completes successfully.</p>

<p><a data-type="indexterm" data-primary="exactly-once semantics" id="idm140417547098272"></a>
<a data-type="indexterm" data-primary="effectively-once semantics" data-seealso="exactly-once semantics" id="idm140417547097216"></a>
<a data-type="indexterm" data-primary="messages" data-secondary="exactly-once semantics" id="idm140417547096144"></a>
In particular, the batch approach to fault tolerance ensures that the output of the batch job is the
same as if nothing had gone wrong, even if in fact some tasks did fail. It appears as though every
input record was processed exactly once—no records are skipped, and none are processed twice.
Although restarting tasks means that records may in fact be processed multiple times, the visible
effect in the output is as if they had only been processed once. This principle is known as
<em>exactly-once semantics</em>, although <em>effectively-once</em> would be a more descriptive term
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Klang2016mw-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Klang2016mw">90</a>].</p>

<p>The same issue of fault tolerance arises in stream processing, but it is less straightforward to
handle: waiting until a task is finished before making its output visible is not an option, because
a stream is infinite and so you can never finish processing it.</p>










<section data-type="sect3" data-pdf-bookmark="Microbatching and checkpointing"><div class="sect3" id="idm140417547090720">
<h3>Microbatching and checkpointing</h3>

<p><a data-type="indexterm" data-primary="fault tolerance" data-secondary="in stream processing" data-tertiary="microbatching and checkpointing" id="idm140417547089312"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="fault tolerance" data-tertiary="microbatching and checkpointing" id="idm140417547087744"></a>
<a data-type="indexterm" data-primary="microbatching" id="idm140417547086352"></a>
<a data-type="indexterm" data-primary="Spark (processing framework)" data-secondary="Spark Streaming" data-tertiary="microbatching" id="idm140417547085520"></a>
One solution is to break the stream into small blocks, and treat each block like a miniature batch
process. This approach is called <em>microbatching</em>, and it is used in Spark Streaming
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Zaharia2012wa-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Zaharia2012wa">91</a>]. The
batch size is typically around one second, which is the result of a performance compromise: smaller
batches incur greater scheduling and coordination overhead, while larger batches mean a longer delay
before results of the stream processor become visible.</p>

<p><a data-type="indexterm" data-primary="time" data-secondary="reasoning about, in stream processors" data-tertiary="event time versus processing time" id="idm140417547081056"></a>
<a data-type="indexterm" data-primary="events" data-secondary="event time versus processing time" id="idm140417547079648"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="reasoning about time" data-tertiary="event time versus processing time" id="idm140417547078528"></a>
<a data-type="indexterm" data-primary="tumbling windows (stream processing)" data-secondary="in microbatching" id="idm140417547077136"></a>
Microbatching also implicitly provides a tumbling window equal to the batch size (windowed by
processing time, not event timestamps); any jobs that require larger windows need to explicitly
carry over state from one microbatch to the next.</p>

<p><a data-type="indexterm" data-primary="checkpointing" data-secondary="in stream processors" id="idm140417547075504"></a>
<a data-type="indexterm" data-primary="Flink (processing framework)" data-secondary="fault tolerance" id="idm140417547074400"></a>
A variant approach, used in Apache Flink, is to periodically generate rolling checkpoints of state and
write them to durable storage
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Tzoumas2015tt-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Tzoumas2015tt">92</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Carbone2015wh-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Carbone2015wh">93</a>].
If a stream operator crashes, it can restart from its most recent checkpoint and discard any output
generated between the last checkpoint and the crash. The checkpoints are triggered by barriers in
the message stream, similar to the boundaries between microbatches, but without forcing a particular
window size.</p>

<p><a data-type="indexterm" data-primary="stream processing" data-secondary="accessing external services within job" id="idm140417547068448"></a>
Within the confines of the stream processing framework, the microbatching and checkpointing
approaches provide the same exactly-once semantics as batch processing. However, as soon as output
leaves the stream processor (for example, by writing to a database, sending messages to an external
message broker, or sending emails), the framework is no longer able to discard the output of a
failed batch. In this case, restarting a failed task causes the external side effect to happen
twice, and microbatching or checkpointing alone is not sufficient to prevent this problem.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Atomic commit revisited"><div class="sect3" id="sec_stream_atomic_commit">
<h3>Atomic commit revisited</h3>

<p><a data-type="indexterm" data-primary="fault tolerance" data-secondary="in stream processing" data-tertiary="atomic commit" id="idm140417547065056"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="fault tolerance" data-tertiary="atomic commit" id="idm140417547063680"></a>
<a data-type="indexterm" data-primary="atomicity (transactions)" data-secondary="atomic commit" data-tertiary="in stream processing" id="idm140417547062304"></a>
In order to give the appearance of exactly-once processing in the presence of faults, we need to
ensure that all outputs and side effects of processing an event take effect <em>if and only if</em> the
processing is successful. Those effects include any messages sent to downstream operators or
external messaging systems (including email or push notifications), any database writes, any changes
to operator state, and any acknowledgment of input messages (including moving the consumer offset
forward in a log-based message broker).</p>

<p>Those things either all need to happen atomically, or none of them must happen, but they should not
go out of sync with each other. If this approach sounds familiar, it is because we discussed it in
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#sec_consistency_exactly_once">“Exactly-once message processing”</a> in the context of distributed transactions and two-phase commit.</p>

<p><a data-type="indexterm" data-primary="Google" data-secondary="Cloud Dataflow (stream processor)" id="idm140417547058256"></a>
<a data-type="indexterm" data-primary="VoltDB (database)" data-secondary="transactions in stream processing" id="idm140417547056912"></a>
<a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="transaction support" id="idm140417547055792"></a>
<a data-type="indexterm" data-primary="database-internal distributed transactions" id="idm140417547054688"></a>
In <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch09.html#ch_consistency">Chapter&nbsp;9</a> we discussed the problems in the traditional implementations of distributed
transactions, such as XA. However, in more restricted environments it is possible to implement such
an atomic commit facility efficiently. This approach is used in Google Cloud Dataflow
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2013uz">81</a>,
<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Tzoumas2015tt">92</a>] and VoltDB
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Betts2015ub-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Betts2015ub">94</a>],
and there are plans to add similar features to Apache Kafka
[<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Junqueira2016vv-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Junqueira2016vv">95</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Gustafson2016na-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gustafson2016na">96</a>]. Unlike XA, these implementations do not attempt to provide transactions across heterogeneous technologies, but instead keep them internal by managing both state changes and messaging within the stream processing framework. The overhead of the transaction protocol can be amortized by processing several input
messages within a single transaction.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Idempotence"><div class="sect3" id="sec_stream_idempotence">
<h3>Idempotence</h3>

<p><a data-type="indexterm" data-primary="idempotence" id="idm140417547042592"></a>
<a data-type="indexterm" data-primary="fault tolerance" data-secondary="in stream processing" data-tertiary="idempotence" id="idm140417547041760"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="fault tolerance" data-tertiary="idempotence" id="idm140417547040384"></a>
Our goal is to discard the partial output of any failed tasks so that they can be safely retried
without taking effect twice. Distributed transactions are one way of achieving that goal, but
another way is to rely on <em>idempotence</em> [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Helland2012id-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2012id">97</a>].</p>

<p>An idempotent operation is one that you can perform multiple times, and it has the same effect as if
you performed it only once. For example, setting a key in a key-value store to some fixed value is
idempotent (writing the value again simply overwrites the value with an identical value), whereas
incrementing a counter is not idempotent (performing the increment again means the value is
incremented twice).</p>

<p><a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="message offsets" id="idm140417547034416"></a>
Even if an operation is not naturally idempotent, it can often be made idempotent with a bit of
extra metadata. For example, when consuming messages from Kafka, every message has a persistent,
monotonically increasing offset. When writing a value to an external database, you can include the
offset of the message that triggered the last write with the value. Thus, you can tell whether an
update has already been applied, and avoid performing the same update again.</p>

<p><a data-type="indexterm" data-primary="deterministic operations" data-secondary="and idempotence" id="idm140417547032576"></a>
<a data-type="indexterm" data-primary="Storm (stream processor)" data-secondary="Trident state handling" id="idm140417547031408"></a>
The state handling in Storm’s Trident is based on a similar idea
[<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#StormDocs">78</a>]. Relying on idempotence implies several
assumptions: restarting a failed task must replay the same messages in the same order (a log-based
message broker does this), the processing must be deterministic, and no other node may concurrently
update the same value [<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Kreps2014zt-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014zt">98</a>, <a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Elnozahy2002fp-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Elnozahy2002fp">99</a>].</p>

<p><a data-type="indexterm" data-primary="fencing (preventing split brain)" data-secondary="stream processors writing to databases" id="idm140417546995456"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="accessing external services within job" id="idm140417546994272"></a>
When failing over from one processing node to another, fencing may be required (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch08.html#sec_distributed_lock_fencing">“The leader and the lock”</a>) to prevent interference from a node that is thought to be dead but
is actually alive. Despite all those caveats, idempotent operations can be an effective way of
achieving exactly-once semantics with only a small overhead.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Rebuilding state after a failure"><div class="sect3" id="sec_stream_state_fault_tolerance">
<h3>Rebuilding state after a failure</h3>

<p><a data-type="indexterm" data-primary="state" data-secondary="rebuilding after stream processor failure" id="idm140417546990384"></a>
<a data-type="indexterm" data-primary="fault tolerance" data-secondary="in stream processing" data-tertiary="rebuilding state after a failure" id="idm140417546989248"></a>
<a data-type="indexterm" data-primary="stream processing" data-secondary="fault tolerance" data-tertiary="rebuilding state after a failure" id="idm140417546987808"></a>
Any stream process that requires state—for example, any windowed aggregations (such as counters,
averages, and histograms) and any tables and indexes used for joins—must ensure that this state
can be recovered after a failure.</p>

<p><a data-type="indexterm" data-primary="locality (data access)" data-secondary="in stream processing" id="idm140417546985920"></a>
One option is to keep the state in a remote datastore and replicate it, although having to query a
remote database for each individual message can be slow, as discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_table_joins">“Stream-table join (stream enrichment)”</a>.
An alternative is to keep state local to the stream processor, and replicate it periodically. Then,
when the stream processor is recovering from a failure, the new task can read the replicated state
and resume processing without data loss.</p>

<p><a data-type="indexterm" data-primary="changelogs" data-secondary="for operator state" id="idm140417546983312"></a>
<a data-type="indexterm" data-primary="Flink (processing framework)" data-secondary="fault tolerance" id="idm140417546981872"></a>
<a data-type="indexterm" data-primary="HDFS (Hadoop Distributed File System)" data-secondary="use by Flink" id="idm140417546980752"></a>
<a data-type="indexterm" data-primary="Samza (stream processor)" data-secondary="fault tolerance" id="idm140417546979632"></a>
<a data-type="indexterm" data-primary="Kafka (messaging)" data-secondary="Kafka Streams (stream processor)" data-tertiary="fault tolerance" id="idm140417546978512"></a>
<a data-type="indexterm" data-primary="VoltDB (database)" data-secondary="statement-based replication" id="idm140417546977120"></a>
<a data-type="indexterm" data-primary="compaction" data-secondary="of changelogs" data-tertiary="for stream operator state" id="idm140417546976000"></a>
<a data-type="indexterm" data-primary="logs (data structure)" data-secondary="compaction" data-tertiary="for stream operator state" id="idm140417546974608"></a>
For example, Flink periodically captures snapshots of operator state and writes them to durable
storage such as HDFS [<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Tzoumas2015tt">92</a>,
<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Carbone2015wh">93</a>]; Samza and Kafka Streams replicate state
changes by sending them to a dedicated Kafka topic with log compaction, similar to change data
capture [<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#SamzaState">84</a>,
<a xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="noteref" id="Warski2016tm-marker" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Warski2016tm">100</a>].
VoltDB replicates state by redundantly processing each input message on several nodes (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch07.html#sec_transactions_serial">“Actual Serial Execution”</a>).</p>

<p>In some cases, it may not even be necessary to replicate the state, because it can be rebuilt from
the input streams. For example, if the state consists of aggregations over a fairly short window, it
may be fast enough to simply replay the input events corresponding to that window. If the state is a
local replica of a database, maintained by change data capture, the database can also be rebuilt
from the log-compacted change stream (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#sec_stream_log_compaction">“Log compaction”</a>).</p>

<p>However, all of these trade-offs depend on the performance characteristics of the underlying
infrastructure: in some systems, network delay may be lower than disk access latency, and network
bandwidth may be comparable to disk bandwidth. There is no universally ideal trade-off for all
situations, and the merits of local versus remote state may also shift as storage and networking
technologies evolve.
<a data-type="indexterm" data-primary="stream processing" data-secondary="fault tolerance" data-startref="ix_strmprfault" id="idm140417546965072"></a>
<a data-type="indexterm" data-primary="fault tolerance" data-secondary="in stream processing" data-startref="ix_faultstrm" id="idm140417546963696"></a></p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm140417547468256">
<h1>Summary</h1>

<p>In this chapter we have discussed event streams, what purposes they serve, and how to process them.
In some ways, stream processing is very much like the batch processing we discussed in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html#ch_batch">Chapter&nbsp;10</a>,
but done continuously on unbounded (never-ending) streams rather than on a fixed-size input. From
this perspective, message brokers and event logs serve as the streaming equivalent of a filesystem.</p>

<p>We spent some time comparing two types of message brokers:</p>
<dl>
<dt>AMQP/JMS-style message broker</dt>
<dd>
<p>The broker assigns individual messages to consumers, and consumers acknowledge individual messages
when they have been successfully processed. Messages are deleted from the broker once they have
been acknowledged. This approach is appropriate as an asynchronous form of RPC (see also
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch04.html#sec_encoding_dataflow_msg">“Message-Passing Dataflow”</a>), for example in a task queue, where the exact order of message
processing is not important and where there is no need to go back and read old messages again
after they have been processed.</p>
</dd>
<dt>Log-based message broker</dt>
<dd>
<p>The broker assigns all messages in a partition to the same consumer node, and always delivers
messages in the same order. Parallelism is achieved through partitioning, and consumers track
their progress by checkpointing the offset of the last message they have processed. The broker
retains messages on disk, so it is possible to jump back and reread old messages if necessary.</p>
</dd>
</dl>

<p>The log-based approach has similarities to the replication logs found in databases (see
<a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch05.html#ch_replication">Chapter&nbsp;5</a>) and log-structured storage engines (see <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch03.html#ch_storage">Chapter&nbsp;3</a>). We saw that this
approach is especially appropriate for stream processing systems that consume input streams and
generate derived state or derived output streams.</p>

<p>In terms of where streams come from, we discussed several possibilities: user activity events,
sensors providing periodic readings, and data feeds (e.g., market data in finance) are naturally
represented as streams. We saw that it can also be useful to think of the writes to a database as a
stream: we can capture the changelog—i.e., the history of all changes made to a database—either
implicitly through change data capture or explicitly through event sourcing. Log compaction allows
the stream to retain a full copy of the contents of a database.</p>

<p>Representing databases as streams opens up powerful opportunities for integrating systems. You can
keep derived data systems such as search indexes, caches, and analytics systems continually
up to date by consuming the log of changes and applying them to the derived system. You can even
build fresh views onto existing data by starting from scratch and consuming the log of changes from
the beginning all the way to the present.</p>

<p>The facilities for maintaining state as streams and replaying messages are also the basis for the
techniques that enable stream joins and fault tolerance in various stream processing frameworks.
We discussed several purposes of stream processing, including searching for event patterns (complex
event processing), computing windowed aggregations (stream analytics), and keeping derived data
systems up to date (materialized views).</p>

<p>We then discussed the difficulties of reasoning about time in a stream processor, including the
distinction between processing time and event timestamps, and the problem of dealing with straggler
events that arrive after you thought your window was complete.</p>

<p>We distinguished three types of joins that may appear in stream processes:</p>
<dl>
<dt>Stream-stream joins</dt>
<dd>
<p>Both input streams consist of activity events, and the join operator searches for related events
that occur within some window of time. For example, it may match two actions taken by the same
user within 30 minutes of each other.
<a data-type="indexterm" data-primary="self-joins" id="idm140417546946256"></a> The two join inputs may in fact be the same stream (a <em>self-join</em>) if you want
to find related events within that one stream.</p>
</dd>
<dt>Stream-table joins</dt>
<dd>
<p>One input stream consists of activity events, while the other is a database changelog. The
changelog keeps a local copy of the database up to date. For each activity event, the join
operator queries the database and outputs an enriched activity event.</p>
</dd>
<dt>Table-table joins</dt>
<dd>
<p>Both input streams are database changelogs. In this case, every change on one side is joined with
the latest state of the other side. The result is a stream of changes to the materialized view of
the join between the two tables.</p>
</dd>
</dl>

<p>Finally, we discussed techniques for achieving fault tolerance and exactly-once semantics in a
stream processor. As with batch processing, we need to discard the partial output of any failed
tasks. However, since a stream process is long-running and produces output continuously, we can’t
simply discard all output. Instead, a finer-grained recovery mechanism can be used, based on
microbatching, checkpointing, transactions, or idempotent writes.
<a data-type="indexterm" data-primary="stream processing" data-startref="ix_streamproc" id="idm140417546940688"></a></p>
</div></section>







<div data-type="footnotes"><h5>Footnotes</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm140417547924592"><sup><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#idm140417547924592-marker" class="totri-footnote">i</a></sup> It’s possible to create a load balancing
scheme in which two consumers share the work of processing a partition by having both read the
full set of messages, but one of them only considers messages with even-numbered offsets while the other
deals with the odd-numbered offsets. Alternatively, you could spread message processing over a thread pool, but
that approach complicates consumer offset management. In general, single-threaded processing of a
partition is preferable, and parallelism can be increased by using more partitions.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm140417547300656"><sup><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#idm140417547300656-marker">ii</a></sup> Thank you to Kostas Kloudas from
the Flink community for coming up with this analogy.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="idm140417547170144"><sup><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#idm140417547170144-marker">iii</a></sup> If you regard a stream as the derivative
of a table, as in <a data-type="xref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#fig_stream_integral">Figure&nbsp;11-6</a>, and regard a join as a product
of two tables <em>u·v</em>, something interesting happens: the stream of changes to the
materialized join follows the product rule
(<em>u·v</em>)′&nbsp;=&nbsp;<em>u</em>′<em>v</em>&nbsp;+&nbsp;<em>uv</em>′.
In words: any change of tweets is joined with the current followers, and any change of followers is
joined with the current tweets [<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hyde2016">49</a>,
<a data-type="noteref" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gupta1999uz">50</a>].</p></div><div data-type="footnotes"><h5>References</h5><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Akidau2015gh">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2015gh-marker" class="totri-footnote">1</a>] Tyler Akidau, Robert Bradshaw, Craig Chambers, et al.:
“<a href="http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf">The Dataflow Model: A Practical Approach to
Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing</a>,”
<em>Proceedings of the VLDB Endowment</em>, volume 8, number 12, pages 1792–1803, August 2015.
<a href="http://dx.doi.org/10.14778/2824032.2824076">doi:10.14778/2824032.2824076</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Abelson1996ut">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Abelson1996ut-marker" class="totri-footnote">2</a>] Harold Abelson, Gerald Jay Sussman, and Julie Sussman:
<a href="https://mitpress.mit.edu/sicp/"><em>Structure and Interpretation of Computer Programs</em></a>,
2nd edition. MIT Press, 1996. ISBN: 978-0-262-51087-5, available online at <em>mitpress.mit.edu</em></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Eugster2003ih_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Eugster2003ih_ch11-marker" class="totri-footnote">3</a>] Patrick Th. Eugster, Pascal A. Felber,
Rachid Guerraoui, and Anne-Marie Kermarrec:
“<a href="http://www.cs.ru.nl/~pieter/oss/manyfaces.pdf">The Many Faces of Publish/Subscribe</a>,”
<em>ACM Computing Surveys</em>, volume 35, number 2, pages 114–131, June 2003.
<a href="http://dx.doi.org/10.1145/857076.857078">doi:10.1145/857076.857078</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Hellerstein2005tj">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hellerstein2005tj-marker" class="totri-footnote">4</a>] Joseph M. Hellerstein and Michael Stonebraker:
<a href="http://redbook.cs.berkeley.edu/"><em>Readings in Database Systems</em></a>, 4th edition.
MIT Press, 2005. ISBN: 978-0-262-69314-1, available online at <em>redbook.cs.berkeley.edu</em></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Carney2002um">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Carney2002um-marker" class="totri-footnote">5</a>] Don Carney, Uğur Çetintemel, Mitch Cherniack, et al.:
“<a href="http://www.vldb.org/conf/2002/S07P02.pdf">Monitoring Streams – A New Class of Data
Management Applications</a>,” at <em>28th International Conference on Very Large Data Bases</em>
(VLDB), August 2002.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Sackman2016ws">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Sackman2016ws-marker" class="totri-footnote">6</a>] Matthew Sackman:
“<a href="http://www.lshift.net/blog/2016/05/05/pushing-back/">Pushing Back</a>,”
<em>lshift.net</em>, May 5, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Marti2015ww">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Marti2015ww-marker" class="totri-footnote">7</a>] Vicent Martí:
“<a href="http://githubengineering.com/brubeck/">Brubeck, a statsd-Compatible Metrics
Aggregator</a>,” <em>githubengineering.com</em>, June 15, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Lowenberger2009ac">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Lowenberger2009ac-marker" class="totri-footnote">8</a>] Seth Lowenberger:
“<a href="http://www.nasdaqtrader.com/content/technicalsupport/specifications/dataproducts/moldudp64.pdf">MoldUDP64
Protocol Specification V 1.00</a>,” <em>nasdaqtrader.com</em>, July 2009.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Hintjens2013wf">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hintjens2013wf-marker" class="totri-footnote">9</a>] Pieter Hintjens:
<a href="http://zguide.zeromq.org/page:all"><em>ZeroMQ – The Guide</em></a>. O’Reilly Media, 2013.
ISBN: 978-1-449-33404-8</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Malpass2011wb">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Malpass2011wb-marker">10</a>] Ian Malpass:
“<a href="https://codeascraft.com/2011/02/15/measure-anything-measure-everything/">Measure
Anything, Measure Everything</a>,” <em>codeascraft.com</em>, February 15, 2011.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Plaetinck2016ta">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Plaetinck2016ta-marker">11</a>] Dieter Plaetinck:
“<a href="https://blog.raintank.io/25-graphite-grafana-and-statsd-gotchas/">25 Graphite, Grafana
and statsd Gotchas</a>,” <em>blog.raintank.io</em>, March 3, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Lindsay2007tl">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Lindsay2007tl-marker">12</a>] Jeff Lindsay:
“<a href="http://progrium.com/blog/2007/05/03/web-hooks-to-revolutionize-the-web/">Web Hooks to
Revolutionize the Web</a>,” <em>progrium.com</em>, May 3, 2007.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Gray1995tn">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gray1995tn-marker">13</a>] Jim N. Gray:
“<a href="http://research.microsoft.com/pubs/69641/tr-95-56.pdf">Queues Are Databases</a>,”
Microsoft Research Technical Report MSR-TR-95-56, December 1995.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Hapner2013uk">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hapner2013uk-marker">14</a>] Mark Hapner, Rich Burridge, Rahul Sharma, et al.:
“<a href="https://jcp.org/en/jsr/detail?id=343">JSR-343 Java Message Service (JMS) 2.0
Specification</a>,” <em>jms-spec.java.net</em>, March 2013.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Aiyagari2008th">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Aiyagari2008th-marker">15</a>] Sanjay Aiyagari, Matthew Arrott, Mark Atwell, et al.:
“<a href="http://www.rabbitmq.com/resources/specs/amqp0-9-1.pdf">AMQP: Advanced Message Queuing
Protocol Specification</a>,” Version 0-9-1, November 2008.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="GooglePubSub">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#GooglePubSub-marker">16</a>] “<a href="https://cloud.google.com/pubsub/architecture">Google
Cloud Pub/Sub: A Google-Scale Messaging Service</a>,” <em>cloud.google.com</em>, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kafka2015">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kafka2015-marker">17</a>] “<a href="http://kafka.apache.org/documentation.html">Apache
Kafka 0.9 Documentation</a>,” <em>kafka.apache.org</em>, November 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kreps2011wl">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2011wl-marker">18</a>] Jay Kreps, Neha Narkhede, and Jun Rao:
“<a href="http://www.longyu23.com/doc/Kafka.pdf">Kafka:
A Distributed Messaging System for Log Processing</a>,” at <em>6th International Workshop on
Networking Meets Databases</em> (NetDB), June 2011.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kinesis2016">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kinesis2016-marker">19</a>] “<a href="http://docs.aws.amazon.com/streams/latest/dev/introduction.html">Amazon
Kinesis Streams Developer Guide</a>,” <em>docs.aws.amazon.com</em>, April 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Stewart2015vb">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Stewart2015vb-marker">20</a>] Leigh Stewart and Sijie Guo:
“<a href="https://blog.twitter.com/2015/building-distributedlog-twitter-s-high-performance-replicated-log-service">Building
DistributedLog: Twitter’s High-Performance Replicated Log Service</a>,” <em>blog.twitter.com</em>,
September 16, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="DistributedLog">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#DistributedLog-marker">21</a>] “<a href="http://distributedlog.incubator.apache.org/docs/latest/">DistributedLog
Documentation</a>,” Twitter, Inc., <em>distributedlog.io</em>, May 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kreps2014wz">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014wz-marker">22</a>] Jay Kreps:
“<a href="https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines">Benchmarking
Apache Kafka: 2 Million Writes Per Second (On Three Cheap Machines)</a>,” <em>engineering.linkedin.com</em>,
April 27, 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Paramasivam2015um">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Paramasivam2015um-marker">23</a>] Kartik Paramasivam:
“<a href="https://engineering.linkedin.com/apache-kafka/how-we_re-improving-and-advancing-kafka-linkedin">How
We’re Improving and Advancing Kafka at LinkedIn</a>,” <em>engineering.linkedin.com</em>, September 2, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kreps2013vs_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2013vs_ch11-marker">24</a>] Jay Kreps:
“<a href="http://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying">The
Log: What Every Software Engineer Should Know About Real-Time Data’s Unifying Abstraction</a>,”
<em>engineering.linkedin.com</em>, December 16, 2013.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Das2012uf_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Das2012uf_ch11-marker">25</a>] Shirshanka Das, Chavdar Botev, Kapil Surlaker,
et al.: “<a href="http://www.socc2012.org/s18-das.pdf">All Aboard the Databus!</a>,” at <em>3rd ACM
Symposium on Cloud Computing</em> (SoCC), October 2012.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Sharma2015te_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Sharma2015te_ch11-marker">26</a>] Yogeshwer Sharma, Philippe Ajoux, Petchean Ang, et al.:
“<a href="https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-sharma.pdf">Wormhole:
Reliable Pub-Sub to Support Geo-Replicated Internet Services</a>,” at <em>12th USENIX Symposium on
Networked Systems Design and Implementation</em> (NSDI), May 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Narayan2010wq">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Narayan2010wq-marker">27</a>] P. P. S. Narayan:
“<a href="http://web.archive.org/web/20160801221400/https://developer.yahoo.com/blogs/ydn/sherpa-7992.html">Sherpa Update</a>,”
<em>developer.yahoo.com</em>, June 8, .</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kleppmann2015vl">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kleppmann2015vl-marker">28</a>] Martin Kleppmann:
“<a href="http://martin.kleppmann.com/2015/04/23/bottled-water-real-time-postgresql-kafka.html">Bottled
Water: Real-Time Integration of PostgreSQL and Kafka</a>,” <em>martin.kleppmann.com</em>, April 23, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Osheroff2015uy">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Osheroff2015uy-marker">29</a>] Ben Osheroff:
“<a href="https://developer.zendesk.com/blog/introducing-maxwell-a-mysql-to-kafka-binlog-processor">Introducing
Maxwell, a mysql-to-kafka Binlog Processor</a>,” <em>developer.zendesk.com</em>, August 20, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Debezium2016">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Debezium2016-marker">30</a>] Randall Hauch:
“<a href="http://debezium.io/blog/2016/06/10/Debezium-0/">Debezium 0.2.1 Released</a>,” <em>debezium.io</em>,
June 10, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Shankar2016ug">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Shankar2016ug-marker">31</a>] Prem Santosh Udaya Shankar:
“<a href="https://engineeringblog.yelp.com/2016/08/streaming-mysql-tables-in-real-time-to-kafka.html">Streaming
MySQL Tables in Real-Time to Kafka</a>,” <em>engineeringblog.yelp.com</em>, August 1, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Mongoriver2016">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Mongoriver2016-marker">32</a>] “<a href="https://github.com/stripe/mongoriver">Mongoriver</a>,”
Stripe, Inc., <em>github.com</em>, September 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Harvey2015vl">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Harvey2015vl-marker">33</a>] Dan Harvey:
“<a href="http://www.slideshare.net/danharvey/change-data-capture-with-mongodb-and-kafka">Change
Data Capture with Mongo + Kafka</a>,” at <em>Hadoop Users Group UK</em>, August 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="GoldenGate2013ub">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#GoldenGate2013ub-marker">34</a>] “<a href="http://www.oracle.com/us/products/middleware/data-integration/oracle-goldengate-realtime-access-2031152.pdf">Oracle
GoldenGate 12c: Real-Time Access to Real-Time Information</a>,” Oracle White Paper, March 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="GoldenGate2012ct">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#GoldenGate2012ct-marker">35</a>] “<a href="https://www.youtube.com/watch?v=6H9NibIiPQE">Oracle
GoldenGate Fundamentals: How Oracle GoldenGate Works</a>,” Oracle Corporation, <em>youtube.com</em>, November 2012.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Akhmechet2015tq">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akhmechet2015tq-marker">36</a>] Slava Akhmechet:
“<a href="http://rethinkdb.com/blog/realtime-web/">Advancing the Realtime Web</a>,” <em>rethinkdb.com</em>,
January 27, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Firebase2016">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Firebase2016-marker">37</a>] “<a href="https://firebase.google.com/docs/database/">Firebase
Realtime Database Documentation</a>,” Google, Inc., <em>firebase.google.com</em>, May 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="CouchDB2014_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#CouchDB2014_ch11-marker">38</a>] “<a href="http://docs.couchdb.org/en/latest/">Apache
CouchDB 1.6 Documentation</a>,” <em>docs.couchdb.org</em>, 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="DeBergalis2013vd">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#DeBergalis2013vd-marker">39</a>] Matt DeBergalis:
“<a href="http://info.meteor.com/blog/meteor-070-scalable-database-queries-using-mongodb-oplog-instead-of-poll-and-diff">Meteor
0.7.0: Scalable Database Queries Using MongoDB Oplog Instead of Poll-and-Diff</a>,” <em>info.meteor.com</em>,
December 17, 2013.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="VoltDBCh15">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#VoltDBCh15-marker">40</a>] “<a href="https://docs.voltdb.com/UsingVoltDB/ChapExport.php">Chapter
15. Importing and Exporting Live Data</a>,” VoltDB 6.4 User Manual, <em>docs.voltdb.com</em>, June 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Narkhede2016uo">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Narkhede2016uo-marker">41</a>] Neha Narkhede:
“<a href="http://www.confluent.io/blog/announcing-kafka-connect-building-large-scale-low-latency-data-pipelines">Announcing
Kafka Connect: Building Large-Scale Low-Latency Data Pipelines</a>,” <em>confluent.io</em>,
February 18, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Young2014wp">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Young2014wp-marker">42</a>] Greg Young:
“<a href="https://www.youtube.com/watch?v=JHGkaShoyNs">CQRS and Event Sourcing</a>,” at <em>Code on
the Beach</em>, August 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Fowler2005vd">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Fowler2005vd-marker">43</a>] Martin Fowler:
“<a href="http://martinfowler.com/eaaDev/EventSourcing.html">Event Sourcing</a>,” <em>martinfowler.com</em>,
December 12, 2005.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Vernon2013ww">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Vernon2013ww-marker">44</a>] Vaughn Vernon:
<a href="https://vaughnvernon.co/?page_id=168"><em>Implementing Domain-Driven Design</em></a>.
Addison-Wesley Professional, 2013. ISBN: 978-0-321-83457-7</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Jagadish1995ee">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Jagadish1995ee-marker">45</a>] H. V. Jagadish, Inderpal Singh Mumick, and Abraham Silberschatz:
“<a href="http://www.mathcs.emory.edu/~cheung/papers/StreamDB/Histogram/1995-Jagadish-Histo.pdf">View
Maintenance Issues for the Chronicle Data Model</a>,” at <em>14th ACM SIGACT-SIGMOD-SIGART Symposium
on Principles of Database Systems</em> (PODS), May 1995.
<a href="http://dx.doi.org/10.1145/212433.220201">doi:10.1145/212433.220201</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="EventStore2016">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#EventStore2016-marker">46</a>] “<a href="http://docs.geteventstore.com/">Event
Store 3.5.0 Documentation</a>,” Event Store LLP, <em>docs.geteventstore.com</em>, February 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kleppmann2016ug">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kleppmann2016ug-marker">47</a>] Martin Kleppmann:
<a href="http://www.oreilly.com/data/free/stream-processing.csp"><em>Making Sense of Stream
Processing</em></a>. Report, O’Reilly Media, May 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Mak2014ta">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Mak2014ta-marker">48</a>] Sander Mak:
“<a href="http://www.slideshare.net/SanderMak/eventsourced-architectures-with-akka">Event-Sourced
Architectures with Akka</a>,” at <em>JavaOne</em>, September 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Hyde2016">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hyde2016-marker">49</a>] Julian Hyde:
<a href="https://twitter.com/julianhyde/status/743374145006641153">personal communication</a>,
June 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Gupta1999uz">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gupta1999uz-marker">50</a>] Ashish Gupta and Inderpal Singh Mumick:
<em>Materialized Views: Techniques, Implementations, and Applications</em>. MIT Press, 1999.
ISBN: 978-0-262-57122-7</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Griffin1995gr">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Griffin1995gr-marker">51</a>] Timothy Griffin and Leonid Libkin:
“<a href="http://homepages.inf.ed.ac.uk/libkin/papers/sigmod95.pdf">Incremental
Maintenance of Views with Duplicates</a>,” at <em>ACM International Conference on Management of
Data</em> (SIGMOD), May 1995.
<a href="http://dx.doi.org/10.1145/223784.223849">doi:10.1145/223784.223849</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Helland2015vx">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2015vx-marker">52</a>] Pat Helland:
“<a href="http://www.cidrdb.org/cidr2015/Papers/CIDR15_Paper16.pdf">Immutability Changes
Everything</a>,” at <em>7th Biennial Conference on Innovative Data Systems Research</em> (CIDR),
January 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kleppmann2011vr">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kleppmann2011vr-marker">53</a>] Martin Kleppmann:
“<a href="http://martin.kleppmann.com/2011/03/07/accounting-for-computer-scientists.html">Accounting
for Computer Scientists</a>,” <em>martin.kleppmann.com</em>, March 7, 2011.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Helland2007vk">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2007vk-marker">54</a>] Pat Helland:
“<a href="https://blogs.msdn.microsoft.com/pathelland/2007/06/14/accountants-dont-use-erasers/">Accountants
Don’t Use Erasers</a>,” <em>blogs.msdn.com</em>, June 14, 2007.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Yang2015ui">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Yang2015ui-marker">55</a>] Fangjin Yang:
“<a href="https://metamarkets.com/2015/dogfooding-with-druid-samza-and-kafka-metametrics-at-metamarkets/">Dogfooding
with Druid, Samza, and Kafka: Metametrics at Metamarkets</a>,” <em>metamarkets.com</em>, June 3, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Li2015vm">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Li2015vm-marker">56</a>] Gavin Li, Jianqiu Lv, and Hang Qi:
“<a href="http://yahoohadoop.tumblr.com/post/116365275781/pistachio-co-locate-the-data-and-compute-for">Pistachio:
Co-Locate the Data and Compute for Fastest Cloud Compute</a>,” <em>yahoohadoop.tumblr.com</em>, April 13, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Paramasivam2016th">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Paramasivam2016th-marker">57</a>] Kartik Paramasivam:
“<a href="https://engineering.linkedin.com/blog/2016/06/stream-processing-hard-problems-part-1-killing-lambda">Stream
Processing Hard Problems – Part 1: Killing Lambda</a>,” <em>engineering.linkedin.com</em>, June 27, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Fowler2011xt">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Fowler2011xt-marker">58</a>] Martin Fowler:
“<a href="http://martinfowler.com/bliki/CQRS.html">CQRS</a>,” <em>martinfowler.com</em>, July 14, 2011.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Young2010td">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Young2010td-marker">59</a>] Greg Young:
“<a href="https://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf">CQRS Documents</a>,”
<em>cqrs.files.wordpress.com</em>, November 2010.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Schwartz2013ur_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Schwartz2013ur_ch11-marker">60</a>] Baron Schwartz:
“<a href="http://www.xaprb.com/blog/2013/12/28/immutability-mvcc-and-garbage-collection/">Immutability,
MVCC, and Garbage Collection</a>,” <em>xaprb.com</em>, December 28, 2013.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Eloff2015xu">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Eloff2015xu-marker">61</a>] Daniel Eloff, Slava Akhmechet, Jay Kreps, et al.:
<a href="https://news.ycombinator.com/item?id=9145197">“Re: Turning the Database Inside-out with
Apache Samza</a>,” Hacker News discussion, <em>news.ycombinator.com</em>, March 4, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="DatomicExcision">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#DatomicExcision-marker">62</a>] “<a href="http://docs.datomic.com/excision.html">Datomic
Development Resources: Excision</a>,” Cognitect, Inc., <em>docs.datomic.com</em>.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="FossilShun">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#FossilShun-marker">63</a>] “<a href="http://fossil-scm.org/index.html/doc/trunk/www/shunning.wiki">Fossil
Documentation: Deleting Content from Fossil</a>,” <em>fossil-scm.org</em>, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kreps2015zt">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2015zt-marker">64</a>] Jay Kreps:
“<a href="https://twitter.com/jaykreps/status/582580836425330688">The irony of distributed systems
is that data loss is really easy but deleting data is surprisingly hard,</a>” <em>twitter.com</em>, March 30,
2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Luckham2006tv">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Luckham2006tv-marker">65</a>] David C. Luckham:
“<a href="http://www.complexevents.com/2006/08/01/what%E2%80%99s-the-difference-between-esp-and-cep/">What’s
the Difference Between ESP and CEP?</a>,” <em>complexevents.com</em>, August 1, 2006.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Perera2015tz">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Perera2015tz-marker">66</a>] Srinath Perera:
“<a href="https://www.quora.com/How-is-stream-processing-and-complex-event-processing-CEP-different">How
Is Stream Processing and Complex Event Processing (CEP) Different?</a>,” <em>quora.com</em>, December 3, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Arasu2006df">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Arasu2006df-marker">67</a>] Arvind Arasu, Shivnath Babu, and Jennifer Widom:
“<a href="http://research.microsoft.com/pubs/77607/cql.pdf">The CQL Continuous Query Language:
Semantic Foundations and Query Execution</a>,” <em>The VLDB Journal</em>, volume 15, number 2, pages
121–142, June 2006.
<a href="http://dx.doi.org/10.1007/s00778-004-0147-z">doi:10.1007/s00778-004-0147-z</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Hyde2009jm">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hyde2009jm-marker">68</a>] Julian Hyde:
“<a href="http://queue.acm.org/detail.cfm?id=1667562">Data in Flight: How Streaming SQL Technology
Can Help Solve the Web 2.0 Data Crunch</a>,” <em>ACM Queue</em>, volume 7, number 11, December 2009.
<a href="http://dx.doi.org/10.1145/1661785.1667562">doi:10.1145/1661785.1667562</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Esper2016">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Esper2016-marker">69</a>] “<a href="http://www.espertech.com/esper/release-5.4.0/esper-reference/html_single/index.html">Esper
Reference, Version 5.4.0</a>,” EsperTech, Inc., <em>espertech.com</em>, April 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Nabi2014wu">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Nabi2014wu-marker">70</a>] Zubair Nabi, Eric Bouillet, Andrew Bainbridge, and Chris Thomas:
“<a href="https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2014/04/Streams-and-Storm-April-2014-Final.pdf">Of
Streams and Storms</a>,” IBM technical report, <em>developer.ibm.com</em>, April 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Pathirage2016fr">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Pathirage2016fr-marker">71</a>] Milinda Pathirage, Julian Hyde, Yi Pan, and Beth Plale:
“<a href="https://github.com/milinda/samzasql-hpbdc2016/blob/master/samzasql-hpbdc2016.pdf">SamzaSQL:
Scalable Fast Data Management with Streaming SQL</a>,” at <em>IEEE International Workshop on
High-Performance Big Data Computing</em> (HPBDC), May 2016.
<a href="http://dx.doi.org/10.1109/IPDPSW.2016.141">doi:10.1109/IPDPSW.2016.141</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Flajolet2007um">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Flajolet2007um-marker">72</a>] Philippe Flajolet, Éric Fusy, Olivier
Gandouet, and Frédéric Meunier:
“<a href="http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf">HyperLo⁠g​Log: The Analysis
of a Near-Optimal Cardinality Estimation Algorithm</a>,” at <em>Conference on Analysis of
Algorithms</em> (AofA), June 2007.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kreps2014wv_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014wv_ch11-marker">73</a>] Jay Kreps:
“<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">Questioning the Lambda
Architecture</a>,” <em>oreilly.com</em>, July 2, 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Hellstrom2016ub">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Hellstrom2016ub-marker">74</a>] Ian Hellström:
“<a href="https://databaseline.wordpress.com/2016/03/12/an-overview-of-apache-streaming-technologies/">An
Overview of Apache Streaming Technologies</a>,” <em>databaseline.wordpress.com</em>, March 12, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kreps2014wm_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014wm_ch11-marker">75</a>] Jay Kreps:
“<a href="https://www.oreilly.com/ideas/why-local-state-is-a-fundamental-primitive-in-stream-processing">Why
Local State Is a Fundamental Primitive in Stream Processing</a>,” <em>oreilly.com</em>, July 31, 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Banon2011hw">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Banon2011hw-marker">76</a>] Shay Banon:
“<a href="https://www.elastic.co/blog/percolator">Percolator</a>,” <em>elastic.co</em>, February 8,
2011.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Woodward2015vy">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Woodward2015vy-marker">77</a>] Alan Woodward and Martin Kleppmann:
“<a href="http://martin.kleppmann.com/2015/04/13/real-time-full-text-search-luwak-samza.html">Real-Time
Full-Text Search with Luwak and Samza</a>,” <em>martin.kleppmann.com</em>, April 13, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="StormDocs">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#StormDocs-marker">78</a>] “<a href="https://storm.apache.org/releases/1.0.1/index.html">Apache
Storm 1.0.1 Documentation</a>,” <em>storm.apache.org</em>, May 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Akidau2016tb">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2016tb-marker">79</a>] Tyler Akidau:
“<a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102">The World Beyond
Batch: Streaming 102</a>,” <em>oreilly.com</em>, January 20, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Ewen2016tz">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Ewen2016tz-marker">80</a>] Stephan Ewen:
“<a href="http://www.confluent.io/kafka-summit-2016-systems-advanced-streaming-analytics-with-apache-flink-and-apache-kafka">Streaming
Analytics with Apache Flink</a>,” at <em>Kafka Summit</em>, April
2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Akidau2013uz">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Akidau2013uz-marker">81</a>] Tyler Akidau, Alex Balikov, Kaya Bekiroğlu, et al.:
“<a href="http://research.google.com/pubs/pub41378.html">MillWheel: Fault-Tolerant Stream Processing
at Internet Scale</a>,” at <em>39th International Conference on Very Large Data Bases</em> (VLDB),
August 2013.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Dean2015tn">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Dean2015tn-marker">82</a>] Alex Dean:
“<a href="http://snowplowanalytics.com/blog/2015/09/15/improving-snowplows-understanding-of-time/">Improving
Snowplow’s Understanding of Time</a>,” <em>snowplowanalytics.com</em>, September 15, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="AzureWindowing">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#AzureWindowing-marker">83</a>] “<a href="https://msdn.microsoft.com/en-us/library/azure/dn835019.aspx">Windowing
(Azure Stream Analytics)</a>,” Microsoft Azure Reference, <em>msdn.microsoft.com</em>, April 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="SamzaState">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#SamzaState-marker">84</a>] “<a href="http://samza.apache.org/learn/documentation/0.10/container/state-management.html">State
Management</a>,” Apache Samza 0.10 Documentation, <em>samza.apache.org</em>, December 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Ananthanarayanan2013hw">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Ananthanarayanan2013hw-marker">85</a>] Rajagopal Ananthanarayanan,
Venkatesh Basker, Sumit Das, et al.:
“<a href="http://research.google.com/pubs/pub41318.html">Photon: Fault-Tolerant and Scalable
Joining of Continuous Data Streams</a>,” at <em>ACM International Conference on Management of
Data</em> (SIGMOD), June 2013.
<a href="http://dx.doi.org/10.1145/2463676.2465272">doi:10.1145/2463676.2465272</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="SamzaNewsfeed">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#SamzaNewsfeed-marker">86</a>] Martin Kleppmann:
“<a href="https://github.com/ept/newsfeed">Samza Newsfeed Demo</a>,” <em>github.com</em>,
September 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kirwin2014vm">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kirwin2014vm-marker">87</a>] Ben Kirwin:
“<a href="http://ben.kirw.in/2014/11/28/kafka-patterns/">Doing the Impossible: Exactly-Once
Messaging Patterns in Kafka</a>,” <em>ben.kirw.in</em>, November 28, 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Helland2005tc_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2005tc_ch11-marker">88</a>] Pat Helland:
“<a href="http://cidrdb.org/cidr2005/papers/P12.pdf">Data on the Outside Versus Data on the
Inside</a>,” at <em>2nd Biennial Conference on Innovative Data Systems Research</em> (CIDR), January
2005.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kimball2013tb_ch11">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kimball2013tb_ch11-marker">89</a>] Ralph Kimball and Margy Ross:
<em>The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling</em>,
3rd edition. John Wiley &amp; Sons, 2013. ISBN: 978-1-118-53080-1</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Klang2016mw">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Klang2016mw-marker">90</a>] Viktor Klang:
“<a href="https://twitter.com/viktorklang/status/789036133434978304">I’m coining the phrase
‘effectively-once’ for message processing with at-least-once + idempotent operations</a>,”
<em>twitter.com</em>, October 20, 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Zaharia2012wa">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Zaharia2012wa-marker">91</a>] Matei Zaharia, Tathagata Das, Haoyuan Li, et al.:
“<a href="https://www.usenix.org/system/files/conference/hotcloud12/hotcloud12-final28.pdf">Discretized
Streams: An Efficient and Fault-Tolerant Model for Stream Processing on Large Clusters</a>,” at
<em>4th USENIX Conference in Hot Topics in Cloud Computing</em> (HotCloud), June 2012.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Tzoumas2015tt">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Tzoumas2015tt-marker">92</a>] Kostas Tzoumas, Stephan Ewen, and Robert Metzger:
“<a href="http://data-artisans.com/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink/">High-Throughput,
Low-Latency, and Exactly-Once Stream Processing with Apache Flink</a>,” <em>data-artisans.com</em>, August 5, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Carbone2015wh">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Carbone2015wh-marker">93</a>] Paris Carbone, Gyula Fóra, Stephan Ewen, et al.:
“<a href="http://arxiv.org/abs/1506.08603">Lightweight Asynchronous Snapshots for Distributed
Dataflows</a>,” arXiv:1506.08603 [cs.DC], June 29, 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Betts2015ub">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Betts2015ub-marker">94</a>] Ryan Betts and John Hugg:
<a href="http://www.oreilly.com/data/free/fast-data-smart-and-at-scale.csp"><em>Fast Data: Smart and
at Scale</em></a>. Report, O’Reilly Media, October 2015.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Junqueira2016vv">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Junqueira2016vv-marker">95</a>] Flavio Junqueira:
“<a href="http://conferences.oreilly.com/strata/hadoop-big-data-eu/public/schedule/detail/49690">Making
Sense of Exactly-Once Semantics</a>,” at <em>Strata+Hadoop World London</em>, June 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Gustafson2016na">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Gustafson2016na-marker">96</a>] Jason Gustafson, Flavio Junqueira, Apurva Mehta, Sriram Subramanian, and Guozhang Wang: “<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging">KIP-98 – Exactly Once Delivery and Transactional Messaging</a>,” <em>cwiki.apache.org</em>, November 2016.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Helland2012id">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Helland2012id-marker">97</a>] Pat Helland:
“<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.401.1539&amp;rep=rep1&amp;type=pdf">Idempotence
Is Not a Medical Condition</a>,” <em>Communications of the ACM</em>, volume 55, number 5, page 56, May 2012.
<a href="http://dx.doi.org/10.1145/2160718.2160734">doi:10.1145/2160718.2160734</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Kreps2014zt">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Kreps2014zt-marker">98</a>] Jay Kreps:
“<a href="http://mail-archives.apache.org/mod_mbox/samza-dev/201409.mbox/%3CCAOeJiJg%2Bc7Ei%3DgzCuOz30DD3G5Hm9yFY%3DUJ6SafdNUFbvRgorg%40mail.gmail.com%3E">Re:
Trying to Achieve Deterministic Behavior on Recovery/Rewind</a>,” email to <em>samza-dev</em> mailing list,
September 9, 2014.</p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Elnozahy2002fp">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Elnozahy2002fp-marker">99</a>] E. N. (Mootaz) Elnozahy,
Lorenzo Alvisi, Yi-Min Wang, and David B. Johnson:
“<a href="http://www.cs.utexas.edu/~lorenzo/papers/SurveyFinal.pdf">A Survey of Rollback-Recovery
Protocols in Message-Passing Systems</a>,” <em>ACM Computing Surveys</em>, volume 34, number 3,
pages 375–408, September 2002.
<a href="http://dx.doi.org/10.1145/568522.568525">doi:10.1145/568522.568525</a></p><p xmlns:htmlbook="https://github.com/oreillymedia/HTMLBook" data-type="footnote" id="Warski2016tm">[<a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#Warski2016tm-marker">100</a>] Adam Warski:
“<a href="https://softwaremill.com/kafka-streams-how-does-it-fit-stream-landscape/">Kafka Streams –
How Does It Fit the Stream Processing Landscape?</a>,” <em>softwaremill.com</em>, June 1, 2016.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-0" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#">Copy</a></li>
		
		<li class="add-highlight"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#">Add Highlight</a></li>
		<li class="add-note"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch10.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">10. Batch Processing</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch12.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">12. The Future of Data Systems</div>
        </a>
    
  
  </div>


        
    </section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" class="icon-up"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/playlists/">Playlists</a>
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/preferences/">Settings</a></li>
      <li class="full-support"><a href="https://www.oreilly.com/online-learning/support/">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2018 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>




    
    
      <img src="https://www.oreilly.com/library/view/oreilly_set_cookie/" alt="" style="display:none;">
    
    

    
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 151.003px; left: 1356px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="/site/library/view/designing-data-intensive-applications/9781491903063/ch11.html#">Reset</a>
</div>
</div><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.9228074114505378"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.9108120480710227" width="0" height="0" alt="" src="https://bat.bing.com/action/0?ti=5794699&amp;Ver=2&amp;mid=cb45f438-553d-0b84-81b2-780b6598b0d0&amp;pi=1200101525&amp;lg=en-US&amp;sw=1440&amp;sh=900&amp;sc=24&amp;tl=11.%20Stream%20Processing%20-%20Designing%20Data-Intensive%20Applications&amp;p=https%3A%2F%2Fwww.safaribooksonline.com%2Flibrary%2Fview%2Fdesigning-data-intensive-applications%2F9781491903063%2Fch11.html&amp;r=&amp;lt=32149&amp;evt=pageLoad&amp;msclkid=N&amp;rn=272884"></div></body></html>