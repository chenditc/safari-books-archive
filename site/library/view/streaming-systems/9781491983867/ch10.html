<!--[if IE]><![endif]--><!DOCTYPE html><!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/streaming-systems/9781491983867/ch10.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="3905629"
  data-user-uuid="f04af719-1c84-4fc3-9be3-1f1b4622ab99"
  data-username="safaribooksonline122"
  data-account-type="Trial"
  
  data-activated-trial-date="12/09/2018"


  data-archive="9781491983867"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch10.html"
  data-epub-title="Streaming Systems" data-debug=0 data-testing=0><![endif]--><!--[if gt IE 8]><!--><html class="js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom gr__safaribooksonline_com" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/streaming-systems/9781491983867/ch10.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="3905629" data-user-uuid="f04af719-1c84-4fc3-9be3-1f1b4622ab99" data-username="safaribooksonline122" data-account-type="Trial" data-activated-trial-date="12/09/2018" data-archive="9781491983867" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch10.html" data-epub-title="Streaming Systems" data-debug="0" data-testing="0" style=""><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491983867"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.0c29511d2d72.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900,200italic,300italic,400italic,600italic,700italic,900italic" rel="stylesheet" type="text/css"><title>10. The Evolution of Large-Scale Data Processing - Streaming Systems</title><link rel="stylesheet" href="https://www.safaribooksonline.com/static/CACHE/css/5e586a47a3b7.css" type="text/css"><link rel="stylesheet" type="text/css" href="https://www.safaribooksonline.com/static/css/annotator.e3b0c44298fc.css"><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"><style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000 !important;padding-top:10px !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:1em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .what_lt{color:#c90;}#sbo-rt-content .where_lt{color:#26c}#sbo-rt-content .when_lt{color:#6a5;}#sbo-rt-content .how_lt{color:#c00}#sbo-rt-content .what_dk{color:#ffd040}#sbo-rt-content .where_dk{color:#6af}#sbo-rt-content .when_dk{color:#8ac86f}#sbo-rt-content .how_dk{color:#d77}#sbo-rt-content .grey_bg{background-color:#ff0}#sbo-rt-content .yellow_bg{background-color:#ff0}#sbo-rt-content .green_bg{background-color:#00FF7F}#sbo-rt-content .red_bg{background-color:#FFA07A}#sbo-rt-content .blue_bg{background-color:#87CEEB}#sbo-rt-content .code_blue{color:#00f}#sbo-rt-content .code_grey{color:#777}#sbo-rt-content .code_orange{color:#d83}#sbo-rt-content .code_purple{color:#87c}#sbo-rt-content .code_lightgrey{color:#C0C0C0}#sbo-rt-content .strikethrough{text-decoration:line-through}#sbo-rt-content .table_white{color:white}#sbo-rt-content .table_black{color:black}#sbo-rt-content .table_red{color:#d77}#sbo-rt-content .table_green{color:#8ac86f}#sbo-rt-content .table_blue{color:#00f}#sbo-rt-content .table_mediumgrey{background-color:#404040}#sbo-rt-content .table_lightgrey{background-color:#606060}#sbo-rt-content .table_darkgrey{background-color:#202020}
    </style><link rel="canonical" href="/site/library/view/streaming-systems/9781491983867/ch10.html"><meta name="description" content=" Chapter 10. The Evolution of Large-Scale Data Processing You have now arrived at the final chapter in the book, you stoic literate, you. Your journey will soon be complete! To ... "><meta property="og:title" content="10. The Evolution of Large-Scale Data Processing"><meta itemprop="isPartOf" content="/library/view/streaming-systems/9781491983867/"><meta itemprop="name" content="10. The Evolution of Large-Scale Data Processing"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/ch10.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491983867/"><meta property="og:description" itemprop="description" content=" Chapter 10. The Evolution of Large-Scale Data Processing You have now arrived at the final chapter in the book, you stoic literate, you. Your journey will soon be complete! To ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491983874"><meta property="og:book:author" itemprop="author" content="Reuven Lax"><meta property="og:book:author" itemprop="author" content="Slava Chernyak"><meta property="og:book:author" itemprop="author" content="Tyler Akidau"><meta property="og:book:tag" itemprop="about" content="Databases"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: <%= font_size %> !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: <%= font_family %> !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: <%= column_width %>% !important; margin: 0 auto !important; }"></style><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  
  



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="/site/library/view/streaming-systems/9781491983867/ch10.html#container" class="skip">Skip to content</a><header class="topbar t-topbar" style="display:None"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/playlists/" class="t-queue-nav l0 nav-icn None"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="21px" height="17px" viewBox="0 0 21 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch --><title>icon_Playlist_sml</title><desc>Created with Sketch.</desc><defs></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="icon_Playlist_sml" fill-rule="nonzero" fill="#000000"><g id="playlist-icon"><g id="Group-6"><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle></g><g id="Group-5" transform="translate(0.000000, 7.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g><g id="Group-5-Copy" transform="translate(0.000000, 14.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g></g></g></g></svg><span>
               Playlists
            </span></a></li><li class="search"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://get.oreilly.com/email-signup.html" target="_blank" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/f04af719-1c84-4fc3-9be3-1f1b4622ab99/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/preferences/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/preferences/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Streaming Systems
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><div class="js-content-uri" data-content-uri="/api/v1/book/9781491983867/chapter/ch10.html"><div class="js-collections-dropdown collections-dropdown menu-bit-cards"><div data-reactroot="" class="menu-dropdown-wrapper js-menu-dropdown-wrapper align-right"><img class="hidden" src="https://www.safaribooksonline.com/static/images/ajax-transp.gif" alt="loading spinner"><div class="menu-control"><div class="control "><div class="js-playlists-menu"><button class="js-playlist-icon"><svg class="icon-add-to-playlist-sml" viewBox="0 0 16 14" version="1.1" xmlns="http://www.w3.org/2000/svg"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill-rule="nonzero" fill="#000000"><g transform="translate(-1.000000, 0.000000)"><rect x="5" y="0" width="12" height="2"></rect><title>Playlists</title><path d="M4.5,14 C6.43299662,14 8,12.4329966 8,10.5 C8,8.56700338 6.43299662,7 4.5,7 C2.56700338,7 1,8.56700338 1,10.5 C1,12.4329966 2.56700338,14 4.5,14 Z M2.5,10 L4,10 L4,8.5 L5,8.5 L5,10 L6.5,10 L6.5,11 L5,11 L5,12.5 L4,12.5 L4,11 L2.5,11 L2.5,10 Z"></path><circle cx="2" cy="5" r="1"></circle><circle cx="1.94117647" cy="1" r="1"></circle><rect x="5" y="4" width="12" height="2"></rect><rect x="9" y="8" width="8" height="2"></rect><rect x="9" y="12" width="8" height="2"></rect></g></g></g></svg><div class="js-playlist-addto-label">Add&nbsp;To</div></button></div></div></div></div></div></div></li><li class="js-font-control-panel font-control-activator"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/ch10.html&amp;text=Streaming%20Systems&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/ch10.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/ch10.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%2010.%20The%20Evolution%20of%20Large-Scale%20Data%20Processing&amp;body=https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/ch10.html%0D%0Afrom%20Streaming%20Systems%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
        
        



 <!--[if lt IE 9]>
  
<![endif]-->



  


        
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="/site/library/view/streaming-systems/9781491983867/ch09.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">9. Streaming Joins</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="/site/library/view/streaming-systems/9781491983867/ix01.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">Index</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content" style="transform: none;"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 10. The Evolution of Large-Scale Data Processing"><div class="chapter" id="the_evolution_of_large_scale_data_processing">
<h1><span class="label">Chapter 10. </span>The Evolution of Large-Scale <span class="keep-together">Data Processing</span></h1>

<p>You have now arrived at the final chapter in the book, you stoic literate, you.<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-type="indexterm" id="ix_lgscdp"></a> Your journey will soon be complete!</p>

<p>To wrap things up, I’d like you to join me on a brief stroll through history, starting back in the ancient days of large-scale data processing with MapReduce and touching upon some <a contenteditable="false" data-primary="MapReduce" data-type="indexterm" id="ix_MRlgsc"></a>of the highlights over the ensuing decade and a half that have brought streaming systems to the point they’re at today. It’s a relatively lightweight chapter in which I make a few observations about important contributions from a number of well-known systems (and a couple maybe not-so-well known), refer you to a bunch of source material you can go read on your own should you want to learn more, all while attempting not to offend or inflame the folks responsible for systems whose truly impactful contributions I’m going to either oversimplify or ignore completely for the sake of space, focus, and a cohesive narrative. Should be a good time.<a contenteditable="false" data-primary="data processing, large scale" data-see="large-scale data processing, evolution of" data-type="indexterm" id="idm140176508312512"></a></p>

<p>On that note, keep in mind as you read this chapter that we’re really just talking about specific pieces of the MapReduce/Hadoop family tree of large-scale data processing here. I’m not covering the SQL arena in any way shape or form<sup><a data-type="noteref" id="idm140176508310416-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508310416" class="totri-footnote">1</a></sup>; we’re not talking HPC/supercomputers, and so on. So as broad and expansive as the title of this chapter might sound, I’m really focusing on a specific vertical swath of the grand universe of large-scale data processing. Caveat literatus, and all that.</p>

<p>Also note that I’m covering a <a contenteditable="false" data-primary="Google technologies in large-scale data processing" data-type="indexterm" id="idm140176508308016"></a>disproportionate amount of Google technologies here. You would be right in thinking that this might have something to do with the fact that I’ve worked at Google for more than a decade. But there are two other reasons for it: 1) big data has always been important for Google, so there have been a number of worthwhile contributions created there that merit discussing in detail, and 2) my experience has been that folks outside of Google generally seem to enjoy learning more about the things we’ve done, because we as a company have historically been somewhat tight-lipped in that regard. So indulge me a bit while I prattle on excessively about the stuff we’ve been working on behind closed doors.</p>

<p>To ground <a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="timeline of systems discussed" data-type="indexterm" id="idm140176508305648"></a>our travels in concrete chronology, we’ll be following the timeline in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#approximate_timeline_of_systems_discussed_in_this_chapter">Figure&nbsp;10-1</a>, which shows rough dates of existence for the various systems I discuss.</p>

<figure><div id="approximate_timeline_of_systems_discussed_in_this_chapter" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1001.png" width="600" height="284" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1001.png">
<h6><span class="label">Figure 10-1. </span>Approximate timeline of systems discussed in this chapter</h6>
</div></figure>

<p>At each stop, I give a brief history of the system as best I understand it and frame its contributions from the perspective of shaping streaming systems as we know them today. At the end, we recap all of the contributions to see how they’ve summed up to create the modern stream processing ecosystem of today.</p>

<section data-type="sect1" data-pdf-bookmark="MapReduce"><div class="sect1" id="idm140176508300336">
<h1>MapReduce</h1>

<p>We begin the journey<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="MapReduce" data-type="indexterm" id="ix_lgscdpMR"></a> with MapReduce (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_map_reduce">Figure&nbsp;10-2</a>).</p>

<figure><div id="timeline_map_reduce" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1002.png" width="600" height="282" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1002.png">
<h6><span class="label">Figure 10-2. </span>Timeline: MapReduce</h6>
</div></figure>

<p>I think it’s safe to say that large-scale data processing as we all know it today got its start with MapReduce way back in 2003.<sup><a data-type="noteref" id="idm140176508293680-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508293680" class="totri-footnote">2</a></sup> At the time, engineers within Google were building all sorts of bespoke systems to tackle data processing challenges at the scale of the World Wide Web.<sup><a data-type="noteref" id="idm140176508292336-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508292336" class="totri-footnote">3</a></sup> As they did so, they noticed three things:</p>

<dl>
	<dt>Data processing is hard</dt>
	<dd>
	<p>As the data scientists and <a contenteditable="false" data-primary="data processing" data-secondary="difficulty of" data-type="indexterm" id="idm140176508289712"></a>engineers among us well know, you can build a career out of just focusing on the best ways to extract useful insights from raw data.</p>
	</dd>
	<dt>Scalability is hard</dt>
	<dd>
	<p>Extracting useful insights<a contenteditable="false" data-primary="scalability" data-secondary="in large-scale data processing" data-type="indexterm" id="idm140176508286656"></a> over massive-scale data is even more difficult yet.</p>
	</dd>
	<dt>Fault-tolerance is hard</dt>
	<dd>
	<p>Extracting useful insights from <a contenteditable="false" data-primary="fault-tolerance in large-scale data processing" data-type="indexterm" id="idm140176508283712"></a>massive-scale data in a fault-tolerant, correct way on commodity hardware is brutal.</p>
	</dd>
</dl>

<p>After solving all three of these challenges in tandem across a number of use cases, they began to notice some similarities between the custom systems they’d built. And they came to the conclusion that if they could build a framework that took care of the latter two issues (scalability and fault-tolerance), it would make focusing on the first issue a heck of a lot simpler. Thus was born MapReduce.<sup><a data-type="noteref" id="idm140176508281456-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508281456" class="totri-footnote">4</a></sup></p>

<p>The basic idea with MapReduce was <a contenteditable="false" data-primary="MapReduce" data-secondary="visualization of a job" data-type="indexterm" id="idm140176508280272"></a>to provide a simple data processing API centered around two well-understand operations from the functional programming realm: map and reduce (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#visualization_of_a_mapreduce_jovisualization_of_a_mapreduce_jobb">Figure&nbsp;10-3</a>). Pipelines built with that API would then be executed on a distributed systems framework that took care of all the nasty scalability and fault-tolerance stuff that quickens the hearts of hardcore distributed-systems engineers and crushes the souls of the rest of us mere mortals.</p>

<figure><div id="visualization_of_a_mapreduce_jovisualization_of_a_mapreduce_jobb" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1003.png" width="600" height="281" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1003.png">
<h6><span class="label">Figure 10-3. </span>Visualization of a MapReduce job</h6>
</div></figure>

<p>We already discussed the semantics of MapReduce in great detail back in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch06.html#streams_and_tables">Chapter&nbsp;6</a>, so we won’t dwell on them here. Simply recall that we broke things down into six discrete phases (MapRead, Map, MapWrite, ReduceRead, Reduce, ReduceWrite) as part of our streams and tables analysis, and we came to the conclusion in the end that there really<a contenteditable="false" data-primary="MapReduce" data-secondary="functionality of overall Map and Reduce phases" data-type="indexterm" id="idm140176508273872"></a> wasn’t all that much different between the overall Map and Reduce phases; at a high-level, they <a contenteditable="false" data-primary="streams and tables" data-secondary="conversions to and from in MapReduce" data-type="indexterm" id="idm140176508272224"></a>both do the following:</p>

<ul>
	<li>
	<p>Convert a table to a stream</p>
	</li>
	<li>
	<p>Apply a user transformation to that stream to yield another stream</p>
	</li>
	<li>
	<p>Group that stream into a table</p>
	</li>
</ul>

<p>After it was placed into service within Google, MapReduce found such broad application across a variety of tasks that the team decided it was worth sharing its ideas with the rest of the world. <a contenteditable="false" data-primary="MapReduce" data-secondary="MapReduce paper" data-type="indexterm" id="idm140176508266736"></a>The result was the <a href="https://goo.gl/Rsqr3G">MapReduce paper</a>, published at OSDI 2004 (see <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#the_mapreduce_paper_published_at_osdi">Figure&nbsp;10-4</a>).</p>

<figure class="floatleft"><div id="the_mapreduce_paper_published_at_osdi" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1004.png" width="600" height="435" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1004.png">
<h6><span class="label">Figure 10-4. </span>The <a href="https://goo.gl/Rsqr3G">MapReduce paper</a>, published at OSDI 2004</h6>
</div></figure>

<p>In it, the team described in detail the history of the project, design of the API and implementation, and details about a number of different use cases to which MapReduce had been applied. Unfortunately, they provided no actual source code, so the best that folks outside of Google at the time could do was say, “Yes, that sounds very nice indeed,” and go back to building their bespoke systems.</p>

<p>Over the course of the decade that followed, MapReduce continued to undergo heavy development within Google, with large amounts of time invested in making the system scale to unprecedented levels. <a contenteditable="false" data-primary="MapReduce" data-secondary="history of massive-scale sorting experiments at Google" data-type="indexterm" id="idm140176508259120"></a>For a more detailed account of some of the highlights along that journey, I recommend the post <a href="http://bit.ly/2LPvuVN">“History of massive-scale sorting experiments at Google”</a> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#marian_dvosrkys_history_of_massive_scale_sorting_experiments">Figure&nbsp;10-5</a>) written by our official MapReduce historian/scalability and performance wizard, Marián <span class="keep-together">Dvorský</span>.</p>

<figure class="floatright"><div id="marian_dvosrkys_history_of_massive_scale_sorting_experiments" class="figure"><img alt="" class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1005.png" width="600" height="593" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1005.png">
<h6><span class="label">Figure 10-5. </span>Marián Dvorský’s <a href="http://bit.ly/2LPvuVN">“History of massive-scale sorting experiments”</a> blog post</h6>
</div></figure>

<p>But for our purposes here, suffice it to say that nothing else yet has touched the magnitude of scale achieved by MapReduce, not even within Google. Considering how long MapReduce has been around, that’s saying something; 14 years is an eternity in our industry.</p>

<p>From a streaming systems perspective, the main takeaways I want to leave you with for MapReduce are <em>simplicity</em> and <em>scalability</em>. <a contenteditable="false" data-primary="scalability" data-secondary="in MapReduce" data-type="indexterm" id="idm140176508249376"></a>MapReduce took the <a contenteditable="false" data-primary="MapReduce" data-secondary="simplicity and scalability" data-type="indexterm" id="idm140176508247840"></a>first brave steps toward taming the unruly beast that is massive-scale data processing, exposing a simple and straightforward API for crafting powerful data processing pipelines, its austerity belying the complex distributed systems magic happening under the covers to allow those pipelines to run at scale on large clusters<a contenteditable="false" data-primary="MapReduce" data-startref="ix_MRlgsc" data-type="indexterm" id="idm140176508245952"></a> of commodity hardware.&nbsp;<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="MapReduce" data-startref="ix_lgscdpMR" data-type="indexterm" id="idm140176508244448"></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Hadoop"><div class="sect1" id="idm140176508299712">
<h1>Hadoop</h1>

<p>Next in our list is Hadoop (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_hadoop">Figure&nbsp;10-6</a>). Fair warning: <a contenteditable="false" data-primary="Hadoop" data-type="indexterm" id="idm140176508240432"></a>this is one of<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Hadoop" data-type="indexterm" id="idm140176508239168"></a> those times where I will grossly oversimplify the impact of a system for the sake of a focused narrative. The impact Hadoop has had on our industry and the world at large cannot be overstated, and it extends well beyond the relatively specific scope I discuss here.</p>

<figure><div id="timeline_hadoop" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1006.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1006.png">
<h6><span class="label">Figure 10-6. </span>Timeline: Hadoop</h6>
</div></figure>

<p>Hadoop came about in 2005, when Doug Cutting and Mike Cafarella decided that the ideas from the MapReduce paper were just the thing they needed as they built a distributed version of their Nutch webcrawler. They had already built their own version of Google’s distributed filesystem (originally called NDFS for Nutch Distributed File System, later <a contenteditable="false" data-primary="HDFS (Hadoop Distributed File System)" data-type="indexterm" id="idm140176508234960"></a>renamed to HDFS, or Hadoop Distributed File System), so it was a natural next step to add a MapReduce layer on top after that paper was published. They called this layer Hadoop.</p>

<p>The key difference between Hadoop and MapReduce was that Cutting and Cafarella made sure the source code for Hadoop was shared with the rest of the world by open sourcing it (along with the source for HDFS) as part of what would eventually become the Apache Hadoop project. Yahoo’s hiring of Cutting to help transition the Yahoo webcrawler architecture onto Hadoop gave the project an additional boost of validity and engineering oomph, and from there, an entire ecosystem of open source data processing tools grew. As with MapReduce, others have told the history of Hadoop in other fora far better than I can; one particularly good reference is Marko Bonaci’s <a href="http://bit.ly/2Kjc4fZ">“The history of Hadoop,”</a> itself originally slated for inclusion in a print book (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#marko_bonaci">Figure&nbsp;10-7</a>).</p>

<figure class="floatleft"><div id="marko_bonaci" class="figure"><img alt="" class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1007.png" width="600" height="464" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1007.png">
<h6><span class="label">Figure 10-7. </span>Marko Bonaci’s <a href="http://bit.ly/2Kjc4fZ">“The history of Hadoop”</a></h6>
</div></figure>

<p>The main point I want you to take away from this section is the massive impact the <em>open source ecosystem</em> that flowered around Hadoop had upon the industry as a whole.<a contenteditable="false" data-primary="open source ecosystem, Hadoop and" data-type="indexterm" id="idm140176508226848"></a> By creating an open community in which engineers could improve and extend the ideas from those early GFS and MapReduce papers, a thriving ecosystem was born, yielding dozens of useful tools like Pig, Hive, HBase, Crunch, and on and on. That openness was key to incubating the diversity of ideas that exist now across our industry, and it’s why I’m pigeonholing Hadoop’s open source ecosystem as its single most important contribution to the world of streaming systems as we know them today.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Flume"><div class="sect1" id="idm140176508224832">
<h1>Flume</h1>

<p>We now<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Flume" data-type="indexterm" id="ix_lgscdpFlume"></a> return to Google territory to talk about the official <a contenteditable="false" data-primary="Flume" data-type="indexterm" id="ix_Flume"></a>successor to MapReduce within Google: Flume ([<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_flume">Figure&nbsp;10-8</a>] sometimes also called FlumeJava in reference to the original Java version of the system, <a contenteditable="false" data-primary="FlumeJava" data-seealso="Flume" data-type="indexterm" id="idm140176508218368"></a>and not to be confused with Apache Flume, which is an entirely different beast that just so happens to share the same name).</p>

<figure><div id="timeline_flume" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1008.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1008.png">
<h6><span class="label">Figure 10-8. </span>Timeline: Flume</h6>
</div></figure>

<p>The Flume project was founded by Craig Chambers when the Google Seattle office opened in 2007. It was motivated by a desire to solve some of the inherent shortcomings of MapReduce, which had become apparent over the first few years of its success. Many of these shortcomings revolved around MapReduce’s rigid Map → Shuffle → Reduce structure; though<a contenteditable="false" data-primary="MapReduce" data-secondary="shortcomings of" data-type="indexterm" id="idm140176508214368"></a> refreshingly simple, it carried with it some downsides:</p>

<ul>
	<li>
	<p>Because many use cases cannot be served by the application of a single MapReduce, a number of bespoke <em>orchestration systems</em> began popping up across Google for coordinating sequences of MapReduce jobs. These systems all served essentially the same purpose (gluing together multiple MapReduce jobs to create a coherent pipeline solving a complex problem). However, having been developed independently, they were naturally incompatible and a textbook example of unnecessary duplication of effort.</p>
	</li>
	<li>
	<p>What’s worse, there were numerous cases in which a clearly<a contenteditable="false" data-primary="efficiency" data-secondary="inefficiencies in MapReduce jobs" data-type="indexterm" id="idm140176508209760"></a> written sequence of MapReduce jobs would introduce <em>inefficiencies</em> thanks to the rigid structure of the API. For example, one team might write a MapReduce that simply filtered out some number of elements; that is, a map-only job with an empty reducer. It might be followed up by another team’s map-only job doing some element-wise enrichment (with yet another empty reducer). The output from the second job might then finally be consumed by a final team’s MapReduce performing some grouping aggregation over the data. This pipeline, consisting of essentially a single chain of Map phases followed by a single Reduce phase, would require the orchestration of three completely independent jobs, each chained together by shuffle and output phases materializing the data. But that’s assuming you wanted to keep the codebase logical and clean, which leads to the final downside…</p>
	</li>
	<li>
	<p>In an effort to optimize away these inefficiencies in their MapReductions, engineers began introducing <em>manual optimizations</em> that would <em>obfuscate</em> the simple logic of the pipeline, increasing maintenance and debugging costs.</p>
	</li>
</ul>

<p>Flume addressed these issues<a contenteditable="false" data-primary="Flume" data-secondary="high-level pipelines in" data-type="indexterm" id="idm140176508204384"></a> by providing a composable, high-level API for describing data processing pipelines, essentially based around the same PCollection and PTransform concepts found in Beam, as illustrated in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#high_level_pipelines_in_flume">Figure&nbsp;10-9</a>.</p>

<figure><div id="high_level_pipelines_in_flume" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1009.png" width="600" height="282" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1009.png">
<h6><span class="label">Figure 10-9. </span>High-level pipelines in Flume (image credit: Frances Perry)</h6>
</div></figure>

<p>These pipelines, when launched, would be fed through an optimizer<sup><a data-type="noteref" id="idm140176508199280-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508199280" class="totri-footnote">5</a></sup> to generate a plan for an<a contenteditable="false" data-primary="Flume" data-secondary="optimization of MapReduce jobs" data-type="indexterm" id="idm140176508198512"></a> optimally efficient sequence of MapReduce jobs, the execution of which was then orchestrated by the framework, which you can see illustrated in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#optimization_from_a_logical_pipeline_to_a_physical_execution_plan">Figure&nbsp;10-10</a>.</p>

<figure><div id="optimization_from_a_logical_pipeline_to_a_physical_execution_plan" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1010.png" width="600" height="306" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1010.png">
<h6><span class="label">Figure 10-10. </span>Optimization from a logical pipeline to a physical execution plan</h6>
</div></figure>

<p>Perhaps the most important example of an<a contenteditable="false" data-primary="fusion optimization on pipeline graph" data-type="indexterm" id="idm140176508193504"></a> automatic optimization<a contenteditable="false" data-primary="Flume" data-secondary="fusion optimizations" data-type="indexterm" id="idm140176508192256"></a> that Flume can perform is fusion (which Reuven discussed a bit back in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch05.html#exactly_once_and_side_effects">Chapter&nbsp;5</a>), in which two logically independent stages can be run in the same job either sequentially (consumer-producer fusion) or in parallel (sibling fusion), as depicted in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#fusion_optimizations_combine_successive_or_parallel_operations_together_into_the_same_physical_operation">Figure&nbsp;10-11</a>.</p>

<figure><div id="fusion_optimizations_combine_successive_or_parallel_operations_together_into_the_same_physical_operation" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1011.png" width="600" height="337" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1011.png">
<h6><span class="label">Figure 10-11. </span>Fusion optimizations combine successive or parallel operations together into the same physical operation</h6>
</div></figure>

<p>Fusing two stages together eliminates serialization/deserialization and network costs, which can be significant in pipelines processing large amounts of data.</p>

<p>Another type of<a contenteditable="false" data-primary="combiner lifting optimization" data-type="indexterm" id="idm140176508185424"></a> automatic <a contenteditable="false" data-primary="Flume" data-secondary="combiner lifting optimization" data-type="indexterm" id="idm140176508184096"></a>optimization is <em>combiner lifting</em> (see <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#combiner_lifting_applies_partial_aggregation_on_the_sender_side_of_a_group">Figure&nbsp;10-12</a>), the mechanics of which we already touched upon in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch07.html#practicalities_of_persistent_state">Chapter&nbsp;7</a> when we talked about incremental combining. Combiner lifting is simply the automatic application of multilevel combine logic that we discussed in that chapter: a combining operation (e.g., summation) that logically happens after a grouping operation is partially lifted into the stage preceding the group-by-key (which by definition requires a trip across the network to shuffle the data) so that it can perform partial combining before the grouping happens. In cases of very hot keys, this can greatly reduce the amount of data shuffled over the network, and also spread the load of computing the final aggregate more smoothly across multiple machines.</p>

<figure><div id="combiner_lifting_applies_partial_aggregation_on_the_sender_side_of_a_group" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1012.png" width="600" height="278" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1012.png">
<h6><span class="label">Figure 10-12. </span>Combiner lifting applies partial aggregation on the sender side of a group-by-key operation before completing aggregation on the consumer side</h6>
</div></figure>

<p>As a result of its cleaner API and automatic optimizations, Flume Java was an instant hit upon its introduction at Google in early 2009. Following on the heels of that success, the team published the<a contenteditable="false" data-primary="Flume" data-secondary="FlumeJava paper" data-type="indexterm" id="idm140176508177088"></a> paper titled <a href="https://goo.gl/9e1nXf">“Flume Java: Easy, Efficient Data-Parallel Pipelines”</a> (see <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#flumejava_paper">Figure&nbsp;10-13</a>), itself an excellent resource for learning more about the system as it originally existed.</p>

<figure class="floatright"><div id="flumejava_paper" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1013.png" width="600" height="447" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1013.png">
<h6><span class="label">Figure 10-13. </span><a href="https://goo.gl/9e1nXf">FlumeJava paper</a></h6>
</div></figure>

<p>Flume C++ followed not too much later in 2011, and in early 2012 Flume was introduced into Noogler<sup><a data-type="noteref" id="idm140176508170576-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508170576" class="totri-footnote">6</a></sup> training provided to all new engineers at Google. That was the beginning of the end for MapReduce.</p>

<p>Since then, Flume has been migrated to no longer use MapReduce as its execution engine; instead,<a contenteditable="false" data-primary="Flume" data-secondary="migration away from MapReduce to Dax execution engine" data-type="indexterm" id="idm140176508169216"></a> it uses a custom execution engine, called Dax, built directly into the framework itself. By freeing Flume itself from the confines of the previously underlying Map → Shuffle → Reduce structure of MapReduce, Dax enabled new optimizations, such as the dynamic work rebalancing feature described in Eugene Kirpichov and Malo Denielou’s <a href="http://bit.ly/2JPaUnR">“No shard left behind”</a> blog post (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#no_shard_left_behind">Figure&nbsp;10-14</a>).</p>

<figure class="floatleft"><div id="no_shard_left_behind" class="figure"><img alt="" class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1014.png" width="600" height="417" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1014.png">
<h6><span class="label">Figure 10-14. </span><a href="http://bit.ly/2JPaUnR">“No shard left behind”</a> post</h6>
</div></figure>

<p>Though discussed in that post in the context of Cloud Dataflow, dynamic work rebalancing (or liquid sharding, as it’s colloquially known at Google) automatically rebalances<a contenteditable="false" data-primary="Flume" data-secondary="dynamic work rebalancing (or liquid sharding)" data-type="indexterm" id="idm140176508162016"></a> extra work from straggler shards to other idle workers in the system as they complete their work early. <a contenteditable="false" data-primary="liquid sharding" data-type="indexterm" id="idm140176508160352"></a><a contenteditable="false" data-primary="dynamic work rebalancing (or liquid sharding)" data-type="indexterm" id="idm140176508159248"></a>By dynamically rebalancing the work distribution over time, it’s possible to come much closer to an optimal work distribution than even the best educated initial splits could ever achieve. It also allows for adapting to variations across the pool of workers, where a slow machine that might have otherwise held up the completion of a job is simply compensated for by moving most of its tasks to other workers. When liquid sharding was rolled out at Google, it recouped significant amounts of resources across the fleet.</p>

<p>One last point on Flume is that it was also later extended to support streaming semantics.<a contenteditable="false" data-primary="Flume" data-secondary="extension to support streaming semantics" data-type="indexterm" id="idm140176508156912"></a> In addition to the batch Dax backend, Flume was extended to be able to execute pipelines on the MillWheel stream processing system (discussed in a moment). <a contenteditable="false" data-primary="MillWheel" data-secondary="Flume and" data-type="indexterm" id="idm140176508155200"></a>Most of the high-level streaming semantics concepts we’ve discussed in this book were first incorporated into Flume before later finding their way into Cloud Dataflow and eventually Apache Beam.</p>

<p>All that said, the primary thing to take away from Flume in this section is the introduction of a notion of <em>high-level pipelines</em>, which enabled the <em>automatic optimization</em> of clearly written, logical pipelines. This enabled the creation of much larger and complex pipelines, without the need for manual orchestration or optimization, and all while keeping<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Flume" data-startref="ix_lgscdpFlume" data-type="indexterm" id="idm140176508151872"></a> the code for those<a contenteditable="false" data-primary="Flume" data-startref="ix_Flume" data-type="indexterm" id="idm140176508150064"></a> pipelines logical and clear.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Storm"><div class="sect1" id="idm140176508223920">
<h1>Storm</h1>

<p>Next up is Apache Storm (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_storm">Figure&nbsp;10-15</a>), the <a contenteditable="false" data-primary="Apache Storm" data-type="indexterm" id="ix_ApStorm"></a>first real streaming system we cover.<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Apache Storm" data-type="indexterm" id="ix_lgscdpApSt"></a> Storm most certainly wasn’t the first streaming system in existence, but I would argue it was the first streaming system <a contenteditable="false" data-primary="Storm" data-see="Apache Storm" data-type="indexterm" id="idm140176508142672"></a>to see truly broad adoption across the industry, and for that reason we give it a closer look here.</p>

<figure><div id="timeline_storm" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1015.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1015.png">
<h6><span class="label">Figure 10-15. </span>Timeline: Storm</h6>
</div></figure>

<figure class="floatright"><div id="history_of_apache_storm" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1016.png" width="600" height="395" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1016.png">
<h6><span class="label">Figure 10-16. </span><a href="http://bit.ly/2HLwSqd">“History of Apache Storm and lessons learned”</a></h6>
</div></figure>

<p>Storm was the brainchild of Nathan Marz, who later chronicled the history of its creation <a contenteditable="false" data-primary="Apache Storm" data-secondary="history of its creation" data-type="indexterm" id="idm140176508136480"></a>in a blog <span class="keep-together">post titled</span> <a href="http://bit.ly/2HLwSqd">“History of Apache Storm and lessons learned”</a> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#history_of_apache_storm">Figure&nbsp;10-16</a>). The TL;DR version of it is that Nathan’s team at the startup employing him then, BackType, had been attempting to process the Twitter firehose using a custom system of queues and workers. He came to essentially the same realization that the MapReduce folks had nearly a decade earlier: the actual data processing portion of their code was only a tiny amount of the system, and building those real-time data processing pipelines would be a lot easier if there were a framework doing all the distributed system’s dirty work under the covers. Out of that was born Storm.</p>

<p>The interesting thing about Storm, in comparison to the rest of the systems we’ve talked about so far, is that the team chose to loosen the strong consistency guarantees found in all of the other systems we’ve talked about so far as a way of providing lower latency.<a contenteditable="false" data-primary="latency" data-secondary="improvements in Apache Storm" data-type="indexterm" id="idm140176508131184"></a> By combining at-most once or at-least once semantics with per-record processing and no integrated (i.e., no consistent) notion of persistent state, <a contenteditable="false" data-primary="Apache Storm" data-secondary="bringing low-latency data processing to the masses" data-type="indexterm" id="idm140176508129456"></a>Storm was able provide much lower latency in providing results than systems that executed over batches of data and guaranteed exactly-once correctness. And for a certain type of use cases, this was a very reasonable trade-off to make.</p>

<p>Unfortunately, it quickly became clear that people really wanted to have their cake and eat it, too. They didn’t just want to get their answers quickly, they wanted to have both low-latency results <em>and</em> eventual correctness.<a contenteditable="false" data-primary="correctness" data-secondary="Apache Storm and" data-type="indexterm" id="idm140176508126544"></a> But such a thing was impossible <a contenteditable="false" data-primary="lambda architecture" data-type="indexterm" id="idm140176508125008"></a>with Storm alone.<a contenteditable="false" data-primary="CAP theorem" data-type="indexterm" id="idm140176508123776"></a> Enter the Lambda Architecture.</p>


<p>Given the limitations of Storm, shrewd engineers began running a weakly consistent Storm streaming pipeline alongside a strongly consistent Hadoop batch pipeline. The former produced low-latency, inexact results, whereas the latter produced high-latency, exact results, both of which would then be somehow merged together in the end to provide a single low-latency, eventually consistent view of the outputs. We learned back in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch01.html#streaming_one_oh_one">Chapter&nbsp;1</a> that the Lambda Architecture was Marz’s other brainchild, as detailed in his post titled <a href="http://bit.ly/1ATyjbD">“How to beat the CAP theorem”</a> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#how_to_beat_the_cap_theorem">Figure&nbsp;10-17</a>).<sup><a data-type="noteref" id="idm140176508118768-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508118768" class="totri-footnote">7</a></sup></p>

<figure class="floatleft"><div id="how_to_beat_the_cap_theorem" class="figure"><img alt="" class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1017.png" width="600" height="490" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1017.png">
<h6><span class="label">Figure 10-17. </span><a href="http://bit.ly/1ATyjbD">“How to beat the CAP theorem”</a></h6>
</div></figure>

<p>I’ve already spent a fair amount of time harping on the shortcomings of the Lambda Architecture, so I won’t belabor those points here. But I will reiterate this: the Lambda Architecture became quite popular, despite the costs and headaches associated with it, simply because it met a critical need that a great many businesses were otherwise having a difficult time fulfilling: that of getting low-latency, but eventually correct results out of their data processing pipelines.<a contenteditable="false" data-primary="latency" data-secondary="low-latency and eventually correct results with lambda architecture" data-type="indexterm" id="idm140176508113568"></a></p>

<p>From the perspective of the evolution of streaming systems, I argue that Storm was responsible for first bringing low-latency data processing to the masses. However, it did so at the cost of weak consistency, which in turn brought about the rise of the Lambda Architecture, and the years<a contenteditable="false" data-primary="Heron" data-type="indexterm" id="idm140176508111424"></a> of dual-pipeline darkness that followed.</p>

<figure class="floatright"><div id="heron_paper" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1018.png" width="600" height="456" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1018.png">
<h6><span class="label">Figure 10-18. </span><a href="http://bit.ly/2LNzOF4">Heron paper</a></h6>
</div></figure>

<p>But hyperbolic dramaticism aside, Storm was the system that gave the industry its first taste of low-latency data processing, and the impact of that is reflected in the broad interest in and adoption of streaming systems today.</p>

<p>Before moving on, it’s also worth giving a shout out to Heron. In 2015, Twitter (the largest known user of Storm in the world,<a contenteditable="false" data-primary="Twitter Heron" data-type="indexterm" id="idm140176508106240"></a> and the company that originally fostered the Storm project) surprised the industry by announcing it was abandoning the Storm execution engine in favor of a new system it had developed in house, called Heron. Heron aimed to address a number of performance and maintainability issues that had plagued Storm, while remaining API compatible, as detailed in the company’s paper titled <a href="http://bit.ly/2LNzOF4">“Twitter Heron: Stream Processing at Scale”</a> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#heron_paper">Figure&nbsp;10-18</a>). Heron itself was subsequently <a href="http://bit.ly/2MoOpYK">open sourced</a> (with governance moved to its own independent foundation, not an existing one like Apache). Given the continued development on Storm, there are now two competing variants of the Storm lineage. Where things will end up is anyone’s guess, but it will <a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Apache Storm" data-startref="ix_lgscdpApSt" data-type="indexterm" id="idm140176508101936"></a>be exciting to watch.<a contenteditable="false" data-primary="Apache Storm" data-startref="ix_ApStorm" data-type="indexterm" id="idm140176508100064"></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Spark"><div class="sect1" id="idm140176508148224">
<h1>Spark</h1>

<p>Moving on, we <a contenteditable="false" data-primary="Apache Spark" data-type="indexterm" id="ix_ApSpark"></a>now come to Apache Spark (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_spark">Figure&nbsp;10-19</a>). This is another section in which I’m going to greatly oversimplify the total impact that Spark has had on the industry by focusing on a specific portion of its contributions: those within the realm of stream processing. Apologies in advance.</p>

<figure><div id="timeline_spark" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1019.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1019.png">
<h6><span class="label">Figure 10-19. </span>Timeline: Spark</h6>
</div></figure>

<p>Spark got its start at the now famous AMPLab in UC Berkeley around 2009. The thing that initially fueled Spark’s fame was its ability to oftentimes perform the bulk of a pipeline’s calculations entirely in memory, without touching disk until the very end. Engineers achieved this<a contenteditable="false" data-primary="resilient distributed datasets (RDDs)" data-type="indexterm" id="idm140176508092112"></a> via the Resilient Distributed Dataset (RDD) idea, which basically captured the full lineage of data at any given point in the pipeline, allowing intermediate results to be recalculated as needed on machine failure, under the assumptions that a) your inputs were always replayable, and b) your computations were deterministic.<a contenteditable="false" data-primary="Hadoop" data-secondary="Spark as successor to" data-type="indexterm" id="idm140176508090528"></a> For many use cases, these preconditions were true, or at least true enough given the massive gains in performance users were able to realize over standard Hadoop jobs. From there, Spark gradually built up its eventual reputation as Hadoop’s de facto successor.</p>

<p>A few years after Spark was created, Tathagata Das, then a graduate student in the AMPLab, came to the realization that: hey, we’ve got this fast batch processing engine, what if we just wired things up so we ran multiple batches one after another, and used that to process streaming data? From that bit of insight, Spark Streaming was born.<a contenteditable="false" data-primary="Apache Spark" data-secondary="Spark Streaming" data-type="indexterm" id="idm140176508087984"></a>&nbsp;</p>

<p>What was really fantastic about Spark Streaming was this: thanks to the strongly consistent batch engine powering things under the covers, the world now had a stream processing engine that could provide correct results all by itself without needing the help of an additional batch job.<a contenteditable="false" data-primary="lambda architecture" data-secondary="using Spark Streaming instead of" data-type="indexterm" id="idm140176508085728"></a> In other words, given the right use case, you could ditch your Lambda Architecture system and just use Spark Streaming. All hail Spark Streaming!</p>

<p>The one major caveat here was the “right use case” part. The big downside to the original version of Spark Streaming (the 1.x variants) was that it provided support for only a specific flavor of stream processing: processing-time windowing. So any use case that cared about event time, needed to deal with late data, and so on, couldn’t be handled out of the box without a bunch of extra code being written by the user to implement some form of event-time handling on top of Spark’s processing-time windowing architecture. This meant that Spark Streaming was best suited for in-order data or event-time-agnostic computations. And, as I’ve reiterated throughout this book, those conditions are not as prevalent as you would hope when dealing with the large-scale, user-centric datasets common today.</p>

<p>Another interesting controversy that surrounds Spark Streaming is the age-old “microbatch versus true streaming” debate.<a contenteditable="false" data-primary="streaming" data-secondary="microbatch vs. true streaming debate" data-type="indexterm" id="idm140176508082240"></a><a contenteditable="false" data-primary="microbatch vs. true streaming debate" data-type="indexterm" id="idm140176508080960"></a> Because Spark Streaming is built upon the idea of small, repeated runs of a batch processing engine, detractors claim that Spark Streaming is not a true streaming engine in the sense that progress in the system is gated by the global barriers of each batch. There’s some amount of truth there. Even though true streaming engines almost always utilize some sort of batching or bundling for the sake of throughput, they have the flexibility to do so at much finer-grained levels, down to individual keys. The fact that microbatch architectures process bundles at a global level means that it’s virtually impossible to have both low per-key latency and high overall throughput, and there are a number of benchmarks that have shown this to be more or less true. But at the same time, latency on the order of minutes or multiple seconds is still quite good. And there are very few use cases that demand exact correctness and such stringent latency capabilities. So in some sense, Spark was absolutely right to target the audience it did originally; most people fall in that category. But that hasn’t stopped its competitors from slamming this as a massive disadvantage for the platform. Personally, I see it as a minor complaint at best in most cases.</p>

<p>Shortcomings aside, Spark Streaming was a watershed moment for stream processing: the first publicly available, large-scale stream processing engine that could also provide the correctness guarantees of a batch system. And of course, as previously noted, streaming is only a very small part of Spark’s overall success story, with important contributions made in the space of iterative processing and machine learning, its native SQL integration, <a contenteditable="false" data-primary="SQL" data-secondary="Spark integration with" data-type="indexterm" id="idm140176508077568"></a>and the aforementioned lightning-fast in-memory performance, to name a few.</p>

<p>If you’re curious to learn more about the details of the original Spark 1.x architecture, I highly recommend Matei Zaharia’s dissertation on the subject, <a href="http://bit.ly/2y8rduN">“An Architecture for Fast and General Data Processing on Large Clusters”</a> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#spark_dissertation">Figure&nbsp;10-20</a>). It’s 113 pages of Sparky goodness that’s well worth the investment.</p>

<figure class="floatleft"><div id="spark_dissertation" class="figure"><img alt="" class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1020.png" width="600" height="575" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1020.png">
<h6><span class="label">Figure 10-20. </span><a href="http://bit.ly/2y8rduN">Spark dissertation</a></h6>
</div></figure>

<p>As of today, the 2.x variants of Spark are greatly expanding upon the semantic capabilities of Spark Streaming, <a contenteditable="false" data-primary="Apache Spark" data-secondary="current developments in" data-type="indexterm" id="idm140176508070144"></a>incorporating many parts of the model described in this book, while attempting to simplify some of the more complex pieces. And Spark is even pushing a new true streaming architecture, to try to shut down the microbatch naysayer arguments. But when it first came on the scene, the important contribution that Spark brought to the table was the fact that it was the <em>first publicly available stream processing engine with strong consistency semantics</em>, albeit only in the case of in-order data or event-time-agnostic computation.<a contenteditable="false" data-primary="Apache Spark" data-startref="ix_ApSpark" data-type="indexterm" id="idm140176508067840"></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="MillWheel"><div class="sect1" id="idm140176508098192">
<h1>MillWheel</h1>

<p>Next we discuss MillWheel, a project that I first dabbled<a contenteditable="false" data-primary="MillWheel" data-type="indexterm" id="ix_MillWh"></a> with in <a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="MillWheel" data-type="indexterm" id="ix_lgscdpMW"></a>my 20% time after joining Google in 2008, later joining the team full time in 2010 (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_millwheel">Figure&nbsp;10-21</a>).</p>

<figure><div id="timeline_millwheel" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1021.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1021.png">
<h6><span class="label">Figure 10-21. </span>Timeline: MillWheel</h6>
</div></figure>

<p>MillWheel is Google’s original, general-purpose stream processing architecture, and the project was founded by Paul Nordstrom around the time Google’s Seattle office opened. MillWheel’s success within Google has long centered on an ability to provide low-latency, strongly consistent processing of unbounded, out-of-order data.<a contenteditable="false" data-primary="MillWheel" data-secondary="low-latency, strongly consistent processing of unbounded, out-of-order data" data-type="indexterm" id="idm140176508057856"></a><a contenteditable="false" data-primary="out-of-order data" data-secondary="unbounded, processing in MillWheel" data-type="indexterm" id="idm140176508056512"></a> Over the course of this book, we’ve looked at most of the bits and pieces that came together in MillWheel to make this possible:</p>

<ul>
	<li>
	<p>Reuven discussed <em>exactly-once guarantees</em> in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch05.html#exactly_once_and_side_effects">Chapter&nbsp;5</a>. Exactly-once guarantees<a contenteditable="false" data-primary="exactly-once processing" data-type="indexterm" id="idm140176508052048"></a> are essential for correctness.</p>
	</li>
	<li>
	<p>In <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch07.html#practicalities_of_persistent_state">Chapter&nbsp;7</a> we<a contenteditable="false" data-primary="persistent state" data-type="indexterm" id="idm140176508048880"></a> looked at <em>persistent state</em>, the strongly consistent variations of which provide the foundation for maintaining that correctness in long-running pipelines executing on unreliable hardware.</p>
	</li>
	<li>
	<p>Slava talked about <em>watermarks</em> in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch03.html#watermarks_chapter">Chapter&nbsp;3</a>. Watermarks <a contenteditable="false" data-primary="watermarks" data-type="indexterm" id="chap_ten_watermarks"></a>provide a foundation for reasoning about disorder in input data.</p>
	</li>
	<li>
	<p>Also in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch07.html#practicalities_of_persistent_state">Chapter&nbsp;7</a>, we looked at <em>persistent timers</em>, which provide the necessary link between watermarks and the pipeline’s business logic.<a contenteditable="false" data-primary="persistent timers" data-type="indexterm" id="idm140176508040656"></a><a contenteditable="false" data-primary="timers" data-type="indexterm" id="idm140176508039552"></a></p>
	</li>
</ul>

<p>It’s perhaps somewhat surprising then to note that the MillWheel project was not initially focused on correctness.<a contenteditable="false" data-primary="correctness" data-secondary="MillWheel and" data-type="indexterm" id="idm140176508037648"></a> Paul’s original vision more closely targeted the niche that Storm later espoused: low-latency data processing with weak consistency. It was the initial MillWheel customers, one building sessions over search data and another performing anomaly detection on search queries (the Zeitgeist example from the MillWheel paper), who drove the project in the direction of correctness. Both had a strong need for consistent results: sessions were used to infer user behavior, and anomaly detection was used to infer trends in search queries; the utility of both decreased significantly if the data they provided were not reliable. As a result, MillWheel’s direction was steered toward one of strong consistency.</p>

<p>Support for out-of-order processing, which is the other core aspect of robust streaming often attributed to MillWheel, was also motivated by customers.<a contenteditable="false" data-primary="Zeitgeist pipeline, true streaming use case" data-type="indexterm" id="idm140176508034624"></a> The Zeitgeist pipeline, as a true streaming use case, wanted to<a contenteditable="false" data-primary="streaming" data-secondary="Zeitgeist pipeline, true streaming use case" data-type="indexterm" id="idm140176508033360"></a> generate an output stream that identified anomalies in search query traffic, and only anomalies (i.e., it was not practical for consumers of its analyses to poll all the keys in a materialized view output table waiting for an anomaly to be flagged; consumers needed a direct signal only when anomalies happened for specific keys). For anomalous spikes (i.e., <em>increases</em> in query traffic), this is relatively straightforward: when the count for a given query exceeds the expected value in your model for that query by some statistically significant amount, you can signal an anomaly. But for anomalous dips (i.e., <em>decreases</em> in query traffic), the problem is a bit trickier. It’s not enough to simply see that the number of queries for a given search term has decreased, because for any period of time, the observed number always starts out at zero. What you really need to do in these cases is wait until you have reason to believe that you’ve seen a sufficiently representative portion of the input for a given time period, and only <em>then</em> compare the count against your model.</p>

<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before less_space"><div class="sidebar" id="idm140176508029424">
<h5>True Streaming</h5>

<p>“True streaming use case” bears a bit of explanation. One recent trend in streaming systems is to try to simplify the programming models to make them more accessible by limiting the types of use cases one can address. For example, at the time of writing, both Spark’s Structured Streaming and Apache Kafka’s Kafka Streams systems limit themselves to what I refer to in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch08.html#streaming_sql">Chapter&nbsp;8</a> as “materialized view semantics,” essentially repeated updates to an eventually consistent output table. Materialized view semantics are great when you want to consume your output as a lookup table: any time you can just lookup a value in that table and be okay with the latest result as of query time, materialized views are a good fit. They are not, however, particularly well suited for use cases in which you want to consume your output as a bonafide stream. I refer to these as true streaming use cases, with anomaly detection being one of the better examples.</p>

<p>As we’ll discuss shortly, there are certain aspects of anomaly detection that make it unsuitable for pure materialized view semantics (i.e., record-by-record processing only), specifically the fact that it relies on reasoning about the completeness of the input data to accurately identify anomalies that are the result of an absence of data (in addition to the fact that polling an output table to see if an anomaly signal has arrived is not an approach that scales particularly well). True streaming use cases are thus the motivation for features like watermarks (Preferably <em>low</em> watermarks that pessimistically track input completeness, as described in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch03.html#watermarks_chapter">Chapter&nbsp;3</a>, not <em>high</em> watermarks that track the event time of the newest record the system is aware of, as used by Spark Structured Streaming for garbage collecting windows, since high watermarks are more prone to incorrectly throwing away data as event time skew varies within the pipeline) and triggers. Systems that omit these features do so for the sake of simplicity but at the cost of decreased ability. There can be great value in that, most certainly, but don’t be fooled if you hear such systems claim these simplifications yield equivalent or even greater generality; you can’t address fewer use cases and be equally or more general.</p>
</div></aside>

<p>The Zeitgeist pipeline first attempted to do this by inserting processing-time delays before the analysis logic that looked for dips. This would work reasonably decently when data arrived in order, but the pipeline’s authors discovered that data could, at times, be greatly delayed and thus arrive wildly out of order. In these cases, the processing-time delays they were using weren’t sufficient, because the pipeline would erroneously report a flurry of dip anomalies that didn’t actually exist. What they really needed was a way to wait until the input became complete.</p>

<p>Watermarks were thus born out of this need for reasoning about input completeness in out-of-order data.<a contenteditable="false" data-primary="watermarks" data-type="indexterm" data-startref="chap_ten_watermarks" id="idm140176508020720"></a> As Slava described in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch03.html#watermarks_chapter">Chapter&nbsp;3</a>, the basic idea was to track the known progress of the inputs being provided to the system, using as much or as little data available for the given type of data source, to construct a progress metric that could be used to quantify input completeness. For simpler input sources like a statically partitioned Kafka topic with each partition being written to in increasing event-time order (such as by web frontends logging events in real time), you can compute a perfect watermark. For more complex input sources like a dynamic set of input logs, a heuristic might be the best you can do. But either way, watermarks provide a distinct advantage over the alternative of using processing time to reason <a contenteditable="false" data-primary="MillWheel" data-secondary="fault-tolerant stream processing at internet scale" data-type="indexterm" id="idm140176508017504"></a>about event-time completeness, which experience has shown serves about as well as a map of London while trying to navigate the streets of Cairo.</p>

<p>So thanks to the needs of its customers, MillWheel ended up as a system with the right set of features for supporting robust stream processing on out-of-order data. As a result, the paper titled <a href="http://bit.ly/2yab5ZH">“MillWheel: Fault-Tolerant Stream Processing at Internet Scale”</a><sup><a data-type="noteref" id="idm140176508014624-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508014624" class="totri-footnote">8</a></sup> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#millwheel_paper">Figure&nbsp;10-22</a>) spends most of its time discussing the difficulties of providing correctness in a system like this, with consistency guarantees and watermarks being the main areas of focus. It’s well worth your time if you’re interested in the subject.</p>

<figure class="floatright"><div id="millwheel_paper" class="figure"><img alt="" class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1022.png" width="600" height="395" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1022.png">
<h6><span class="label">Figure 10-22. </span><a href="http://bit.ly/2yab5ZH">MillWheel paper</a></h6>
</div></figure>

<p>Not long after the MillWheel paper was published, MillWheel was integrated as an alternative, streaming backend for Flume, together often referred to as Streaming Flume.<a contenteditable="false" data-primary="Flume" data-secondary="MillWheel integration with" data-type="indexterm" id="idm140176508008992"></a> Within Google today, MillWheel is in the process of being replaced by its successor,<a contenteditable="false" data-primary="Windmill" data-type="indexterm" id="idm140176508007472"></a> Windmill (the execution engine that also powers Cloud Dataflow, discussed in a moment), a ground-up rewrite that incorporates all the best ideas from MillWheel, along with a few new ones like better scheduling and dispatch, and a cleaner separation of user and system code.</p>

<p>However, the big takeaway for MillWheel is that the four concepts listed earlier (exactly-once, persistent state, watermarks, persistent timers) together provided the basis for a system that was finally able to deliver on the true promise of stream processing: robust, low-latency processing of out-of-order data, even on unreliable commodity hardware.<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="MillWheel" data-startref="ix_lgscdpMW" data-type="indexterm" id="idm140176508005168"></a><a contenteditable="false" data-primary="MillWheel" data-startref="ix_MillWh" data-type="indexterm" id="idm140176508003488"></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Kafka"><div class="sect1" id="idm140176508065808">
<h1>Kafka</h1>

<p>We now come to Kafka (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_kafka">Figure&nbsp;10-23</a>). <a contenteditable="false" data-primary="Apache Kafka" data-type="indexterm" id="ix_ApKafka"></a>Kafka is unique among the systems discussed in this chapter<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Apache Kafka" data-type="indexterm" id="ix_lgscdpAK"></a> in that it’s not a data processing framework,<sup><a data-type="noteref" id="idm140176507996064-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507996064" class="totri-footnote">9</a></sup> but instead a transport layer. Make no mistake, however: Kafka has played one of the most influential roles in advancing stream processing out of all the system’s we’re discussing here.</p>

<figure><div id="timeline_kafka" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1023.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1023.png">
<h6><span class="label">Figure 10-23. </span>Timeline: Kafka</h6>
</div></figure>

<p>If you’re not familiar with it, Kafka is essentially a persistent streaming transport, implemented as a set of partitioned logs. It was developed originally at LinkedIn by such industry luminaries as Neha Narkhede and Jay Kreps, and its accolades include the<a contenteditable="false" data-primary="Apache Kafka" data-secondary="capabilities of" data-type="indexterm" id="idm140176507992768"></a> following:</p>

<ul>
	<li>
	<p>Providing a clean model of persistence that packaged that warm fuzzy feeling of <em>durable</em>, <em>replayable input sources</em> from the batch world in a streaming friendly interface.</p>
	</li>
	<li>
	<p>Providing an elastic <em>isolation layer</em> between producers and consumers.</p>
	</li>
	<li>
	<p>Embodying the relationship between <em>streams and tables</em> that we discussed in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch06.html#streams_and_tables">Chapter&nbsp;6</a>, revealing a foundational<a contenteditable="false" data-primary="streams and tables" data-secondary="Kafka as embodiment of relationship between" data-type="indexterm" id="idm140176507985296"></a> way of thinking about data processing in general while also providing a conceptual link to the rich and storied world of databases.</p>
	</li>
	<li>
	<p>As of side of effect of all of the above, not only becoming the <em>cornerstone</em> of a majority of stream processing installations across the industry, but also fostering the stream-processing-as-databases and microservices movements.</p>
	</li>
</ul>

<p>They must get up very early in the morning.</p>

<p>Of those accolades, there are two that stand out most to me. The first is the application of durability and replayability to stream data.<a contenteditable="false" data-primary="Apache Kafka" data-secondary="application of durability and replayability to stream data" data-type="indexterm" id="idm140176507980768"></a> Prior to Kafka, most stream processing systems used some sort of ephemeral queuing system like Rabbit MQ or even plain-old TCP sockets to send data around. Durability might be provided to some degree via upstream backup in the producers (i.e., the ability for upstream producers of data to resend if the downstream workers crashed), but oftentimes the upstream data was stored ephemerally, as well. And most approaches entirely ignored the idea of being able to replay input data later in cases of backfills or for prototyping, development, and regression testing.</p>

<p>Kafka changed all that. By taking the battle-hardened concept of a durable log from the database world and applying it to the realm of stream processing, Kafka gave us all back that sense of safety and security we’d lost when moving from the durable input sources common in the Hadoop/batch world to the ephemeral sources prevalent at the time in the streaming world. With durability and replayability, stream processing took yet another step toward being a robust, reliable replacement for the ad hoc, continuous batch processing systems of yore that were still being applied to streaming use cases.</p>

<p>As a streaming system developer, one of the more interesting visible artifacts of the impact that Kafka’s durability and replayability features have had on the industry is how many of the stream processing engines today have grown to fundamentally rely on that replayability to provide end-to-end exactly-once guarantees. <a contenteditable="false" data-primary="exactly-once processing" data-secondary="end-to-end" data-type="indexterm" id="idm140176507976848"></a><a contenteditable="false" data-primary="end-to-end exactly once" data-type="indexterm" id="idm140176507975472"></a>Replayability is the foundation upon which end-to-end exactly-once guarantees in Apex, Flink, Kafka Streams, Spark, and Storm are all built. When executing in exactly-once mode, each of those systems assumes/requires that the input data source be able to rewind and replay all of the data up until the most recent checkpoint. When used with an input source that does not provide such ability (even if the source can guarantee reliable delivery via upstream backup), end-to-end exactly-once semantics fall apart. That sort of broad reliance on replayability (and the related aspect of durability) is a huge testament to the amount of impact those features have had across the industry.</p>

<p>The second noteworthy bullet from Kafka’s resume is the popularization of stream and table theory.<a contenteditable="false" data-primary="Apache Kafka" data-secondary="popularization of stream and table theory" data-type="indexterm" id="idm140176507972784"></a> We spent the entirety of <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch06.html#streams_and_tables">Chapter&nbsp;6</a> discussing streams and tables as well as much of Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="/site/library/view/streaming-systems/9781491983867/ch08.html#streaming_sql" class="totri-footnote">8</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="/site/library/view/streaming-systems/9781491983867/ch09.html#streaming_joins" class="totri-footnote">9</a>. And for good reason. <a contenteditable="false" data-primary="streams and tables" data-secondary="popularization of theory by Apache Kafka" data-type="indexterm" id="idm140176507967648"></a>Streams and tables form the foundation of data processing, be it the MapReduce family tree of systems, the enormous legacy of SQL database systems, or what have you. Not all data processing approaches need speak directly in terms of streams and tables but conceptually speaking, that’s how they all operate. And as both users and developers of these systems, there’s great value in understanding the core underlying concepts that all of our systems build upon. We all owe a collective thanks to the folks in the Kafka community who helped shine a broader light on the streams-and-tables way of thinking.</p>

<figure class="floatleft"><div id="i_love_logs" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1024.png" width="500" height="656" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1024.png">
<h6><span class="label">Figure 10-24. </span>I ❤ Logs</h6>
</div></figure>

<p>If you’d like to learn more about Kafka and the foundations it’s built on, <em>I ❤ Logs</em> by Jay Kreps (O’Reilly; <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#i_love_logs">Figure&nbsp;10-24</a>) is an excellent resource.<sup><a data-type="noteref" id="idm140176507961456-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507961456">10</a></sup> Additionally, as cited originally in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch06.html#streams_and_tables">Chapter&nbsp;6</a>, Kreps and Martin Kleppmann have a pair of articles (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#martins_post">Figure&nbsp;10-25</a>) that I highly recommend for reading up on the origins of streams and table theory.</p>


<p>Kafka <a contenteditable="false" data-primary="Apache Kafka" data-secondary="Kafka's Streams API" data-type="indexterm" id="idm140176507958304"></a>has made huge contributions to the world of stream processing, arguably more than any other single system out there. In particular, the application of durability and replayability to input and output streams played a big part in helping move stream processing out of the niche realm of approximation tools and into the big leagues of general data processing. Additionally, the theory of streams and tables, popularized<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Apache Kafka" data-startref="ix_lgscdpAK" data-type="indexterm" id="idm140176507956336"></a> by the Kafka community, provides deep insight into the underlying mechanics of data processing in general.&nbsp;<a contenteditable="false" data-primary="Apache Kafka" data-startref="ix_ApKafka" data-type="indexterm" id="idm140176507954336"></a></p>

<figure><div id="martins_post" class="figure"><img alt="" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1025.png" width="600" height="251" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1025.png">
<h6><span class="label">Figure 10-25. </span><a href="https://www.confluent.io/blog/making-sense-of-stream-processing/">Martin’s post</a> (left) and <a href="https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/">Jay’s post</a> (right)</h6>
</div></figure>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Cloud Dataflow"><div class="sect1" id="idm140176508001520">
<h1>Cloud Dataflow</h1>

<p>Cloud Dataflow (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_cloud_dataflow">Figure&nbsp;10-26</a>) is Google’s fully managed,<a contenteditable="false" data-primary="Cloud Dataflow" data-type="indexterm" id="ix_ClData"></a> cloud-based data processing service. Dataflow launched to<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Cloud Dataflow" data-type="indexterm" id="ix_lgscdpCD"></a> the world in August 2015. It was built with the intent to take the decade-plus of experiences that had gone into building MapReduce, Flume, and MillWheel, and package them up into a serverless cloud experience.</p>

<figure><div id="timeline_cloud_dataflow" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1027.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1027.png">
<h6><span class="label">Figure 10-26. </span>Timeline: Cloud Dataflow</h6>
</div></figure>

<p>Although the serverless aspect of Cloud Dataflow is perhaps<a contenteditable="false" data-primary="Cloud Dataflow" data-secondary="serverless aspect of" data-type="indexterm" id="idm140176507941264"></a> its most technically challenging and distinguishing factor from a systems perspective, the primary contribution to streaming systems that I want to discuss here is its unified batch plus streaming programming model. <a contenteditable="false" data-primary="batch processing" data-secondary="unified batch plus streaming programming model" data-type="indexterm" id="idm140176507939440"></a><a contenteditable="false" data-primary="Cloud Dataflow" data-secondary="unified batch plus streaming programming model" data-type="indexterm" id="idm140176507938032"></a><a contenteditable="false" data-primary="streaming" data-secondary="unified batch plus streaming programming model" data-type="indexterm" id="idm140176507936624"></a>That’s all the transformations, windowing, watermarks, triggers, and accumulation goodness we’ve spent most of the book talking about. And all of them, of course, wrapped up the <em><span class="what_lt">what</span></em>/<em><span class="where_lt">where</span></em>/<em><span class="when_lt">when</span></em>/<em><span class="how_lt">how</span></em> way of thinking about things.<a contenteditable="false" data-primary="data processing" data-secondary="what, where, when, and how of" data-type="indexterm" id="idm140176507931504"></a></p>

<p>The model first arrived back in Flume, as <a contenteditable="false" data-primary="Flume" data-secondary="combined batch and streaming approach in" data-type="indexterm" id="idm140176507929840"></a>we looked to incorporate the robust out-of-order processing support in MillWheel into the higher-level programming model Flume afforded. The combined batch and streaming approach available to Googlers internally with Flume was then the basis for the fully unified model included in Dataflow.</p>

<p>The key insight in the unified model—the full extent of which none of us at the time even truly appreciated—is that under the covers, batch and <a contenteditable="false" data-primary="streaming" data-secondary="commonalities between batch and streaming" data-type="indexterm" id="idm140176507927328"></a>streaming<a contenteditable="false" data-primary="batch processing" data-secondary="commonalities between batch and streaming" data-type="indexterm" id="idm140176507925792"></a> are really not that different: they’re both just minor variations on the streams and tables theme. As we learned in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch06.html#streams_and_tables">Chapter&nbsp;6</a>, the main difference really boils down to the ability to incrementally trigger tables into streams; everything else is conceptually the same.<sup><a data-type="noteref" id="idm140176507922976-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507922976">11</a></sup> By taking advantage of the underlying commonalities of the two approaches, it was possible to provide a single, nearly seamless experience that applied to both worlds. This was a big step forward in making stream processing more accessible.</p>

<p>In addition to taking advantage of the commonalities between batch and streaming, we took a long, hard look at the variety of use cases we’d encountered over the years at Google and used those to inform the pieces that went into the unified model.<a contenteditable="false" data-primary="Cloud Dataflow" data-secondary="unified batch and streaming programming model" data-tertiary="key aspects of" data-type="indexterm" id="idm140176507919792"></a> Key aspects we targeted included the following:</p>

<ul>
	<li>
	<p><em>Unaligned, event-time windows</em> such as sessions, providing <a contenteditable="false" data-primary="windowing" data-secondary="in Cloud Dataflow" data-type="indexterm" id="idm140176507916448"></a>the ability to concisely express powerful analytic constructs and apply them to out-of-order data.</p>
	</li>
	<li>
	<p><em>Custom windowing support</em>, because one (or even three or four) sizes rarely fit all.</p>
	</li>
	<li>
	<p><em>Flexible triggering</em> and <em>accumulation modes</em>, providing the ability to shape the way data flow through the pipeline to match the correctness, latency, and cost needs of the given use case.<a contenteditable="false" data-primary="flexibility" data-secondary="flexible triggering and accumulation modes" data-type="indexterm" id="idm140176507911872"></a></p>
	</li>
	<li>
	<p>The use of <em>watermarks</em> for reasoning about <em>input completeness</em>, which is critical for use cases<a contenteditable="false" data-primary="watermarks" data-secondary="use in Cloud Dataflow" data-type="indexterm" id="idm140176507908592"></a> like anomalous dip detection where the analysis depends upon an absence of data.<a contenteditable="false" data-primary="completeness" data-secondary="watermarks for reasoning about input completeness" data-type="indexterm" id="idm140176507907088"></a><a contenteditable="false" data-primary="input completeness" data-type="indexterm" id="idm140176507905584"></a></p>
	</li>
	<li>
	<p><em>Logical abstraction</em> of the underlying execution environment, be <a contenteditable="false" data-primary="logical abstraction of execution environment" data-type="indexterm" id="idm140176507903328"></a>it batch, microbatch, or streaming, providing flexibility of choice in execution engine and avoiding system-level constructs (such as micro-batch size) from creeping into the logical API.</p>
	</li>
</ul>

<p>Taken together, these aspects provided the flexibility <a contenteditable="false" data-primary="Cloud Dataflow" data-secondary="balancing correctness, latency, and cost" data-type="indexterm" id="idm140176507901280"></a>to balance the tensions between<a contenteditable="false" data-primary="correctness" data-secondary="balancing with latency and cost in Cloud Dataflow" data-type="indexterm" id="idm140176507899648"></a> correctness, latency, <a contenteditable="false" data-primary="latency" data-secondary="balancing with correctness and cost in Cloud Dataflow" data-type="indexterm" id="idm140176507898112"></a>and cost, allowing the model to<a contenteditable="false" data-primary="Dataflow Model paper" data-type="indexterm" id="idm140176507896496"></a> be applied across a wide breadth of use cases.<a contenteditable="false" data-primary="Cloud Dataflow" data-secondary="Dataflow Model paper" data-type="indexterm" id="idm140176507895264"></a></p>

<figure class="floatright"><div id="dataflow_model_paper" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1028.png" width="600" height="527" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1028.png">
<h6><span class="label">Figure 10-27. </span><a href="http://bit.ly/2sXgVJ3">Dataflow Model paper</a></h6>
</div></figure>

<p>Given that you’ve just read an entire book covering the finer points of the Dataflow/Beam Model, there’s little point in trying to retread any those concepts here. However, if you’re looking for a slightly more academic take on things as well as a nice overview of some of the motivating use cases alluded to earlier, you might find our 2015 <a href="http://bit.ly/2sXgVJ3">Dataflow Model paper</a> worthwhile (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#dataflow_model_paper">Figure&nbsp;10-27</a>).</p>

<p>Though there are many other compelling aspects to Cloud Dataflow, the important contribution from the perspective of this chapter is its <em>unified batch plus streaming programming model</em>. It brought the world a comprehensive approach to tackling unbounded, out-of-order datasets, and in a way that provided the flexibility to make the trade-offs necessary to balance the tensions between correctness, latency, and cost to match the requirements for a given use case.<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Cloud Dataflow" data-startref="ix_lgscdpCD" data-type="indexterm" id="idm140176507887520"></a><a contenteditable="false" data-primary="Cloud Dataflow" data-startref="ix_ClData" data-type="indexterm" id="idm140176507885808"></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Flink"><div class="sect1" id="idm140176507949168">
<h1>Flink</h1>

<p>Flink (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_flink">Figure&nbsp;10-28</a>) burst onto the scene in 2015, rapidly transforming<a contenteditable="false" data-primary="Apache Flink" data-type="indexterm" id="ix_ApFlink"></a> itself from a system that almost no one had heard of into one of the powerhouses of the streaming world, seemingly overnight.</p>

<figure><div id="timeline_flink" class="figure"><img src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1029.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1029.png">
<h6><span class="label">Figure 10-28. </span>Timeline: Flink</h6>
</div></figure>

<p>There were two main reasons for Flink’s rise to prominence:</p>

<ul>
	<li>
	<p>Its <em>rapid adoption of the Dataflow/Beam programming model</em>, which <a contenteditable="false" data-primary="Apache Flink" data-secondary="adoption of Dataflow/Beam programming model" data-type="indexterm" id="idm140176507876432"></a>put it in the position of being the most semantically capable fully open source streaming system on the planet at the time.</p>
	</li>
	<li>
	<p>Followed shortly <a contenteditable="false" data-primary="Apache Flink" data-secondary="highly efficient snapshotting implementation" data-type="indexterm" id="idm140176507873600"></a>thereafter <a contenteditable="false" data-primary="snapshots" data-secondary="Flink's highly efficient snapshotting implementation" data-type="indexterm" id="idm140176507872032"></a>by its <em>highly efficient snapshotting</em> implementation (derived from research in Chandy and Lamport’s original paper <a href="http://bit.ly/2JBCsRU">“Distributed Snapshots: Determining Global States of Distributed Systems”</a> [<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#chandy_lamport_snapshots">Figure&nbsp;10-29</a>]), which gave it the strong consistency guarantees needed for correctness.<a contenteditable="false" data-primary="Chandy Lamport distributed snapshots" data-type="indexterm" id="idm140176507868288"></a></p>
	</li>
</ul>

<figure class="floatleft"><div id="chandy_lamport_snapshots" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1030.png" width="600" height="525" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1030.png">
<h6><span class="label">Figure 10-29. </span><a href="http://bit.ly/2JBCsRU">Chandy-Lamport snapshots</a></h6>
</div></figure>

<p>Reuven covered Flink’s consistency mechanism briefly in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch05.html#exactly_once_and_side_effects">Chapter&nbsp;5</a>, but to reiterate, the basic idea is that periodic barriers are propagated along the communication paths between workers in the system.<a contenteditable="false" data-primary="consistency" data-secondary="consistency mechanism in Flink" data-type="indexterm" id="idm140176507862800"></a><a contenteditable="false" data-primary="Apache Flink" data-secondary="consistency mechanism" data-type="indexterm" id="idm140176507861392"></a><a contenteditable="false" data-primary="exactly-once processing" data-secondary="in Apache Flink" data-type="indexterm" id="idm140176507860016"></a> The barriers act as an alignment mechanism between the various distributed workers producing data upstream from a consumer. When the consumer receives a given barrier on all of its input channels (i.e., from all of its upstream producers), it checkpoints its current progress for all active keys, at which point it is then safe to acknowledge processing of all data that came before the barrier.<a contenteditable="false" data-primary="checkpointing" data-secondary="in Flink" data-type="indexterm" id="idm140176507858096"></a> By tuning how frequently barriers are sent through the system, it’s possible to tune the frequency of checkpointing and thus trade off increased latency (due to the need for side effects to be materialized only at checkpoint times) in exchange for higher throughput.</p>

<figure class="floatright"><div id="extending_the_yahoo_streaming_benchmark" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1031.png" width="600" height="657" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1031.png">
<h6><span class="label">Figure 10-30. </span><a href="http://bit.ly/2LQvGnN">“Extending the Yahoo! Streaming Benchmark”</a></h6>
</div></figure>

<p>The simple fact that Flink now had the capability to provide exactly-once semantics along with native support for event-time processing was huge at the time. But it wasn’t until Jamie Grier published his article titled <a href="http://bit.ly/2LQvGnN">“Extending the Yahoo! Streaming Benchmark”</a> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#extending_the_yahoo_streaming_benchmark">Figure&nbsp;10-30</a>) that it became clear just how performant Flink was. In that article, Jamie described two impressive<a contenteditable="false" data-primary="Apache Flink" data-secondary="impressive performance of" data-type="indexterm" id="idm140176507851232"></a> achievements:</p>

<ol>
	<li>
	<p>Building a prototype Flink pipeline that achieved greater accuracy than one of Twitter’s existing Storm pipelines (thanks to Flink’s exactly-once semantics) at 1% of the cost of the original.</p>
	</li>
	<li>
	<p>Updating the <a href="http://bit.ly/2bhgMJd">Yahoo! Streaming Benchmark</a> to show Flink (with exactly-once) achieving 7.5 times the throughput of Storm (without exactly-once). Furthermore, Flink’s performance was shown to be limited due to network saturation; removing the network bottleneck allowed Flink to achieve almost 40 times the throughput of Storm.</p>
	</li>
</ol>

<p>Since then, numerous other projects (notably, Storm and Apex) have all adopted the same type of consistency<a contenteditable="false" data-primary="savepoints" data-type="indexterm" id="idm140176507845696"></a> mechanism.</p>

<figure class="floatleft"><div id="savepoints_turning_back_time" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1032.png" width="600" height="630" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1032.png">
<h6><span class="label">Figure 10-31. </span><a href="http://bit.ly/2JKCouO">“Savepoints: Turning Back Time”</a></h6>
</div></figure>

<p>With the addition of a snapshotting mechanism, Flink gained the strong consistency needed for end-to-end exactly-once.<a contenteditable="false" data-primary="snapshots" data-secondary="Flink's highly efficient snapshotting implementation" data-type="indexterm" id="idm140176507841344"></a><a contenteditable="false" data-primary="Apache Flink" data-secondary="savepoints feature" data-type="indexterm" id="idm140176507839872"></a> But to its credit, Flink went one step further, and used the global nature of its snapshots to provide the ability to restart an entire pipeline from any point in the past, a feature known as savepoints (described in the <a href="http://bit.ly/2JKCouO">“Savepoints: Turning Back Time”</a> post by Fabian Hueske and Michael Winters [<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#savepoints_turning_back_time">Figure&nbsp;10-31</a>]). The savepoints feature took the warm fuzziness of durable replay that Kafka had applied to the streaming transport layer and extended it to cover the breadth of an entire pipeline. Graceful evolution of a long-running streaming pipeline over time remains an important open problem in the field, with lots of room for improvement. But Flink’s savepoints feature stands as one of the first huge steps in the right direction, and one that remains unique across the industry as of this writing.</p>

<p>If you’re<a contenteditable="false" data-primary="State Management in Apache Flink" data-type="indexterm" id="idm140176507835504"></a> interested in learning more about the system constructs underlying Flink’s snapshots and savepoints, the paper <a href="http://bit.ly/2LLyr9O">“State Management in Apache Flink”</a> (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#state_management_in_apache_flink">Figure&nbsp;10-32</a>) discusses the implementation in good detail.</p>

<figure class="floatright"><div id="state_management_in_apache_flink" class="figure"><img class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1033.png" width="600" height="535" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1033.png">
<h6><span class="label">Figure 10-32. </span><a href="http://bit.ly/2LLyr9O">“State Management in Apache Flink”</a></h6>
</div></figure>

<p>Beyond savepoints, the Flink community has continued to innovate, including bringing the first practical streaming SQL API to market for a large-scale, distributed stream processing engine, as we discussed in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch08.html#streaming_sql">Chapter&nbsp;8</a>.</p>

<p>In summary, Flink’s rapid rise to stream<a contenteditable="false" data-primary="Apache Flink" data-secondary="factors in its rapid rise to stream procesing juggernaut" data-type="indexterm" id="idm140176507827424"></a> processing juggernaut can be attributed primarily to three characteristics of its approach: 1) incorporating the <em>best existing ideas</em> from across the industry (e.g., being the first open source adopter of the Dataflow/Beam Model), 2) <em>bringing its own innovations</em> to the table to push forward the state of the art (e.g., strong consistency via snapshots and savepoints, streaming SQL), and 3) doing both of those things <em>quickly</em> and <em>repeatedly</em>. Add in the fact that all of this is done in <em>open source</em>, and you can see why Flink has consistently continued to raise the bar for streaming processing across the industry.<a contenteditable="false" data-primary="Apache Flink" data-startref="ix_ApFlink" data-type="indexterm" id="idm140176507823184"></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Beam"><div class="sect1" id="idm140176507883840">
<h1>Beam</h1>

<p>The last system we talk<a contenteditable="false" data-primary="Apache Beam" data-type="indexterm" id="ix_ApBeam"></a> about is Apache<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Apache Beam" data-type="indexterm" id="ix_lgscdpAB"></a> Beam (<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#timeline_beam">Figure&nbsp;10-33</a>). Beam differs from most of the other systems in this chapter in that it’s primarily a programming model, API, and portability layer, not a full stack with an execution engine underneath. But that’s exactly the point: just as SQL acts as a lingua franca for declarative data processing, Beam aims to be the lingua franca for programmatic data processing. Let’s explore how.</p>

<figure><div id="timeline_beam" class="figure"><img class="iimagesfig_10timeline10_beampng" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1034.png" width="600" height="277" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1034.png">
<h6><span class="label">Figure 10-33. </span>Timeline: Beam</h6>
</div></figure>

<p>Concretely, Beam is composed a number <a contenteditable="false" data-primary="Apache Beam" data-secondary="components" data-type="indexterm" id="idm140176507813392"></a>of components:</p>

<ul>
	<li>
	<p>A unified batch plus streaming <em>programming model</em>, inherited from Cloud Dataflow where<a contenteditable="false" data-primary="streaming" data-secondary="unified batch plus streaming programming model" data-type="indexterm" id="idm140176507810336"></a> it originated, and the <a contenteditable="false" data-primary="batch processing" data-secondary="unified batch plus streaming programming model" data-type="indexterm" id="idm140176507808608"></a>finer points of which <a contenteditable="false" data-primary="unified batch plus streaming programming model" data-secondary="in Apache Beam" data-type="indexterm" id="idm140176507807072"></a>we’ve spent the majority of this book discussing. The model is independent of any language implementations or runtime systems. You can think of this as Beam’s equivalent to SQL’s relational algebra.</p>
	</li>
	<li>
	<p>A set of <em>SDKs (software development kits)</em> that implement that<a contenteditable="false" data-primary="SDKs (software development kits) in Apache Beam" data-type="indexterm" id="idm140176507803920"></a> model, allowing pipelines to be expressed in terms of the model in idiomatic ways for a given language. Beam currently provides SDKs in Java, Python, and Go. You can think of these as Beam’s programmatic equivalents to the SQL language itself.</p>
	</li>
	<li>
	<p>A set of <em>DSLs (domain specific languages)</em> that build <a contenteditable="false" data-primary="domain specific languages (DSLs)" data-type="indexterm" id="idm140176507801040"></a>upon the SDKs, providing specialized interfaces that capture pieces of the model in unique ways.<a contenteditable="false" data-primary="DSLs (domain specific languages)" data-type="indexterm" id="idm140176507799632"></a> Whereas SDKs are required to surface all aspects of the model, DSLs can expose only those pieces that make sense for the specific domain a DSL is targeting. Beam currently provides a Scala DSL called Scio and an SQL DSL, both of which layer on top of the existing Java SDK.</p>
	</li>
	<li>
	<p>A set of <em>runners</em> that <a contenteditable="false" data-primary="runners in Apache Beam" data-type="indexterm" id="idm140176507796784"></a>can execute Beam pipelines. Runners take the logical pipeline described in Beam SDK terms, and translate them as efficiently as possible into a physical pipeline that they can then execute. Beam runners exist currently for Apex, Flink, Spark, and Google Cloud Dataflow. In SQL terms, you can think of these runners as Beam’s equivalent to the various SQL database implementations, such as Postgres, MySQL, Oracle, and so on.</p>
	</li>
</ul>

<p>The core vision for Beam is built around its value as a portability layer, and one of the more compelling features in that realm is its planned support for full cross-language portability.<a contenteditable="false" data-primary="Apache Beam" data-secondary="portability layer" data-type="indexterm" id="idm140176507794192"></a> Though not yet fully complete  (but <a href="http://bit.ly/2N0tPNL">landing imminently</a>), the plan is for Beam to provide sufficiently performant abstraction layers between SDKs and runners that will allow for a full cross-product of SDK × runner matchups. In such a world, a pipeline written in a JavaScript SDK could seamlessly execute on a runner written in Haskell, even if the Haskell runner itself had no native ability to execute JavaScript code.</p>

<p>As an abstraction layer, the way that Beam positions itself relative to its runners is critical to ensure that Beam actually brings value to the community, rather than introducing just an unnecessary layer of abstraction. The key point here is that Beam aims to never be just the intersection (lowest common denominator) or union (kitchen sink) of the features found in its runners.<a contenteditable="false" data-primary="Apache Beam" data-secondary="innovation in" data-type="indexterm" id="idm140176507790800"></a> Instead, it aims to include only the best ideas across the data processing community at large. This allows for innovation in two dimensions:</p>

<dl>
	<dt>Innovation in Beam</dt>
	<dd>
	<figure class="floatright"><div id="powerful_and_modular_io" class="figure"><img alt="" class="width_95" src="https://www.safaribooksonline.com/library/view/streaming-systems/9781491983867/assets/stsy_1035.png" width="600" height="422" data-mfp-src="/library/view/streaming-systems/9781491983867/assets/stsy_1035.png">
	<h6><span class="label">Figure 10-34. </span><a href="http://bit.ly/2JQa7GJ">Powerful and modular I/O</a></h6>
	</div></figure>

	<p>Beam might include API support for runtime features that not all runners initially support. This is okay. Over time, we expect many runners will incorporate such features into future versions; those that don’t will be a less-attractive runner choice for use cases that need such features.</p>

	<p>An example here is Beam’s SplittableDoFn API for writing composable, scalable sources (described by Eugene Kirpichov in his post <a href="http://bit.ly/2JQa7GJ">“Powerful and modular I/O connectors with Splittable DoFn in Apache Beam”</a> [<a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch10.html#powerful_and_modular_io">Figure&nbsp;10-34</a>]). It’s both unique and extremely powerful but also does not yet see broad support across all runners for some of the more innovative parts like dynamic work rebalancing. Given the value such features bring, however, we expect that will change over time.</p>
	</dd>
	<dt>Innovation in runners</dt>
	<dd>
	<p>Runners might introduce runtime features <a contenteditable="false" data-primary="runners in Apache Beam" data-secondary="innovation in" data-type="indexterm" id="idm140176507780704"></a>for which Beam does not initially provide API support. This is okay. Over time, runtime features that have proven their usefulness will have API support incorporated into Beam.</p>

	<p>An example here is the state snapshotting mechanism in Flink, or savepoints, which we discussed earlier. Flink is still the only publicly available streaming system to support snapshots in this way, but there’s a proposal in Beam to provide an API around snapshots because we believe graceful evolution of pipelines over time is an important feature that will be valuable across the industry. If we were to magically push out such an API today, Flink would be the only runtime system to support it. But again, that’s okay. The point here is that the industry as a whole will begin to catch up over time as the value of these features becomes clear.<sup><a data-type="noteref" id="idm140176507777920-marker" href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507777920">12</a></sup> And that’s better for everyone.</p>
	</dd>
</dl>

<p>By encouraging innovation within both Beam itself as well as runners, we hope to push forward the capabilities of the entire industry at a greater pace over time, without accepting compromises along the way. And by delivering on the promise of portability across runtime execution engines, we hope to establish Beam as the common language for expressing programmatic data processing pipelines, similar to how SQL exists today as the common currency of declarative data processing. It’s an ambitious goal, and as of writing, we’re still a ways off from seeing it fully realized, but we’ve also come a long way so far.<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-secondary="Apache Beam" data-startref="ix_lgscdpAB" data-type="indexterm" id="idm140176507775168"></a></p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm140176507773296">
<h1>Summary</h1>

<p>We just took a whirlwind tour through a decade and a half of advances in data processing technology, with a focus on the contributions that made streaming systems what they are today. To summarize one last time, the main takeaways for each system were:</p>

<dl>
	<dt>MapReduce—scalability and simplicity</dt>
	<dd>
	<p>By providing a simple set of abstractions for data <a contenteditable="false" data-primary="MapReduce" data-type="indexterm" id="idm140176507769552"></a>processing on top of a robust and scalable <a contenteditable="false" data-primary="scalability" data-secondary="in MapReduce" data-type="indexterm" id="idm140176507768256"></a>execution engine, MapReduce allowed data engineers to focus on the business logic of their data processing needs rather than the gnarly details of building distributed systems resilient to the failure modes of commodity <span class="keep-together">hardware</span>.</p>
	</dd>
	<dt>Hadoop—open source ecosystem</dt>
	<dd>
	<p>By building an open source<a contenteditable="false" data-primary="Hadoop" data-type="indexterm" id="idm140176507764432"></a> platform on the ideas of MapReduce, Hadoop created a thriving ecosystem that expanded well beyond the scope of its progenitor and allowed a multitude of new ideas to flourish.</p>
	</dd>
	<dt>Flume—pipelines, optimization</dt>
	<dd>
	<p>By coupling a high-level notion of logical pipeline<a contenteditable="false" data-primary="Flume" data-type="indexterm" id="idm140176507761616"></a> operations with an intelligent optimizer, Flume made it possible to write clean and maintainable pipelines whose capabilities extended beyond the Map → Shuffle → Reduce confines of MapReduce, without sacrificing any of the performance theretofore gained by contorting the logical pipeline via hand-tuned manual optimizations.</p>
	</dd>
	<dt>Storm—low latency with weak consistency</dt>
	<dd>
	<p>By sacrificing correctness of <a contenteditable="false" data-primary="Apache Storm" data-type="indexterm" id="idm140176507758640"></a>results in favor of decreased latency, Storm brought stream processing to the masses and also ushered in the era of the Lambda Architecture, where weakly consistent stream processing engines were run alongside strongly consistent batch systems to realize the true business goal of low-latency, eventually consistent results.</p>
	</dd>
	<dt>Spark—strong consistency</dt>
	<dd>
	<p>By utilizing repeated runs of a strongly <a contenteditable="false" data-primary="Apache Spark" data-type="indexterm" id="idm140176507755680"></a>consistent batch engine to provide continuous processing of unbounded datasets, Spark Streaming proved it possible to have both correctness and low-latency results, at least for in-order datasets.</p>
	</dd>
	<dt>MillWheel—out-of-order processing</dt>
	<dd>
	<p>By coupling strong consistency<a contenteditable="false" data-primary="MillWheel" data-type="indexterm" id="idm140176507752864"></a> and exactly-once processing with tools for reasoning about time like watermarks and timers, MillWheel conquered the challenge of robust stream processing over out-of-order data.</p>
	</dd>
	<dt>Kafka—durable streams, streams and tables</dt>
	<dd>
	<p>By applying the concept of a durable<a contenteditable="false" data-primary="Apache Kafka" data-type="indexterm" id="idm140176507750048"></a> log to the problem of streaming transports, Kafka brought back the warm, fuzzy feeling of replayability that had been lost by ephemeral streaming transports like RabbitMQ and TCP sockets. And by popularizing the ideas of stream and table theory, it helped shed light on the conceptual underpinnings of data processing in general.</p>
	</dd>
	<dt>Cloud Dataflow—unified batch plus streaming</dt>
	<dd>
	<p>By melding the out-of-order stream<a contenteditable="false" data-primary="Cloud Dataflow" data-type="indexterm" id="idm140176507747072"></a> processing concepts from MillWheel with the logical, automatically optimizable pipelines of Flume, Cloud Dataflow provided a unified model for batch plus streaming data processing that provided the flexibility to balance the tensions between correctness, latency, and cost to match any given use case.</p>
	</dd>
	<dt>Flink—open source stream processing innovator</dt>
	<dd>
	<p>By rapidly bringing <a contenteditable="false" data-primary="Apache Flink" data-type="indexterm" id="idm140176507744176"></a>the power of out-of-order processing to the world of open source and combining it with innovations of their own like distributed snapshots and its related savepoints features, Flink raised the bar for open source stream processing and helped lead the current charge of stream processing innovation across the industry.</p>
	</dd>
	<dt>Beam—portability</dt>
	<dd>
	<p>By providing a robust abstraction layer that incorporates the best ideas from across the industry,<a contenteditable="false" data-primary="Apache Beam" data-startref="ix_ApBeam" data-type="indexterm" id="idm140176507741152"></a> Beam provides a portability layer positioned as the programmatic equivalent to the declarative lingua franca provided by SQL, while also encouraging the adoption of innovative new ideas throughout the industry.</p>
	</dd>
</dl>

<p>To be certain, these 10 projects and the sampling of their achievements that I’ve highlighted here do not remotely encompass the full breadth of the history that has led the industry to where it exists today. But they stand out to me as important and noteworthy milestones along the way, which taken together paint an informative picture of the evolution of stream processing over the past decade and a half. We’ve come a long way since the early days of MapReduce, with a number of ups, downs, twists, and turns along the way. Even so, there remains a long road of open problems ahead of us in the realm of streaming systems. I’m excited to see what the future holds.<a contenteditable="false" data-primary="large-scale data processing, evolution of" data-startref="ix_lgscdp" data-type="indexterm" id="idm140176507770336"></a></p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="idm140176508310416"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508310416-marker" class="totri-footnote">1</a></sup> Which means I’m skipping a ton of the academic literature around stream processing, because that’s where much of it started. If you’re really into hardcore academic papers on the topic, start from the references in <a href="http://bit.ly/2sXgVJ3">“The Dataflow Model” paper</a> and work backward. You should be able to find your way pretty easily.</p><p data-type="footnote" id="idm140176508293680"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508293680-marker" class="totri-footnote">2</a></sup> Certainly, MapReduce itself was built upon many ideas that had been well known before, as is even explicitly stated in the MapReduce paper. That doesn’t change the fact that MapReduce was the system that tied those ideas together (along with some of its own) to create something practical that solved an important and emerging problem better than anyone else before ever had, and in a way that inspired generations of data-processing systems that followed.</p><p data-type="footnote" id="idm140176508292336"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508292336-marker" class="totri-footnote">3</a></sup> To be clear, Google was most certainly not the only company tackling data processing problems at this scale at the time. Google was just one among a number of companies involved in that first generation of attempts at taming massive-scale data processing.</p><p data-type="footnote" id="idm140176508281456"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508281456-marker" class="totri-footnote">4</a></sup> And to be clear, MapReduce actually built upon the Google File System, GFS, which itself solved the scalability and fault-tolerance issues for a specific subset of the overall problem.</p><p data-type="footnote" id="idm140176508199280"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508199280-marker" class="totri-footnote">5</a></sup> Not unlike the query optimizers long used in the database world.</p><p data-type="footnote" id="idm140176508170576"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508170576-marker" class="totri-footnote">6</a></sup> Noogler == New + Googler == New hires at Google</p><p data-type="footnote" id="idm140176508118768"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508118768-marker" class="totri-footnote">7</a></sup> As an aside, I also highly recommend reading Martin Kleppmann’s <a href="http://bit.ly/2ybJlnt">“A Critique of the CAP Theorem”</a> for very nice analysis of the shortcomings of the CAP theorem itself, as well as a more principled alternative way of looking at the same problem.</p><p data-type="footnote" id="idm140176508014624"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176508014624-marker" class="totri-footnote">8</a></sup> For the record, written primarily by Sam McVeety with help from Reuven and bits of input from the rest of us on the author list; we shouldn’t have alphabetized that author list, because everyone always assumes I’m the primary author on it, even though I wasn’t.</p><p data-type="footnote" id="idm140176507996064"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507996064-marker" class="totri-footnote">9</a></sup> Kafka Streams and now KSQL are of course changing that, but those are relatively recent developments, and I’ll be focusing primarily on the Kafka of yore.</p><p data-type="footnote" id="idm140176507961456"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507961456-marker">10</a></sup> While I recommend the book as the most comprehensive and cohesive resource, you can find much of the content from it scattered across O’Reilly’s website if you just search around for Kreps’ articles. Sorry, Jay...</p><p data-type="footnote" id="idm140176507922976"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507922976-marker">11</a></sup> As with many broad generalizations, this one is true in a specific context, but belies the underlying complexity of reality. As I alluded to in <a data-type="xref" href="/site/library/view/streaming-systems/9781491983867/ch01.html#streaming_one_oh_one">Chapter&nbsp;1</a>, batch systems go to great lengths to optimize the cost and runtime of data processing pipelines over bounded datasets in ways that stream processing engines have yet to attempt to duplicate. To imply that modern batch and streaming systems only differ in one small way is a sizeable oversimplification in any realm beyond the purely conceptual.</p><p data-type="footnote" id="idm140176507777920"><sup><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#idm140176507777920-marker">12</a></sup> There’s an additional subtlety here that’s worth calling out: even as runners adopt new semantics and tick off feature checkboxes, it’s not the case that you can blindly choose any runner and have an identical experience. This is because the runners themselves can still vary greatly in their runtime and operational characteristics. Even for cases in which two given runners implement the same set of semantic features within the Beam Model, the way they go about executing those features at runtime is typically very different. As a result, when building a Beam pipeline, it’s important to do your homework regarding various runners, to ensure that you choose a runtime platform that serves your use case best.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-0" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="/site/library/view/streaming-systems/9781491983867/ch10.html#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="/site/library/view/streaming-systems/9781491983867/ch10.html#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="/site/library/view/streaming-systems/9781491983867/ch10.html#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#">Copy</a></li>
		
		<li class="add-highlight"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#">Add Highlight</a></li>
		<li class="add-note"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="/site/library/view/streaming-systems/9781491983867/ch09.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">9. Streaming Joins</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="/site/library/view/streaming-systems/9781491983867/ix01.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">Index</div>
        </a>
    
  
  </div>


        
    </section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" class="icon-up"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/playlists/">Playlists</a>
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/preferences/">Settings</a></li>
      <li class="full-support"><a href="https://www.oreilly.com/online-learning/support/">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2018 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>




    
    
      <img src="https://www.oreilly.com/library/view/oreilly_set_cookie/" alt="" style="display:none;">
    
    
    
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 201.006px; left: 1356px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="/site/library/view/streaming-systems/9781491983867/ch10.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="/site/library/view/streaming-systems/9781491983867/ch10.html#">Reset</a>
</div>
</div>
<div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.10689043487619498"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.23745026946070147" width="0" height="0" alt="" src="https://bat.bing.com/action/0?ti=5794699&amp;Ver=2&amp;mid=9c02aaf6-cac9-aac7-4e2f-384ef20c1d21&amp;pi=1200101525&amp;lg=en-US&amp;sw=1440&amp;sh=900&amp;sc=24&amp;tl=10.%20The%20Evolution%20of%20Large-Scale%20Data%20Processing%20-%20Streaming%20Systems&amp;p=https%3A%2F%2Fwww.safaribooksonline.com%2Flibrary%2Fview%2Fstreaming-systems%2F9781491983867%2Fch10.html&amp;r=&amp;lt=19792&amp;evt=pageLoad&amp;msclkid=N&amp;rn=170270"></div></body></html>