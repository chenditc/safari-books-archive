<!--[if IE]><![endif]--><!DOCTYPE html><!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/data-mining-practical/9780123748560/xhtml/c0005.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="3283993"
  data-user-uuid="ff49cd60-92d4-4bee-94ce-69a00f89e9c5"
  data-username="safaribooksonline113"
  data-account-type="Trial"
  
  data-activated-trial-date="08/25/2018"


  data-archive="9780123748560"
  data-publishers="Morgan Kaufmann"



  data-htmlfile-name="c0005.html"
  data-epub-title="Data Mining: Practical Machine Learning Tools and Techniques, 3rd Edition" data-debug=0 data-testing=0><![endif]--><!--[if gt IE 8]><!--><html class="js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom gr__safaribooksonline_com" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/data-mining-practical/9780123748560/xhtml/c0005.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="3283993" data-user-uuid="ff49cd60-92d4-4bee-94ce-69a00f89e9c5" data-username="safaribooksonline113" data-account-type="Trial" data-activated-trial-date="08/25/2018" data-archive="9780123748560" data-publishers="Morgan Kaufmann" data-htmlfile-name="c0005.html" data-epub-title="Data Mining: Practical Machine Learning Tools and Techniques, 3rd Edition" data-debug="0" data-testing="0" style=""><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9780123748560"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.0c29511d2d72.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900,200italic,300italic,400italic,600italic,700italic,900italic" rel="stylesheet" type="text/css"><title>Chapter 5. Credibility - Data Mining: Practical Machine Learning Tools and Techniques, 3rd Edition</title><link rel="stylesheet" href="https://www.safaribooksonline.com/static/CACHE/css/5e586a47a3b7.css" type="text/css"><link rel="stylesheet" type="text/css" href="https://www.safaribooksonline.com/static/css/annotator.e3b0c44298fc.css"><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"><style type="text/css" title="ibis-book">
    #sbo-rt-content div{margin-left:2em;margin-right:2em;font-family:"Charis"}#sbo-rt-content div.itr{padding-top:.2em;padding-bottom:.25em;padding-left:.2em;padding-right:.2em}#sbo-rt-content .fm_title_document{font-size:x-large;text-align:center;font-weight:bold;line-height:1.5em;margin-top:2em;color:#241a26;background-color:#a6abee}#sbo-rt-content div.ded{text-align:center;font-size:medium;padding-top:.2em;padding-bottom:.25em;padding-left:.2em;padding-right:.2em;margin-top:4em}#sbo-rt-content .para_fl{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0}#sbo-rt-content div.ded .para_indented{font-size:100%;text-align:center;margin-bottom:.5em;margin-top:0;text-indent:1em}#sbo-rt-content div.ctr{text-align:left;font-weight:bold;font-size:medium;padding-top:.2em;padding-bottom:.25em;padding-left:.2em;padding-right:.2em}#sbo-rt-content div.idx{text-align:left;padding-top:.2em;padding-bottom:.25em;padding-left:.2em;padding-right:.2em}#sbo-rt-content div.ctr .para_fl{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0}#sbo-rt-content div.ctr .para_indented{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0;text-indent:1em}#sbo-rt-content div.ctr .author{font-size:100%;text-align:left;margin-bottom:.5em;margin-top:1em;color:#39293b;font-weight:bold}#sbo-rt-content div.ctr .affiliation{text-align:left;font-size:100%;font-style:italic;color:#5e4462}#sbo-rt-content div.pre{text-align:left;font-size:medium;padding-top:.2em;padding-bottom:.25em;padding-left:.2em;padding-right:.2em}#sbo-rt-content div.pre .para_fl{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0}#sbo-rt-content div.pre .para_indented{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0;text-indent:1em}#sbo-rt-content div.chp{line-height:1.5em;margin-top:2em}#sbo-rt-content .document_number{display:block;font-size:100%;text-align:right;padding-bottom:10px;padding-top:10px;padding-right:10px;font-weight:bold;border-top:solid 2px #0000A0;border-right:solid 8px #0000A0;margin-bottom:.25em;background-color:#a6abee;color:#0000A0}#sbo-rt-content .subtitle_document{font-weight:bold;font-size:large;text-align:center;margin-bottom:2em;margin-top:.5em;padding-top:.5em}#sbo-rt-content .subtitle{font-weight:bold;font-size:large;text-align:center;margin-bottom:1em}#sbo-rt-content a{color:#3152a9;text-decoration:none}#sbo-rt-content .affiliation{font-size:100%;font-style:italic;color:#5e4462}#sbo-rt-content .extract_fl{text-align:justify;font-size:100%;margin-bottom:1em;margin-top:2em;margin-left:1.5em;margin-right:1.5em}#sbo-rt-content .poem_title{text-align:center;font-size:110%;margin-top:1em;font-weight:bold}#sbo-rt-content .stanza{text-align:center;font-size:100%}#sbo-rt-content .poem_source{text-align:center;font-size:100%;font-style:italic}#sbo-rt-content .list_para{font-size:100%;margin-top:0;margin-bottom:.25em}#sbo-rt-content .objectset{font-size:90%;margin-bottom:1.5em;margin-top:1.5em;border-top:solid 3px #e88f1c;border-bottom:solid 1.5px #e88f1c;background-color:#f8d9b5;color:#4f2d02}#sbo-rt-content .objectset_title{margin-top:0;padding-top:5px;padding-left:5px;padding-right:5px;padding-bottom:5px;background-color:#efab5b;font-weight:bold;font-size:110%;color:#88520b;border-bottom:solid 1.5px #e88f1c}#sbo-rt-content .nomenclature{font-size:90%;margin-bottom:1.5em;padding-bottom:15px;border-top:solid 3px #644484;border-bottom:solid 1.5px #644484}#sbo-rt-content .nomenclature_head{margin-top:0;padding-top:5px;padding-left:5px;padding-bottom:5px;background-color:#b29bca;font-weight:bold;font-size:110%;color:#644484;border-bottom:solid 1.5px #644484}#sbo-rt-content .list_def_entry{font-size:100%;margin-top:.5em;margin-bottom:.5em}#sbo-rt-content div.chp .para_fl{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0}#sbo-rt-content .scx{font-size:100%;font-weight:bold;text-align:left;margin-bottom:0;margin-top:0;padding-bottom:5px;padding-top:5px;padding-left:5px;padding-right:5px}#sbo-rt-content p{font-size:100%;text-align:justify;margin-bottom:0;margin-top:0}#sbo-rt-content div.chp .para_indented{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0;text-indent:1em}#sbo-rt-content .head1{font-size:110%;font-weight:bold;text-align:left;margin-bottom:1em;margin-top:1em;color:#005aaa;border-bottom:solid 3px #7f9fd3}#sbo-rt-content .head12{page-break-before:always;font-size:110%;font-weight:bold;text-align:left;margin-bottom:1em;margin-top:1em;color:#005aaa;border-bottom:solid 3px #7f9fd3}#sbo-rt-content .sec_num{color:#0000A0}#sbo-rt-content .head2{font-size:115%;font-weight:bold;text-align:left;margin-bottom:.5em;margin-top:1em;color:#ae3f58;border-bottom:solid 3px #dfd8cb}#sbo-rt-content .head3{font-size:110%;margin-bottom:.5em;margin-top:1em;text-align:left;font-weight:bold;color:#6f2c90}#sbo-rt-content .head4{font-weight:bold;font-size:105%;text-align:left;margin-bottom:.5em;margin-top:1em;color:#53a6df}#sbo-rt-content .bibliography_title{font-size:110%;font-weight:bold;text-align:left;margin-bottom:1em;margin-top:1em;color:#005aaa;border-bottom:solid 3px #7f9fd3}#sbo-rt-content .tch{text-align:center;border-bottom:solid 1px black;border-top:solid 1px black;border-right:solid 1px black;border-left:solid 1px black;margin-top:1.5em;margin-bottom:1.5em;font-weight:bold}#sbo-rt-content table{display:table;margin-bottom:1em}#sbo-rt-content tr{display:table-row}#sbo-rt-content td ul{display:table-cell}#sbo-rt-content .tb{margin-top:1.5em;margin-bottom:1.5em;vertical-align:top;padding-left:1em}#sbo-rt-content .table_source{font-size:75%;margin-bottom:1em;font-style:italic;color:#0000A0;text-align:left;padding-bottom:5px;padding-top:5px;border-bottom:solid 2px black;border-top:solid 1px black}#sbo-rt-content .figure{margin-top:1.5em;margin-bottom:1.5em;padding-right:5px;padding-left:5px;padding-bottom:5px;padding-top:5px;text-align:center}#sbo-rt-content .figure_legend{font-size:90%;margin-top:0;margin-bottom:1em;vertical-align:top;border-top:solid 1px #0000A0;line-height:1.5em}#sbo-rt-content .figure_source{font-size:75%;margin-top:.5em;margin-bottom:1em;font-style:italic;color:#0000A0;text-align:left}#sbo-rt-content .fig_num{font-size:110%;font-weight:bold;color:white;padding-right:10px;background-color:#0000A0}#sbo-rt-content .table_caption{font-size:90%;margin-top:2em;margin-bottom:.5em;vertical-align:top}#sbo-rt-content .tab_num{font-size:90%;font-weight:bold;color:#00f;padding-right:4px}#sbo-rt-content .tablecdt{font-size:75%;margin-bottom:1em;font-style:italic;color:#00f;text-align:left;padding-bottom:5px;padding-top:5px;border-bottom:solid 2px black;border-top:solid 1px black}#sbo-rt-content table.numbered{font-size:85%;border-top:solid 2px black;border-bottom:solid 2px black;margin-top:1.5em;margin-bottom:1em;background-color:#a6abee}#sbo-rt-content table.unnumbered{font-size:85%;border-top:solid 2px black;border-bottom:solid 2px black;margin-top:1.5em;margin-bottom:1em;background-color:#a6abee}#sbo-rt-content .ack{font-size:90%;margin-top:1.5em;margin-bottom:1.5em}#sbo-rt-content .boxg{font-size:90%;padding-left:.5em;padding-right:.5em;margin-bottom:1em;margin-top:1em;border-top:solid 1px red;border-bottom:solid 1px red;border-left:solid 1px red;border-right:solid 1px red;background-color:#ffda6b}#sbo-rt-content .box_title{padding-top:5px;padding-left:5px;padding-bottom:5px;padding-right:5px;background-color:#67582b;font-weight:bold;font-size:110%;color:white;margin-top:.25em}#sbo-rt-content .box_source{padding-top:.5px;padding-left:.5px;padding-bottom:5px;padding-right:.5px;font-size:100%;color:#67582b;margin-top:.25em;margin-left:2.5em;margin-right:2.5em;font-style:italic}#sbo-rt-content .box_no{margin-top:0;padding-left:5px;padding-right:5px;font-weight:bold;font-size:100%;color:#ffda6b}#sbo-rt-content .headx{margin-top:.5em;padding-bottom:.25em;font-weight:bold;font-size:110%}#sbo-rt-content .heady{margin-top:1.5em;padding-bottom:.25em;font-weight:bold;font-size:110%;color:#00f}#sbo-rt-content .headz{margin-top:1.5em;padding-bottom:.25em;font-weight:bold;font-size:110%;color:red}#sbo-rt-content div.subdoc{font-weight:bold;font-size:large;text-align:center;color:#00f}#sbo-rt-content div.subdoc .document_number{display:block;font-size:100%;text-align:right;padding-bottom:10px;padding-top:10px;padding-right:10px;font-weight:bold;border-top:solid 2px #00f;border-right:solid 8px #00f;margin-bottom:.25em;background-color:#2b73b0;color:#00f}#sbo-rt-content ul.none{list-style:none;margin-top:.25em;margin-bottom:1em}#sbo-rt-content ul.bull{list-style:disc;margin-top:.25em;margin-bottom:.25em}#sbo-rt-content ul.squf{list-style:square;margin-top:.25em;margin-bottom:.25em}#sbo-rt-content ul.circ{list-style:circle;margin-top:.25em;margin-bottom:.25em}#sbo-rt-content ol.lower_a{list-style:lower-alpha;margin-top:.25em;margin-bottom:.25em}#sbo-rt-content ol.upper_a{list-style:upper-alpha;margin-top:.25em;margin-bottom:.25em}#sbo-rt-content ol.upper_i{list-style:upper-roman;margin-top:.25em;margin-bottom:.25em}#sbo-rt-content ol.lower_i{list-style:lower-roman;margin-top:.25em;margin-bottom:.25em}#sbo-rt-content div.chp .list_para_indented{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0;text-indent:1em}#sbo-rt-content .book_title_page{margin-top:.5em;margin-left:.5em;margin-right:.5em;border-top:solid 6px #55390e;border-left:solid 6px #55390e;border-right:solid 6px #55390e;padding-left:0;padding-top:10px;background-color:#a6abee}#sbo-rt-content p.pagebreak{page-break-before:always}#sbo-rt-content .book_series_editor{margin-top:.5em;margin-left:.5em;margin-right:.5em;border-top:solid 6px #55390e;border-left:solid 6px #55390e;border-right:solid 6px #55390e;border-bottom:solid 6px #55390e;padding-left:5px;padding-right:5px;padding-top:10px;background-color:#a6abee}#sbo-rt-content .book_title{text-align:center;font-weight:bold;font-size:250%;color:#55390e;margin-top:70px}#sbo-rt-content .book_subtitle{text-align:center;margin-top:.25em;font-weight:bold;font-size:150%;color:#00f;border-top:solid 1px #55390e;border-bottom:solid 1px #55390e;padding-bottom:7px}#sbo-rt-content .edition{text-align:right;margin-top:1.5em;margin-right:5em;font-weight:bold;font-size:90%;color:red}#sbo-rt-content .author_group{padding-left:10px;padding-right:10px;padding-top:2px;padding-bottom:2px;background-color:#ffac29;margin-left:70px;margin-right:70px;margin-top:20px;margin-bottom:20px}#sbo-rt-content .editors{text-align:left;font-weight:bold;font-size:100%;color:#241a26}#sbo-rt-content .title_author{text-align:center;font-weight:bold;font-size:80%;color:#241a26}#sbo-rt-content .title_affiliation{text-align:center;font-size:80%;color:#241a26;margin-bottom:.5em;font-style:italic}#sbo-rt-content .publisher{text-align:center;font-size:100%;margin-bottom:.5em;padding-left:10px;padding-right:10px;padding-top:10px;padding-bottom:10px;background-color:#55390e;color:#a6abee}#sbo-rt-content div.qa h1.head1{font-size:110%;font-weight:bold;margin-bottom:1em;margin-top:1em;color:#6883b5;border-bottom:solid 8px #fee7ca}#sbo-rt-content div.outline{border-left:2px solid #007ec6;border-right:2px solid #007ec6;border-bottom:2px solid #007ec6;border-top:26px solid #007ec6;padding:3px;margin-bottom:1em}#sbo-rt-content div.outline .list_head{background-color:#007ec6;color:white;padding:.2em 1em .2em;margin:-.4em -.3em -.4em -.3em;margin-bottom:.5em;font-size:medium;font-weight:bold;margin-top:-1.5em}#sbo-rt-content div.fm .author{text-align:center;margin-bottom:1.5em;color:#39293b}#sbo-rt-content td p{text-align:left}#sbo-rt-content div.htu .para_indented{font-size:100%;text-align:justify;margin-bottom:.5em;margin-top:0;text-indent:1em}#sbo-rt-content div.htu .para_fl{font-size:100%;margin-bottom:.5em;margin-top:0;text-align:justify}#sbo-rt-content .headx{font-size:110%;font-weight:bold;text-align:left;margin-bottom:1em;margin-top:1em;color:#005aaa;border-bottom:solid 3px #7f9fd3}#sbo-rt-content div.book_section{text-align:center;margin-top:8em}#sbo-rt-content div.book_part{text-align:center;margin-top:6em}#sbo-rt-content p.section_label{display:block;font-size:200%;text-align:center;padding-right:10px;font-weight:bold;border-top:solid 2px #00f;background-color:#a6abee;color:#00f}#sbo-rt-content p.section_title{display:block;font-size:200%;text-align:center;padding-right:10px;margin-bottom:2em;border-top:solid 2px #00f;font-weight:bold;border-bottom:solid 2px #00f;background-color:#a6abee;color:#00f}#sbo-rt-content p.part_label{display:block;font-size:250%;text-align:center;margin-top:6em;padding-right:10px;font-weight:bold;border-top:solid 2px #00f;background-color:#a6abee;color:#00f}#sbo-rt-content p.part_title{display:block;font-size:250%;text-align:center;padding-right:10px;margin-bottom:2em;font-weight:bold;border-bottom:solid 2px #00f;background-color:#a6abee;color:#00f}#sbo-rt-content div.idx li{margin-top:-.3em}#sbo-rt-content p.ueqn{text-align:center}#sbo-rt-content p.eqn{text-align:center}#sbo-rt-content p.extract_indented{margin-left:3em;margin-right:3em;margin-bottom:.5em;text-indent:1em}#sbo-rt-content td p.para_fl{font-size:90%;margin-bottom:.5em;margin-top:0;text-align:left}#sbo-rt-content .small{font-size:small}#sbo-rt-content div.abs{font-size:90%;margin-bottom:2em;margin-top:2em;margin-left:1em;margin-right:1em}#sbo-rt-content p.abstract_title{font-size:110%;margin-bottom:1em;font-weight:bold}#sbo-rt-content sup{vertical-align:4px}#sbo-rt-content sub{vertical-align:-2px}#sbo-rt-content img{max-width:100%;max-height:100%}#sbo-rt-content p.toc1{margin-left:1em;margin-bottom:.5em;font-weight:bold;text-align:left}#sbo-rt-content p.toc2{margin-left:2em;margin-bottom:.5em;font-weight:bold;text-align:left}#sbo-rt-content p.toc3{margin-left:3em;margin-bottom:.5em;text-align:left}#sbo-rt-content .head5{font-weight:bold;font-size:100%;text-align:left;margin-bottom:.5em;margin-top:1em}#sbo-rt-content img.inline{vertical-align:middle}#sbo-rt-content .head6{font-weight:bold;font-size:90%;text-align:left;margin-bottom:.5em;margin-top:1em}#sbo-rt-content .underline{text-decoration:underline}#sbo-rt-content .center{text-align:center}#sbo-rt-content span.big{font-size:2em}#sbo-rt-content p.para_indented{text-indent:2em}#sbo-rt-content p.para_indented1{text-indent:0;page-break-before:always}#sbo-rt-content p.right{text-align:right}#sbo-rt-content p.endnote{margin-left:1em;margin-right:1em;margin-bottom:.5em;text-indent:-1em}#sbo-rt-content div.block{margin-left:3em;margin-bottom:.5em;text-indent:-1em}#sbo-rt-content p.bl_para{font-size:100%;text-indent:0;text-align:justify}#sbo-rt-content div.poem{text-align:center;font-size:100%}#sbo-rt-content .acknowledge_head{font-size:150%;margin-bottom:.25em;font-weight:bold}#sbo-rt-content .intro{font-size:130%;margin-top:1.5em;margin-bottom:1em;font-weight:bold}#sbo-rt-content .exam{font-size:90%;margin-top:1em;margin-bottom:1em}#sbo-rt-content div.exam_head{font-size:130%;margin-top:1.5em;margin-bottom:1em;font-weight:bold}#sbo-rt-content p.table_footnotes{font-size:80%;margin-top:.5em;margin-bottom:.5em;vertical-align:top;text-indent:.01em}#sbo-rt-content div.table_foot{font-size:80%;margin-top:.5em;margin-bottom:1em;text-indent:.01em}#sbo-rt-content p.table_legend{font-size:80%;margin-top:.5em;margin-bottom:.5em;vertical-align:top;text-indent:.01em}#sbo-rt-content .bib_entry{font-size:90%;text-align:left;margin-left:20px;margin-bottom:.25em;margin-top:0;text-indent:-30px}#sbo-rt-content .ref_entry{font-size:90%;text-align:left;margin-left:20px;margin-bottom:.25em;margin-top:0;text-indent:-20px}#sbo-rt-content div.ind1{margin-left:.1em;margin-top:.5em}#sbo-rt-content div.ind2{margin-left:1em}#sbo-rt-content div.ind3{margin-left:1.5em}#sbo-rt-content div.ind4{margin-left:2em}#sbo-rt-content div.ind5{margin-left:2.5em}#sbo-rt-content div.ind6{margin-left:3em}#sbo-rt-content .title_document{font-size:x-large;text-align:center;font-weight:bold;line-height:1.5em;margin-top:2em;margin-bottom:2em;color:#0000A0}#sbo-rt-content .sc1{margin-left:0}#sbo-rt-content .sc2{margin-left:0}#sbo-rt-content .sc3{margin-left:0}#sbo-rt-content .sc4{margin-left:0}#sbo-rt-content .sc5{margin-left:0}#sbo-rt-content .sc6{margin-left:0}#sbo-rt-content .sc7{margin-left:0}#sbo-rt-content .sc8{margin-left:0}#sbo-rt-content .sc9{margin-left:0}#sbo-rt-content .sc10{margin-left:0}#sbo-rt-content .sc11{margin-left:0}#sbo-rt-content .sc12{margin-left:0}#sbo-rt-content .sc13{margin-left:0}#sbo-rt-content .sc14{margin-left:0}#sbo-rt-content .sc15{margin-left:0}#sbo-rt-content .sc16{margin-left:0}#sbo-rt-content .sc17{margin-left:0}#sbo-rt-content .sc18{margin-left:0}#sbo-rt-content .sc19{margin-left:0}#sbo-rt-content .sc20{margin-left:0}#sbo-rt-content .sc0{margin-left:0}#sbo-rt-content .source{font-size:11px;margin-top:.5em;margin-bottom:0;font-style:italic;color:#0000A0;text-align:left}#sbo-rt-content div.footnote{font-size:small;border-style:solid;border-width:1px 0 0 0;margin-top:2em;margin-bottom:1em}#sbo-rt-content table.numbered{font-size:small}#sbo-rt-content div.hang{margin-left:.3em;margin-top:1em;text-align:left}#sbo-rt-content div.p_hang{margin-left:1.5em;text-align:left}#sbo-rt-content div.p_hang1{margin-left:2em;text-align:left}#sbo-rt-content div.p_hang2{margin-left:2.5em;text-align:left}#sbo-rt-content div.p_hang3{margin-left:3em;text-align:left}#sbo-rt-content .bibliography{text-align:left;margin-bottom:1em;margin-top:1em}#sbo-rt-content .biblio_sec{font-size:90%;text-align:left;margin-bottom:1em;margin-top:1em}#sbo-rt-content .gls{text-align:left;margin-bottom:1em;margin-top:1em}#sbo-rt-content .glossary_sec{font-size:90%;font-style:italic;text-align:left;margin-bottom:1em;margin-top:1em}#sbo-rt-content .head7{font-weight:bold;font-size:86%;text-align:left;margin-bottom:.5em;margin-top:1em}#sbo-rt-content .head8{font-weight:bold;font-style:italic;font-size:81%;text-align:left;margin-bottom:.5em;margin-top:1em}#sbo-rt-content .box_subtitle{padding-top:5px;padding-left:5px;padding-bottom:5px;padding-right:5px;font-weight:bold;font-size:105%;margin-top:.25em}#sbo-rt-content div.for{text-align:left;font-size:medium;padding-top:.2em;padding-bottom:.25em;padding-left:.2em;padding-right:.2em}#sbo-rt-content span.strike{text-decoration:line-through}#sbo-rt-content .head9{font-style:italic;font-size:80%;text-align:left;margin-bottom:.5em;margin-top:1em}#sbo-rt-content .bib_note{font-size:85%;text-align:left;margin-left:25px;margin-bottom:.25em;margin-top:0;text-indent:-30px}#sbo-rt-content .glossary_title{font-size:110%;font-weight:bold;text-align:left;margin-bottom:1em;margin-top:1em;color:#005aaa;border-bottom:solid 3px #7f9fd3}#sbo-rt-content .collaboration{padding-left:10px;padding-right:10px;padding-top:2px;padding-bottom:2px;background-color:#ffac29;margin-left:70px;margin-right:70px;margin-top:20px;margin-bottom:20px}#sbo-rt-content .title_collab{text-align:center;font-weight:bold;font-size:85%;color:#241a26}#sbo-rt-content .head0{font-size:105%;font-weight:bold;text-align:left;margin-bottom:.5em;margin-top:1em}#sbo-rt-content .copyright{font-size:80%;text-align:left;margin-bottom:0;margin-top:0;text-indent:0}#sbo-rt-content .copyright-top{font-size:80%;text-align:left;margin-bottom:0;margin-top:1em;text-indent:0}#sbo-rt-content .idxtitle{font-size:x-large;text-align:center;font-weight:bold;line-height:1.5em;margin-top:2em;margin-bottom:2em;color:#0000A0}#sbo-rt-content .idxletter{font-size:100%;text-align:left;margin-bottom:0;margin-top:1em;text-indent:0;font-weight:bold}#sbo-rt-content h1.chaptertitle{margin-top:.5em;margin-bottom:1em;font-size:200%;font-weight:bold;text-indent:0;line-height:1em}#sbo-rt-content h1.chapterlabel{margin-top:0;margin-bottom:0;font-size:150%;font-weight:bold;text-indent:0}#sbo-rt-content p.noindent{text-align:justify;text-indent:0;margin-top:10px;margin-bottom:2px}#sbo-rt-content span.monospace{font-family:consolas,courier,monospace;margin-top:0;margin-bottom:0;white-space:pre;font-size:85%}#sbo-rt-content p.hang{text-indent:-1.1em;margin-left:1em}#sbo-rt-content p.hang1{text-indent:-1.1em;margin-left:2em}#sbo-rt-content p.hang2{text-indent:-1.6em;margin-left:2em}#sbo-rt-content p.hang3{text-indent:-1.1em;margin-left:3em}#sbo-rt-content p.hang4{text-indent:-1.6em;margin-left:4.3em}#sbo-rt-content p.hang5{text-indent:-1.1em;margin-left:5em}#sbo-rt-content p.none{text-align:justify;display:list-item;list-style-type:none;text-indent:-3.2em;margin-left:3.2em;margin-top:2px;margin-bottom:2px}#sbo-rt-content p.blockquote{font-size:90%;margin-left:2.5em;margin-right:2em;margin-top:1em;margin-bottom:1em;line-height:1.3em}#sbo-rt-content p.none1{text-align:justify;display:list-item;list-style-type:none;text-indent:-3.2em;margin-left:2.8em;margin-top:2px;margin-bottom:2px}#sbo-rt-content .listparasub1{list-style:lower-roman;margin-top:.25em;margin-bottom:.25em;margin-left:3.2em}#sbo-rt-content .listparasub2{list-style:lower-roman;margin-top:.25em;margin-bottom:.25em;margin-left:5.5em;text-indent:-3.2em}#sbo-rt-content div.none{list-style:none;margin-top:.25em;margin-bottom:1em}#sbo-rt-content div.bm{line-height:1.5em;margin-top:2em}#sbo-rt-content div.fm{line-height:1.5em;margin-top:2em}#sbo-rt-content span.sup{vertical-align:4px;font-size:75%}#sbo-rt-content span.sub{font-size:75%;vertical-align:-2px}#sbo-rt-content .box_titleC{text-align:center;padding-top:5px;padding-left:5px;padding-bottom:5px;padding-right:5px;background-color:#67582b;font-weight:bold;font-size:110%;color:white;margin-top:.25em}
    </style><link rel="canonical" href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html"><meta name="description" content="CHAPTER 5 Credibility: Evaluating What’s Been Learned Evaluation is the key to making real progress in data mining. There are lots of ways of inferring structure from data: We ... "><meta property="og:title" content="Chapter 5. Credibility"><meta itemprop="isPartOf" content="/library/view/data-mining-practical/9780123748560/"><meta itemprop="name" content="Chapter 5. Credibility"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/xhtml/c0005.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9780123748560/"><meta property="og:description" itemprop="description" content="CHAPTER 5 Credibility: Evaluating What’s Been Learned Evaluation is the key to making real progress in data mining. There are lots of ways of inferring structure from data: We ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="Morgan Kaufmann"><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9780080890364"><meta property="og:book:author" itemprop="author" content="Mark A. Hall"><meta property="og:book:author" itemprop="author" content="Eibe Frank"><meta property="og:book:author" itemprop="author" content="Ian H. Witten"><meta property="og:book:tag" itemprop="about" content="Big Data"><meta property="og:book:tag" itemprop="about" content="Databases"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: <%= font_size %> !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: <%= font_family %> !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: <%= column_width %>% !important; margin: 0 auto !important; }"></style><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  
  



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/playlists/" class="t-queue-nav l0 nav-icn None"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="21px" height="17px" viewBox="0 0 21 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch --><title>icon_Playlist_sml</title><desc>Created with Sketch.</desc><defs></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="icon_Playlist_sml" fill-rule="nonzero" fill="#000000"><g id="playlist-icon"><g id="Group-6"><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle></g><g id="Group-5" transform="translate(0.000000, 7.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g><g id="Group-5-Copy" transform="translate(0.000000, 14.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g></g></g></g></svg><span>
               Playlists
            </span></a></li><li class="search"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://get.oreilly.com/email-signup.html" target="_blank" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/ff49cd60-92d4-4bee-94ce-69a00f89e9c5/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Data Mining: Practical Machine Learning Tools and Techniques, 3rd Edition
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><div class="js-content-uri" data-content-uri="/api/v1/book/9780123748560/chapter/xhtml/c0005.html"><div class="js-collections-dropdown collections-dropdown menu-bit-cards"><div data-reactroot="" class="menu-dropdown-wrapper js-menu-dropdown-wrapper align-right"><img class="hidden" src="https://www.safaribooksonline.com/static/images/ajax-transp.gif" alt="loading spinner"><div class="menu-control"><div class="control "><div class="js-playlists-menu"><button class="js-playlist-icon"><svg class="icon-add-to-playlist-sml" viewBox="0 0 16 14" version="1.1" xmlns="http://www.w3.org/2000/svg"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill-rule="nonzero" fill="#000000"><g transform="translate(-1.000000, 0.000000)"><rect x="5" y="0" width="12" height="2"></rect><title>Playlists</title><path d="M4.5,14 C6.43299662,14 8,12.4329966 8,10.5 C8,8.56700338 6.43299662,7 4.5,7 C2.56700338,7 1,8.56700338 1,10.5 C1,12.4329966 2.56700338,14 4.5,14 Z M2.5,10 L4,10 L4,8.5 L5,8.5 L5,10 L6.5,10 L6.5,11 L5,11 L5,12.5 L4,12.5 L4,11 L2.5,11 L2.5,10 Z"></path><circle cx="2" cy="5" r="1"></circle><circle cx="1.94117647" cy="1" r="1"></circle><rect x="5" y="4" width="12" height="2"></rect><rect x="9" y="8" width="8" height="2"></rect><rect x="9" y="12" width="8" height="2"></rect></g></g></g></svg><div class="js-playlist-addto-label">Add&nbsp;To</div></button></div></div></div></div></div></div></li><li class="js-font-control-panel font-control-activator"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/xhtml/c0005.html&amp;text=Data%20Mining%3A%20Practical%20Machine%20Learning%20Tools%20and%20Techniques%2C%203rd%20Edition&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/xhtml/c0005.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/xhtml/c0005.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%20Chapter%205.%20Credibility&amp;body=https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/xhtml/c0005.html%0D%0Afrom%20Data%20Mining%3A%20Practical%20Machine%20Learning%20Tools%20and%20Techniques%2C%203rd%20Edition%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
        
        



 <!--[if lt IE 9]>
  
<![endif]-->



  


        
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0004.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">Chapter 4. Algorithms</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="/Library/view/data-mining-practical/9780123748560/xhtml/p3.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">PART II. Advanced Data Mining</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content" style="transform: none;"><div class="annotator-wrapper"><div class="chp"><a id="c0005"></a><h1 class="chapterlabel" id="c0005tit1">CHAPTER 5</h1>
<h1 class="chaptertitle" id="c0005tit">Credibility: Evaluating What’s Been Learned</h1><p id="p0010" class="noindent"><a id="p147"></a>Evaluation is the key to making real progress in data mining. There are lots of ways of inferring structure from data: We have encountered many already and will see further refinements, and new methods, in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0006.html#c0006">Chapter 6</a>. However, in order to determine which ones to use on a particular problem we need systematic ways to evaluate how different methods work and to compare one with another. But evaluation is not as simple as it might appear at first sight.</p>
<p id="p0015" class="para_indented">What’s the problem? We have the training set; surely we can just look at how well different methods do on that. Well, no: As we will see very shortly, performance on the training set is definitely not a good indicator of performance on an independent test set. We need ways of predicting performance bounds in practice, based on experiments with whatever data can be obtained.</p>
<p id="p0020" class="para_indented">When a vast supply of data is available, this is no problem: Just make a model based on a large training set, and try it out on another large test set. But although data mining sometimes involves “big data”—particularly in marketing, sales, and customer support applications—it is often the case that data, quality data, is scarce. The oil slicks mentioned in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#c0001">Chapter 1</a> (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#p0570">page 23</a>) had to be detected and marked manually—a skilled and labor-intensive process—before being used as training data. Even in the personal loan application data (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#p0550">page 22</a>), there turned out to be only 1000 training examples of the appropriate type. The electricity supply data (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#p0590">page 24</a>) went back 15 years, 5000 days—but only 15 Christmas days and Thanksgivings, and just four February 29s and presidential elections. The electromechanical diagnosis application (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#p0610">page 25</a>) was able to capitalize on 20 years of recorded experience, but this yielded only 300 usable examples of faults. The marketing and sales applications (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#p0630">page 26</a>) certainly involve big data, but many others do not: Training data frequently relies on specialist human expertise—and that is always in short supply.</p>
<p id="p0025" class="para_indented">The question of predicting performance based on limited data is an interesting, and still controversial, one. We will encounter many different techniques, of which one—repeated cross-validation—is probably the method of choice in most practical limited-data situations. Comparing the performance of different machine learning schemes on a given problem is another matter that is not as easy as it sounds: To be sure that apparent differences are not caused by chance effects, statistical tests are needed.</p>
<p id="p0030" class="para_indented"><a id="p148"></a>So far we have tacitly assumed that what is being predicted is the ability to classify test instances accurately; however, some situations involve predicting class probabilities rather than the classes themselves, and others involve predicting numeric rather than nominal values. Different methods are needed in each case. Then we look at the question of cost. In most practical data mining situations, the cost of a misclassification error depends on the type of error it is—whether, for example, a positive example was erroneously classified as negative or vice versa. When doing data mining, and evaluating its performance, it is often essential to take these costs into account. Fortunately, there are simple techniques to make most learning schemes cost sensitive without grappling with the algorithm’s internals. Finally, the whole notion of evaluation has fascinating philosophical connections. For 2000 years, philosophers have debated the question of how to evaluate scientific theories, and the issues are brought into sharp focus by data mining because what is extracted is essentially a “theory” of the data.</p>
<div id="s0010">
<h2 id="st0010">5.1 Training and testing</h2>
<p id="p0035" class="noindent">For classification problems, it is natural to measure a classifier’s performance in terms of the <em>error rate</em>. The classifier predicts the class of each instance: If it is correct, that is counted as a <em>success</em>; if not, it is an <em>error</em>. The error rate is just the proportion of errors made over a whole set of instances, and it measures the overall performance of the classifier.</p>
<p id="p0040" class="para_indented">Of course, what we are interested in is the likely future performance on new data, not the past performance on old data. We already know the classifications of each instance in the training set, which after all is why we can use it for training. We are not generally interested in learning about those classifications—although we might be if our purpose is data cleansing rather than prediction. So the question is, is the error rate on old data likely to be a good indicator of the error rate on new data? The answer is a resounding <em>no</em>—not if the old data was used during the learning process to train the classifier.</p>
<p id="p0045" class="para_indented">This is a surprising fact, and a very important one. The error rate on the training set is <em>not</em> likely to be a good indicator of future performance. Why? Because the classifier has been learned from the very same training data, any estimate of performance based on that data will be optimistic, even hopelessly optimistic.</p>
<p id="p0050" class="para_indented">We have already seen an example of this in the labor relations dataset. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#f0020">Figure 1.3(b)</a> (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#p0425">page 18</a>) was generated directly from the training data, and <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#f0020">Figure 1.3(a)</a> was obtained from it by a process of pruning. The former is potentially more accurate on the data that was used to train the classifier, but may perform less well on independent test data because it is overfitted to the training data. The first tree will look good according to the error rate on the training data, better than the second tree. But this does not necessarily reflect how they will perform on independent test data.</p>
<p id="p0055" class="para_indented">The error rate on the training data is called the <em>resubstitution error</em> because it is calculated by resubstituting the training instances into a classifier that was <a id="p149"></a>constructed from them. Although it is not a reliable predictor of the true error rate on new data, it is nevertheless often useful to know.</p>
<p id="p0060" class="para_indented">To predict the performance of a classifier on new data, we need to assess its error rate on a dataset that played no part in the formation of the classifier. This independent dataset is called the <em>test set</em>. We assume that both the training data and the test data are representative samples of the underlying problem.</p>
<p id="p0065" class="para_indented">In some cases the test data might be distinct in nature from the training data. Consider, for example, the credit risk problem from <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#s0065">Section 1.3</a> (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#p0550">page 22</a>). Suppose the bank had training data from branches in New York and Florida and wanted to know how well a classifier trained on one of these datasets would perform in a new branch in Nebraska. It should probably use the Florida data as test data for evaluating the New York–trained classifier and the New York data to evaluate the Florida-trained classifier. If the datasets were amalgamated before training, performance on the test data would probably not be a good indicator of performance on future data in a completely different state.</p>
<p id="p0070" class="para_indented">It is important that the test data is <em>not used in any way</em> to create the classifier. For example, some learning schemes involve two stages, one to come up with a basic structure and the second to optimize parameters involved in that structure, and separate sets of data may be needed in the two stages. Or you might try out several learning schemes on the training data and then evaluate them—on a fresh dataset, of course—to see which one works best. But none of this data may be used to determine an estimate of the future error rate.</p>
<p id="p0075" class="para_indented">In such situations people often talk about three datasets: the <em>training</em> data, the <em>validation</em> data, and the <em>test</em> data. The training data is used by one or more learning schemes to come up with classifiers. The validation data is used to optimize parameters of those classifier, or to select a particular one. Then the test data is used to calculate the error rate of the final, optimized, method. Each of the three sets must be chosen independently: The validation set must be different from the training set to obtain good performance in the optimization or selection stage, and the test set must be different from both to obtain a reliable estimate of the true error rate.</p>
<p id="p0080" class="para_indented">It may be that once the error rate has been determined, the test data is bundled back into the training data to produce a new classifier for actual use. There is nothing wrong with this: It is just a way of maximizing the amount of data used to generate the classifier that will actually be employed in practice. With well-behaved learning schemes, this should not decrease predictive performance. Also, once the validation data has been used—maybe to determine the best type of learning scheme to use—then it can be bundled back into the training data to retrain that learning scheme, maximizing the use of data.</p>
<p id="p0085" class="para_indented">If lots of data is available, there is no problem: We take a large sample and use it for training; then another, independent large sample of different data and use it for testing. Provided both samples are representative, the error rate on the test set will give a good indication of future performance. Generally, the larger the training sample, the better the classifier, although the returns begin to diminish once a certain volume of training data is exceeded. And the larger the test sample, the more accurate <a id="p150"></a>the error estimate. The accuracy of the error estimate can be quantified statistically, as we will see in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0015">Section 5.2</a>.</p>
<p id="p0090" class="para_indented">The real problem occurs when there is not a vast supply of data available. In many situations the training data must be classified manually—and so must the test data, of course, to obtain error estimates. This limits the amount of data that can be used for training, validation, and testing, and the problem becomes how to make the most of a limited dataset. From this dataset, a certain amount is held over for testing—this is called the <em>holdout</em> procedure—and the remainder used for training (and, if necessary, part of that is set aside for validation). There’s a dilemma here: To find a good classifier, we want to use as much of the data as possible for training; to obtain a good error estimate, we want to use as much of it as possible for testing. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0020">Sections 5.3</a> and <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0025">5.4</a> review widely used methods for dealing with this dilemma.</p>
</div>
<div id="s0015">
<h2 id="st0015">5.2 Predicting performance</h2>
<p id="p0095" class="noindent">Suppose we measure the error of a classifier on a test set and obtain a certain numerical error rate—say 25%. Actually, in this section we talk about success rate rather than error rate, so this corresponds to a success rate of 75%. Now, this is only an estimate. What can you say about the <em>true</em> success rate on the target population? Sure, it’s expected to be close to 75%. But how close—within 5 or 10%? It must depend on the size of the test set. Naturally, we would be more confident of the 75% figure if it were based on a test set of 10,000 instances rather than a test set of 100 instances. But how much more confident would we be?</p>
<p id="p0100" class="para_indented">To answer these questions, we need some statistical reasoning. In statistics, a succession of independent events that either succeed or fail is called a <em>Bernoulli process</em>. The classic example is coin tossing. Each toss is an independent event. Let’s say we always predict heads; but rather than “heads” or “tails,” each toss is considered a “success” or a “failure.” Let’s say the coin is biased, but we don’t know what the probability of heads is. Then, if we actually toss the coin 100 times and 75 of the tosses are heads, we have a situation very like the one just described for a classifier with an observed 75% success rate on a test set. What can we say about the true success probability? In other words, imagine that there is a Bernoulli process—a biased coin—with a true (but unknown) success rate of <em>p</em>. Suppose that out of <em>N</em> trials, <em>S</em> are successes; thus, the observed success rate is <em>f</em> = <em>S</em>/<em>N</em>. The question is, what does this tell you about the true success rate <em>p</em>?</p>
<p id="p0105" class="para_indented">The answer to this question is usually expressed as a confidence interval—that is, <em>p</em> lies within a certain specified interval with a certain specified confidence. For example, if <em>S</em> = 750 successes are observed out of <em>N</em> = 1000 trials, this indicates that the true success rate must be around 75%. But how close to 75%? It turns out that with 80% confidence, the true success rate <em>p</em> lies between 73.2% and 76.7%. If <em>S</em> = 75 successes are observed out of <em>N</em> = 100 trials, this also indicates that the true success rate must be around 75%. But the experiment is smaller, and so the 80% confidence interval for <em>p</em> is wider, stretching from 69.1 to 80.1%.</p><a id="p0110"></a><a id="p151"></a><div class="boxg" id="b0010">
<p id="p0115" class="noindent">These figures are easy to relate to qualitatively, but how are they derived quantitatively? We reason as follows: The mean and variance of a single Bernoulli trial with success rate <em>p</em> are <em>p</em> and <em>p</em>(1 − <em>p</em>), respectively. If <em>N</em> trials are taken from a Bernoulli process, the expected success rate <em>f</em> = <em>S</em>/<em>N</em> is a random variable with the same mean <em>p</em>; the variance is reduced by a factor of <em>N</em> to <em>p</em>(1 − <em>p</em>)/<em>N</em>. For large <em>N</em>, the distribution of this random variable approaches the normal distribution. These are all facts of statistics—we will not go into how they are derived.</p>
<p id="p0120" class="para_indented">The probability that a random variable <em>X</em>, with zero mean, lies within a certain confidence range of width 2<em>z</em> is</p>
<p class="figure" id="e0010"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si1.jpg" alt="image" width="142" height="29" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si1.jpg"></p>
<p></p>
<p id="p0125" class="para_indented">For a normal distribution, values of <em>c</em> and corresponding values of <em>z</em> are given in tables printed at the back of most statistical texts. However, the tabulations conventionally take a slightly different form: They give the confidence that <em>X</em> will lie outside the range, and they give it for the upper part of the range only:</p>
<p class="figure" id="e0015"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si2.jpg" alt="image" width="77" height="29" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si2.jpg"></p>
<p>This is called a <em>one-tailed</em> probability because it refers only to the upper “tail” of the distribution. Normal distributions are symmetric, so the probabilities for the lower tail</p>
<p class="figure" id="e0020"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si3.jpg" alt="image" width="85" height="29" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si3.jpg"></p>
<p>are just the same.</p>
<p id="p0130" class="para_indented"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0010">Table 5.1</a> gives an example. Like other tables for the normal distribution, this assumes that the random variable <em>X</em> has a mean of 0 and a variance of 1. Alternatively, you might say that the <em>z</em> figures are measured in <em>standard deviations from the mean</em>. Thus, the figure for Pr[<em>X</em> ≥ <em>z</em>] = 5% implies that there is a 5% chance that <em>X</em> lies more than 1.65 standard deviations above the mean. Because the distribution is symmetric, the chance that <em>X</em> lies more than 1.65 standard deviations from the mean (above or below) is 10%, or</p>
<p class="figure" id="e0025"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si4.jpg" alt="image" width="217" height="29" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si4.jpg"></p>
<p>Now all we need to do is reduce the random variable <em>f</em> to have zero mean and unit variance. We do this by subtracting the mean <em>p</em> and dividing by the standard deviation<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-001-9780123748560.jpg" alt="image" width="69" height="21" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-001-9780123748560.jpg">. This leads to</p>
<p class="figure" id="e0030"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si5.jpg" alt="image" width="223" height="54" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si5.jpg"></p>
<p></p>
<p class="table_caption"><span class="tab_num">Table 5.1. </span> Confidence Limits for the Normal Distribution</p>
<table id="t0010" frame="box" rules="all">
<thead>
<tr><td class="tch">Pr[<em><strong>X</strong></em><strong>≥</strong><em><strong>z</strong></em>]</td>
<td class="tch"><em><strong>z</strong></em></td></tr>
</thead>
<tbody valign="top">
<tr><td class="tb">0.1%</td>
<td class="tb">3.09</td></tr>
<tr><td class="tb">0.5%</td>
<td class="tb">2.58</td></tr>
<tr><td class="tb">1%</td>
<td class="tb">2.33</td></tr>
<tr><td class="tb">5%</td>
<td class="tb">1.65</td></tr>
<tr><td class="tb">10%</td>
<td class="tb">1.28</td></tr>
<tr><td class="tb">20%</td>
<td class="tb">0.84</td></tr>
<tr><td class="tb">40%</td>
<td class="tb">0.25</td></tr>
</tbody>
</table>
<p id="p0135" class="para_indented">Here is the procedure for finding confidence limits. Given a particular confidence figure <em>c</em>, consult <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0010">Table 5.1</a> for the corresponding <em>z</em> value. To use the table you will first have to subtract <em>c</em> from 1 and then halve the result, so that for <em>c</em> = 90% you use the table entry for 5%. Linear interpolation can be used for intermediate confidence levels. Then write the inequality in the preceding expression as an equality and invert it to find an expression for <em>p</em>.</p>
<p id="p0140" class="para_indented">The final step involves solving a quadratic equation. Although this is not hard to do, it leads to an unpleasantly formidable expression for the confidence limits:</p>
<p class="figure" id="e0035"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si6.jpg" alt="image" width="315" height="58" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si6.jpg"></p>
<p>The ± in this expression gives two values for <em>p</em> that represent the upper and lower confidence boundaries. Although the formula looks complicated, it is not hard to work out in particular cases.</p>
<p id="p0145" class="para_indented">This result can be used to obtain the values in the numeric example given earlier. Setting <em>f</em> = 75%, <em>N</em> = 1000, and <em>c</em> = 80% (so that <em>z</em> = 1.28) leads to the interval [0.732, 0.767] for <em>p</em>, and <em>N</em> = 100 leads to [0.691, 0.801] for the same level of confidence. Note that the normal distribution assumption is only valid for large <em>N</em> (say, <em>N</em> &gt; 100). Thus, <em>f</em> = 75% and <em>N</em> = 10 leads to confidence limits [0.549, 0.881], but these should be taken with a grain of salt.</p>
</div>
<p></p>
</div>
<div id="s0020">
<h2 id="st0020">5.3 Cross-validation</h2>
<p id="p0150" class="noindent"><a id="p152"></a>Now consider what to do when the amount of data for training and testing is limited. The holdout method reserves a certain amount for testing and uses the remainder for training (and sets part of that aside for validation, if required). In practical terms, it is common to hold out one-third of the data for testing and use the remaining two-thirds for training.</p>
<p id="p0155" class="para_indented">Of course, you may be unlucky: The sample used for training (or testing) might not be representative. In general, you cannot tell whether a sample is representative or not. But there is one simple check that might be worthwhile: Each class in the full dataset should be represented in about the right proportion in the training and testing sets. If, by bad luck, all examples with a certain class were omitted from the training set, you could hardly expect a classifier learned from that data to perform well on examples of that class—and the situation would be exacerbated by the fact that the class would necessarily be overrepresented in the test set because none of its instances made it into the training set! Instead, you should ensure that the random sampling is done in a way that guarantees that each class is properly represented in both training and test sets. This procedure is called <em>stratification</em>, and we might speak of <em>stratified holdout</em>. While it is generally well worth doing, stratification provides only a primitive safeguard against uneven representation in training and test sets.</p>
<p id="p0160" class="para_indented">A more general way to mitigate any bias caused by the particular sample chosen for holdout is to repeat the whole process, training and testing, several times with different random samples. In each iteration a certain proportion, say two-thirds, of <a id="p153"></a>the data is randomly selected for training, possibly with stratification, and the remainder is used for testing. The error rates on the different iterations are averaged to yield an overall error rate. This is the <em>repeated holdout</em> method of error rate estimation.</p>
<p id="p0165" class="para_indented">In a single holdout procedure, you might consider swapping the roles of the testing and training data—that is, train the system on the test data and test it on the training data—and average the two results, thus reducing the effect of uneven representation in training and test sets. Unfortunately, this is only really plausible with a 50:50 split between training and test data, which is generally not ideal—it is better to use more than half the data for training even at the expense of test data. However, a simple variant forms the basis of an important statistical technique called <em>cross-validation</em>. In cross-validation, you decide on a fixed number of <em>folds</em>, or partitions, of the data. Suppose we use three. Then the data is split into three approximately equal partitions; each in turn is used for testing and the remainder is used for training. That is, use two-thirds of the data for training and one-third for testing, and repeat the procedure three times so that in the end, every instance has been used exactly once for testing. This is called <em>threefold cross-validation</em>, and if stratification is adopted as well—which it often is—it is <em>stratified threefold cross-validation</em>.</p>
<p id="p0170" class="para_indented">The standard way of predicting the error rate of a learning technique given a single, fixed sample of data is to use stratified tenfold cross-validation. The data is divided randomly into 10 parts in which the class is represented in approximately the same proportions as in the full dataset. Each part is held out in turn and the learning scheme trained on the remaining nine-tenths; then its error rate is calculated on the holdout set. Thus, the learning procedure is executed a total of 10 times on different training sets (each set has a lot in common with the others). Finally, the 10 error estimates are averaged to yield an overall error estimate.</p>
<p id="p0175" class="para_indented">Why 10? Extensive tests on numerous different datasets, with different learning techniques, have shown that 10 is about the right number of folds to get the best estimate of error, and there is also some theoretical evidence that backs this up. Although these arguments are by no means conclusive, and debate continues to rage in machine learning and data mining circles about what is the best scheme for evaluation, tenfold cross-validation has become the standard method in practical terms. Tests have also shown that the use of stratification improves results slightly. Thus, the standard evaluation technique in situations where only limited data is available is stratified tenfold cross-validation. Note that neither the stratification nor the division into 10 folds has to be exact: It is enough to divide the data into 10 approximately equal sets in which the various class values are represented in approximately the right proportion. Moreover, there is nothing magic about the exact number 10: 5-fold or 20-fold cross-validation is likely to be almost as good.</p>
<p id="p0180" class="para_indented">A single tenfold cross-validation might not be enough to get a reliable error estimate. Different tenfold cross-validation experiments with the same learning scheme and dataset often produce different results because of the effect of random <a id="p154"></a>variation in choosing the folds themselves. Stratification reduces the variation, but it certainly does not eliminate it entirely. When seeking an accurate error estimate, it is standard procedure to repeat the cross-validation process 10 times—that is, 10 times tenfold cross-validation—and average the results. This involves invoking the learning algorithm 100 times on datasets that are all nine-tenths the size of the original. Getting a good measure of performance is a computation-intensive undertaking.</p>
</div>
<div id="s0025">
<h2 id="st0025">5.4 Other estimates</h2>
<p id="p0185" class="noindent">Tenfold cross-validation is the standard way of measuring the error rate of a learning scheme on a particular dataset; for reliable results, 10 times tenfold cross-validation. But many other methods are used instead. Two that are particularly prevalent are <em>leave-one-out</em> cross-validation and the <em>bootstrap</em>.</p>
<div id="s0030">
<h3 id="st0030">Leave-One-Out Cross-Validation</h3>
<p id="p0190" class="noindent">Leave-one-out cross-validation is simply <em>n</em>-fold cross-validation, where <em>n</em> is the number of instances in the dataset. Each instance in turn is left out, and the learning scheme is trained on all the remaining instances. It is judged by its correctness on the remaining instance—one or zero for success or failure, respectively. The results of all <em>n</em> judgments, one for each member of the dataset, are averaged, and that average represents the final error estimate.</p>
<p id="p0195" class="para_indented">This procedure is an attractive one for two reasons. First, the greatest possible amount of data is used for training in each case, which presumably increases the chance that the classifier is an accurate one. Second, the procedure is deterministic: No random sampling is involved. There is no point in repeating it 10 times, or repeating it at all: The same result will be obtained each time. Set against this is the high computational cost, because the entire learning procedure must be executed <em>n</em> times and this is usually infeasible for large datasets. Nevertheless, leave-one-out seems to offer a chance of squeezing the maximum out of a small dataset and getting as accurate an estimate as possible.</p>
<p id="p0200" class="para_indented">But there is a disadvantage to leave-one-out cross-validation, apart from the computational expense. By its very nature, it cannot be stratified—worse than that, it <em>guarantees</em> a nonstratified sample. Stratification involves getting the correct proportion of examples in each class into the test set, and this is impossible when the test set contains only a single example. A dramatic, although highly artificial, illustration of the problems this might cause is to imagine a completely random dataset that contains exactly the same number of instances of each of two classes. The best that an inducer can do with random data is to predict the majority class, giving a true error rate of 50%. But in each fold of leave-one-out, the opposite class to the test instance is in the majority—and therefore the predictions will always be incorrect, leading to an estimated error rate of 100%!</p>
</div>
<div id="s0035">
<h3 id="st0035"><a id="p155"></a>The Bootstrap</h3>
<p id="p0205" class="noindent">The second estimation method we describe, the bootstrap, is based on the statistical procedure of sampling <em>with replacement</em>. Previously, whenever a sample was taken from the dataset to form a training or test set, it was drawn without replacement. That is, the same instance, once selected, could not be selected again. It is like picking teams for football: You cannot choose the same person twice. But dataset instances are not like people. Most learning schemes <em>can</em> use the same instance twice, and it makes a difference in the result of learning if it is present in the training set twice. (Mathematical sticklers will notice that we should not really be talking about “sets” at all if the same object can appear more than once.)</p>
<p id="p0210" class="para_indented">The idea of the bootstrap is to sample the dataset with replacement to form a training set. We will describe a particular variant, mysteriously (but for a reason that will soon become apparent) called the <em>0.632 bootstrap</em>. For this, a dataset of <em>n</em> instances is sampled <em>n</em> times, with replacement, to give another dataset of <em>n</em> instances. Because some elements in this second dataset will (almost certainly) be repeated, there must be some instances in the original dataset that have not been picked—we will use these as test instances.</p><a id="p0215"></a><div class="boxg" id="b0015">
<p id="p0220" class="noindent">What is the chance that a particular instance will not be picked for the training set? It has a 1/<em>n</em> probability of being picked each time and so a 1 – 1/<em>n</em> probability of <em>not</em> being picked. Multiply these probabilities together for a sufficient number of picking opportunities, <em>n</em>, and the result is a figure of</p>
<p class="figure" id="e0040"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si7.jpg" alt="image" width="173" height="52" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si7.jpg"></p>
<p>where <em>e</em> is the base of natural logarithms, 2.7183 (not the error rate!) This gives the chance of a particular instance not being picked at all. Thus, for a reasonably large dataset, the test set will contain about 36.8% of the instances and the training set will contain about 63.2% of them (now you can see why it’s called the <em>0.632 bootstrap</em>). Some instances will be repeated in the training set, bringing it up to a total size of <em>n</em>, the same as in the original dataset.</p>
</div>
<p></p>
<p id="p0225" class="para_indented">The figure obtained by training a learning system on the training set and calculating its error over the test set will be a pessimistic estimate of the true error rate because the training set, although its size is <em>n</em>, nevertheless contains only 63% of the instances, which is not a great deal compared, for example, with the 90% used in tenfold cross-validation. To compensate for this, we combine the test-set error rate with the resubstitution error on the instances in the training set. The resubstitution figure, as we warned earlier, gives a very optimistic estimate of the true error and should certainly not be used as an error figure on its own. But the bootstrap procedure combines it with the test error rate to give a final estimate <em>e</em> as follows:</p>
<p class="figure" id="e0045"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si8.jpg" alt="image" width="365" height="31" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si8.jpg"></p>
<p><a id="p156"></a>Then, the whole bootstrap procedure is repeated several times, with different replacement samples for the training set, and the results are averaged.</p>
<p id="p0230" class="para_indented">The bootstrap procedure may be the best way of estimating the error rate for very small datasets. However, like leave-one-out cross-validation, it has disadvantages that can be illustrated by considering a special, artificial situation. In fact, the very dataset we considered above will do: a completely random dataset with two classes of equal size. The true error rate is 50% for any prediction rule. But a scheme that memorized the training set would give a perfect resubstitution score of 100%, so that <em>e</em>
<span class="sub">training instances</span> = 0, and the 0.632 bootstrap will mix this in with a weight of 0.368 to give an overall error rate of only 31.6% (0.632 × 50% + 0.368 × 0%), which is misleadingly optimistic.</p>
</div>
</div>
<div id="s0040">
<h2 id="st0040">5.5 Comparing data mining schemes</h2>
<p id="p0235" class="noindent">We often need to compare two different learning schemes on the same problem to see which is the better one to use. It seems simple: Estimate the error using cross-validation (or any other suitable estimation procedure), perhaps repeated several times, and choose the scheme with the smaller estimate. This is quite sufficient in many practical applications: If one scheme has a lower estimated error than another on a particular dataset, the best we can do is to use the former scheme’s model. However, it may be that the difference is simply due to estimation error, and in some circumstances it is important to determine whether one scheme is <em>really</em> better than another on a particular problem. This is a standard challenge for machine learning researchers. If a new learning algorithm is proposed, its proponents must show that it improves on the state of the art for the problem at hand and demonstrate that the observed improvement is not just a chance effect in the estimation process.</p>
<p id="p0240" class="para_indented">This is a job for a statistical test based on confidence bounds, the kind we met previously when trying to predict true performance from a given test-set error rate. If there were unlimited data, we could use a large amount for training and evaluate performance on a large independent test set, obtaining confidence bounds just as before. However, if the difference turns out to be significant we must ensure that this is not just because of the particular dataset we happened to base the experiment on. What we want to determine is whether one scheme is better or worse than another on average, across all possible training and test datasets that can be drawn from the domain. Because the amount of training data naturally affects performance, all datasets should be the same size. Indeed, the experiment might be repeated with different sizes to obtain a learning curve.</p>
<p id="p0245" class="para_indented">For the moment, assume that the supply of data is unlimited. For definiteness, suppose that cross-validation is being used to obtain the error estimates (other estimators, such as repeated cross-validation, are equally viable). For each learning scheme we can draw several datasets of the same size, obtain an accuracy estimate <a id="p157"></a>for each dataset using cross-validation, and compute the mean of the estimates. Each cross-validation experiment yields a different, independent error estimate. What we are interested in is the mean accuracy across all possible datasets of the same size, and whether this mean is greater for one scheme or the other.</p>
<p id="p0250" class="para_indented">From this point of view, we are trying to determine whether the mean of a set of samples—cross-validation estimates for the various datasets that we sampled from the domain—is significantly greater than, or significantly less than, the mean of another. This is a job for a statistical device known as the <em>t-test</em>, or <em>Student’s t-test</em>. Because the same cross-validation experiment can be used for both learning schemes to obtain a matched pair of results for each dataset, a more sensitive version of the <em>t</em>-test known as a <em>paired t-test</em> can be used.</p><a id="p0255"></a><div class="boxg" id="b0020">
<p id="p0260" class="noindent">We need some notation. There is a set of samples <em>x</em>
<span class="sub">1</span>, <em>x</em>
<span class="sub">2</span>, …, <em>x<span class="sub">k</span>
</em> obtained by successive tenfold cross-validations using one learning scheme, and a second set of samples <em>y</em>
<span class="sub">1</span>, <em>y</em>
<span class="sub">2</span>, …, <em>y<span class="sub">k</span>
</em> obtained by successive tenfold cross-validations using the other. Each cross-validation estimate is generated using a different dataset, but all datasets are of the same size and from the same domain. We will get best results if exactly the same cross-validation partitions are used for both schemes, so that <em>x</em>
<span class="sub">1</span> and <em>y</em>
<span class="sub">1</span> are obtained using the same cross-validation split, as are <em>x</em>
<span class="sub">2</span> and <em>y</em>
<span class="sub">2</span>, and so on. Denote the mean of the first set of samples by<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-002-9780123748560.jpg" alt="image" width="15" height="17" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-002-9780123748560.jpg">and the mean of the second set by<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-003-9780123748560.jpg" alt="image" width="14" height="18" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-003-9780123748560.jpg">. We are trying to determine whether <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-004-9780123748560.jpg" alt="image" width="14" height="15" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-004-9780123748560.jpg"> is significantly different from<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-005-9780123748560.jpg" alt="image" width="14" height="18" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-005-9780123748560.jpg">.</p>
<p id="p0265" class="para_indented">If there are enough samples, the mean (<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-006-9780123748560.jpg" alt="image" width="14" height="15" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-006-9780123748560.jpg">) of a set of independent samples (<em>x</em>
<span class="sub">1</span>, <em>x</em>
<span class="sub">2</span>, …, <em>x<span class="sub">k</span>
</em>) has a normal (i.e., Gaussian) distribution, regardless of the distribution underlying the samples themselves. Call the true value of the mean <em>µ</em>. If we knew the variance of that normal distribution, so that it could be reduced to have zero mean and unit variance, we could obtain confidence limits on <em>µ</em> given the mean of the samples (<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-007-9780123748560.jpg" alt="image" width="14" height="15" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-007-9780123748560.jpg">). However, the variance is unknown, and the only way we can obtain it is to estimate it from the set of samples.</p>
<p id="p0270" class="para_indented">That is not hard to do. The variance of <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-008-9780123748560.jpg" alt="image" width="14" height="15" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-008-9780123748560.jpg"> can be estimated by dividing the variance calculated from the samples <em>x</em>
<span class="sub">1</span>, <em>x</em>
<span class="sub">2</span>, …, <em>x<span class="sub">k</span>
</em>—call it <em>σ<span class="sub">x</span></em><sup>2</sup>—by <em>k</em>. We can reduce the distribution of <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-009-9780123748560.jpg" alt="image" width="14" height="15" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-009-9780123748560.jpg"> to have zero mean and unit variance by using</p>
<p class="figure" id="e0050"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si9.jpg" alt="image" width="65" height="54" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si9.jpg"></p>
<p></p>
<p id="p0275" class="para_indented">The fact that we have to <em>estimate</em> the variance changes things somewhat. Because the variance is only an estimate, this does <em>not</em> have a normal distribution (although it does become normal for large values of <em>k</em>). Instead, it has what is called a <em>Student’s distribution with k – 1 degrees of freedom</em>. What this means in practice is that we have to use a table of confidence intervals for the Student’s distribution rather than the confidence table for the normal distribution given earlier. For 9 degrees of freedom (which is the correct number if we are using the average of 10 cross-validations) the appropriate confidence limits are shown in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0015">Table 5.2</a>. If you compare them with <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0010">Table 5.1</a> you will see that the Student’s figures are slightly more conservative—for a given degree of confidence, the interval is slightly wider—and this reflects the additional uncertainty caused by having to estimate the variance. Different tables are needed for different numbers of degrees of freedom, and if there are more than 100 degrees of freedom the confidence limits are very close to those for the normal distribution. Like <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0010">Table 5.1</a>, the figures in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0015">Table 5.2</a> are for a “one-sided” confidence interval.</p>
<p class="table_caption"><span class="tab_num">Table 5.2. </span> Confidence Limits for Student’s Distribution with 9 Degrees of Freedom</p>
<table id="t0015" frame="box" rules="all">
<thead>
<tr><td class="tch">Pr[<em><strong>X</strong></em> ≥ <em><strong>z</strong></em>]</td>
<td class="tch"><em><strong>z</strong></em></td></tr>
</thead>
<tbody valign="top">
<tr><td class="tb">0.1%</td>
<td class="tb">4.30</td></tr>
<tr><td class="tb">0.5%</td>
<td class="tb">3.25</td></tr>
<tr><td class="tb">1%</td>
<td class="tb">2.82</td></tr>
<tr><td class="tb">5%</td>
<td class="tb">1.83</td></tr>
<tr><td class="tb">10%</td>
<td class="tb">1.38</td></tr>
<tr><td class="tb">20%</td>
<td class="tb">0.88</td></tr>
</tbody>
</table>
<p id="p0280" class="para_indented"><a id="p158"></a>To decide whether the means <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-010-9780123748560.jpg" alt="image" width="14" height="15" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-010-9780123748560.jpg">and<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-011-9780123748560.jpg" alt="image" width="14" height="18" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-011-9780123748560.jpg">, each an average of the same number <em>k</em> of samples, are the same or not, we consider the differences <em>d<span class="sub">i</span>
</em> between corresponding observations, <em>d<span class="sub">i</span>
</em> = <em>x<span class="sub">i</span>
</em> − <em>y<span class="sub">i</span>
</em>. This is legitimate because the observations are paired. The mean of this difference is just the difference between the two means, <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-012-9780123748560.jpg" alt="image" width="56" height="21" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-012-9780123748560.jpg">, and, like the means themselves, it has a Student’s distribution with <em>k</em> – 1 degrees of freedom. If the means are the same, the difference is zero (this is called the <em>null hypothesis</em>); if they’re significantly different, the difference will be significantly different from zero. So for a given confidence level, we will check whether the actual difference exceeds the confidence limit.</p>
<p id="p0285" class="para_indented">First, reduce the difference to a zero-mean, unit-variance variable called the <em>t</em>-<em>statistic</em>,</p>
<p class="figure" id="e0055"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si10.jpg" alt="image" width="90" height="56" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si10.jpg"></p>
<p>where <em>σ<span class="sub">d</span></em><sup>2</sup> is the variance of the difference samples. Then, decide on a confidence level—generally, 5% or 1% is used in practice. From this, the confidence limit z is determined using <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0015">Table 5.2</a> if <em>k</em> is 10; if it is not, a confidence table of the Student distribution for the <em>k</em> value in question is used. A two-tailed test is appropriate because we do not know in advance whether the mean of the <em>x</em>’s is likely to be greater than that of the <em>y</em>’s or vice versa; thus, for a 1% test we use the value corresponding to 0.5% in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0015">Table 5.2</a>. If the value of <em>t</em> according to the last formula is greater than <em>z</em>, or less than –<em>z</em>, we reject the null hypothesis that the means are the same and conclude that there really is a significant difference between the two learning methods on that domain for that dataset size.</p>
<p id="p0290" class="para_indented">Two observations are worth making on this procedure. The first is technical: What if the observations were not paired? That is, what if we were unable, for some reason, to assess the error of each learning scheme on the same datasets? What if the number of datasets for each scheme was not even the same? These conditions could arise if someone else had evaluated one of the schemes and published several different estimates for a particular domain and dataset size—or perhaps just their mean and variance—and we wished to compare this with a different learning scheme. Then it is necessary to use a regular, nonpaired <em>t</em>-test. Instead of taking the mean of the difference, <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-013-9780123748560.jpg" alt="image" width="14" height="18" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-013-9780123748560.jpg">, we use the difference of the means, <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-014-9780123748560.jpg" alt="image" width="34" height="18" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-014-9780123748560.jpg">. Of course, that’s the same thing: The mean of the difference <em>is</em> the difference of the means. But the variance of the difference <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-015-9780123748560.jpg" alt="image" width="14" height="18" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-015-9780123748560.jpg"> is <em>not</em> the same. If the variance of the samples <em>x</em>
<span class="sub">1</span>, <em>x</em>
<span class="sub">2</span>, …, <em>x<span class="sub">k</span>
</em> is <em>σ<span class="sub">x</span></em><sup>2</sup> and the variance of the samples <em>y</em>
<span class="sub">1</span>, <em>y</em>
<span class="sub">2</span>, …, <em>y</em>
<span class="sub"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/ell_8467.jpg" alt="ent" width="13" height="19" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/ell_8467.jpg"></span> is <em>σ<span class="sub">y</span></em><sup>2</sup>,</p>
<p class="figure" id="e0060"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si11.jpg" alt="image" width="79" height="50" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si11.jpg"></p>
<p>is a good estimate of the variance of the difference of the means. It is this variance (or rather its square root) that should be used as the denominator of the <em>t</em>-statistic given previously. The degrees of freedom, necessary for consulting Student’s confidence tables, should be taken conservatively to be the minimum of the degrees of freedom of the two samples. Essentially, knowing that the observations are paired allows the use of a better estimate for the variance, which will produce tighter confidence bounds.</p>
<p id="p0295" class="para_indented">The second observation concerns the assumption that there is essentially unlimited data, so that several independent datasets of the right size can be used. In practice, there is usually only a single dataset of limited size. What can be done? We could split the data into subsets (perhaps 10) and perform a cross-validation on each one. However, the overall result will only tell us whether a learning scheme is preferable for that particular size—one-tenth of the original dataset. Alternatively, the original dataset could be reused—for example, with different randomizations of the dataset for each cross-validation. However, the resulting cross-validation estimates will not be independent <a id="p159"></a>because they are not based on independent datasets. In practice, this means that a difference may be judged to be significant when in fact it is not. Indeed, just increasing the number of samples <em>k</em>—that is, the number of cross-validation runs—will eventually yield an apparently significant difference because the value of the <em>t</em>-statistic increases without bound.</p>
<p id="p0300" class="para_indented">Various modifications of the standard <em>t</em>-test have been proposed to circumvent this problem, all of them heuristic and somewhat lacking in theoretical justification. One that appears to work well in practice is the <em>corrected resampled t-test</em>. Assume for the moment that the repeated holdout method is used instead of cross-validation, repeated <em>k</em> times on different random splits of the same dataset to obtain accuracy estimates for two learning schemes. Each time, <em>n</em>
<span class="sub">1</span> instances are used for training and <em>n</em>
<span class="sub">2</span> for testing, and differences <em>d<span class="sub">i</span>
</em> are computed from performance on the test data. The corrected resampled <em>t-</em>test uses the modified statistic</p>
<p class="figure" id="e0065"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si12.jpg" alt="image" width="140" height="77" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si12.jpg"></p>
<p>in exactly the same way as the standard <em>t</em>-statistic. A closer look at the formula shows that its value cannot be increased simply by increasing <em>k.</em> The same modified statistic can be used with repeated cross-validation, which is just a special case of repeated holdout in which the individual test sets for <em>one</em> cross-validation do not overlap. For tenfold cross-validation repeated 10 times, <em>k</em> =100, <em>n</em>
<span class="sub">2</span>/<em>n</em>
<span class="sub">1</span> = 0.1/0.9, and <em>σ<span class="sub">d</span></em><sup>2</sup> is based on 100 differences.</p>
</div>
<p></p>
</div>
<div id="s0045">
<h2 id="st0045">5.6 Predicting probabilities</h2>
<p id="p0305" class="noindent">Throughout this chapter we have tacitly assumed that the goal is to maximize the success rate of the predictions. The outcome for each test instance is either <em>correct</em>, if the prediction agrees with the actual value for that instance, or <em>incorrect</em>, if it does not. There are no grays: Everything is black or white, correct or incorrect. In many situations, this is the most appropriate perspective. If the learning scheme, when it is actually applied, results in either a correct or an incorrect prediction, success is <a id="p160"></a>the right measure to use. This is sometimes called a <em>0 – 1 loss function</em>: The “loss” is either 0 if the prediction is correct or 1 if it is not. The use of <em>loss</em> is conventional, although a more optimistic terminology might couch the outcome in terms of profit instead.</p>
<p id="p0310" class="para_indented">Other situations are softer-edged. Most learning schemes can associate a probability with each prediction (as the Naïve Bayes scheme does). It might be more natural to take this probability into account when judging correctness. For example, a correct outcome predicted with a probability of 99% should perhaps weigh more heavily than one predicted with a probability of 51%, and, in a two-class situation, perhaps the latter is not all that much better than an <em>incorrect</em> outcome predicted with probability 51%. Whether it is appropriate to take prediction probabilities into account depends on the application. If the ultimate application really is just a prediction of the outcome, and no prizes are awarded for a realistic assessment of the likelihood of the prediction, it does not seem appropriate to use probabilities. If the prediction is subject to further processing, however—perhaps involving assessment by a person, or a cost analysis, or maybe even serving as input to a second-level learning process—then it may well be appropriate to take prediction probabilities into account.</p>
<div id="s0050">
<h3 id="st0050">Quadratic Loss Function</h3>
<p id="p0315" class="noindent">Suppose for a single instance there are <em>k</em> possible outcomes, or classes, and for a given instance the learning scheme comes up with a probability vector <em>p</em>
<span class="sub">1</span>, <em>p</em>
<span class="sub">2</span>, …, <em>p<span class="sub">k</span>
</em> for the classes (where these probabilities sum to 1). The actual outcome for that instance will be one of the possible classes. However, it is convenient to express it as a vector <em>a</em>
<span class="sub">1</span>, <em>a</em>
<span class="sub">2</span>, …, <em>a<span class="sub">k</span>
</em> whose <em>i</em>th component, where <em>i</em> is the actual class, is 1 and all other components are 0. We can express the penalty associated with this situation as a loss function that depends on both the <em>p</em> vector and the <em>a</em> vector.</p>
<p id="p0320" class="para_indented">One criterion that is frequently used to evaluate probabilistic prediction is the <em>quadratic loss function</em>:</p>
<p class="figure" id="e0070"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si13.jpg" alt="image" width="121" height="40" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si13.jpg"></p>
<p>Note that this is for a single instance: The summation is over possible outputs, not over different instances. Just one of the <em>a</em>’s will be 1 and the rest 0, so the sum contains contributions of <em>p<span class="sub">j</span></em><sup>2</sup> for the incorrect predictions and (1– <em>p<span class="sub">i</span>
</em>)<sup>2</sup> for the correct one. Consequently, it can be written as</p>
<p class="figure" id="e0075"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si14.jpg" alt="image" width="142" height="40" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si14.jpg"></p>
<p>where <em>i</em> is the correct class. When the test set contains several instances, the loss function is summed over them all.</p><a id="p0325"></a><div class="boxg" id="b0025">
<p id="p0330" class="noindent">It is an interesting theoretical fact that if you seek to minimize the value of the quadratic loss function in a situation where the actual class is generated probabilistically, the best strategy is to choose for the <em>p</em> vector the actual probabilities of the different outcomes—that is, <em>p<span class="sub">i</span>
</em> = Pr[class = <em>i</em>]. If the true probabilities are known, they will be the best values for <em>p</em>. If they are not, a system that strives to minimize the quadratic loss function will be encouraged to use its best estimate of Pr[class = <em>i</em>] as the value for <em>p<span class="sub">i</span>
</em>.</p>
<p id="p0335" class="para_indented">This is quite easy to see. Denote the true probabilities by <em>p</em>
<span class="sub">1</span>*, <em>p</em>
<span class="sub">2</span>*, …, <em>p<span class="sub">k</span>
</em>* so that <em>p<span class="sub">i</span>
</em>* = Pr[class = <em>i</em>]. The expected value of the quadratic loss function over test instances can be rewritten as</p>
<p class="figure" id="e0080"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si15.jpg" alt="image" width="356" height="100" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si15.jpg"></p>
<p>The first stage involves bringing the expectation inside the sum and expanding the square. For the second, <em>p<span class="sub">j</span>
</em> is just a constant and the expected value of <em>a<span class="sub">j</span>
</em> is simply <em>p<span class="sub">j</span>
</em>*; moreover, because <em>a<span class="sub">j</span>
</em> is either 0 or 1, <em>a<span class="sub">j</span>
</em><sup>2</sup> = <em>a<span class="sub">j</span>
</em> and its expected value is <em>p<span class="sub">j</span>
</em>* as well. The third stage is straightforward algebra. To minimize the resulting sum, it is clear that it is best to choose <em>p<span class="sub">j</span>
</em> = <em>p<span class="sub">j</span>
</em>*, so that the squared term disappears and all that remains is a term that is just the variance of the true distribution governing the actual class.</p>
</div>
<p></p>
<p id="p0340" class="para_indented"><a id="p161"></a>Minimizing the squared error has a long history in prediction problems. In the present context, the quadratic loss function forces the predictor to be honest about choosing its best estimate of the probabilities—or, rather, it gives preference to predictors that are able to make the best guess at the true probabilities. Moreover, the quadratic loss function has some useful theoretical properties that we will not go into here. For all these reasons, it is frequently used as the criterion of success in probabilistic prediction situations.</p>
</div>
<div id="s0055">
<h3 id="st0055">Informational Loss Function</h3>
<p id="p0345" class="noindent">Another popular criterion used to evaluate probabilistic prediction is the <em>informational loss function</em>,</p>
<p class="figure" id="e0085"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si16.jpg" alt="image" width="77" height="31" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si16.jpg"></p>
<p>where the <em>i</em>th prediction is the correct one. This is in fact identical to the negative of the log-likelihood function that is optimized by logistic regression, described in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0004.html#s0110">Section 4.6</a> (modulo a constant factor, which is determined by the base of the logarithm). It represents the information (in bits) required to express the actual class <em>i</em> with respect to the probability distribution <em>p</em>
<span class="sub">1</span>, <em>p</em>
<span class="sub">2</span>, …, <em>p<span class="sub">k</span>
</em>. In other words, if you were given the probability distribution and someone had to communicate to you which class was the one that actually occurred, this is the number of bits they would need to encode the information if they did it as effectively as possible. (Of course, it is <a id="p162"></a>always possible to use <em>more</em> bits.) Because probabilities are always less than 1, their logarithms are negative, and the minus sign makes the outcome positive. For example, in a two-class situation—heads or tails—with an equal probability of each class, the occurrence of a head would take 1 bit to transmit because −log<span class="sub">2</span> 1/2 is 1.</p><a id="p0350"></a><div class="boxg" id="b0030">
<p id="p0355" class="noindent">The expected value of the informational loss function, if the true probabilities are <em>p</em>
<span class="sub">1</span>*, <em>p</em>
<span class="sub">2</span>*, …, <em>p<span class="sub">k</span>
</em>*, is</p>
<p class="figure" id="e0090"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si17.jpg" alt="image" width="296" height="27" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si17.jpg"></p>
<p>Like the quadratic loss function, this expression is minimized by choosing <em>p<span class="sub">j</span>
</em> = <em>p<span class="sub">j</span>
</em>*, in which case the expression becomes the entropy of the true distribution:</p>
<p class="figure" id="e0095"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si18.jpg" alt="image" width="317" height="27" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si18.jpg"></p>
<p>Thus, the informational loss function also rewards honesty in predictors that know the true probabilities, and encourages predictors that do not to put forward their best guess.</p>
</div>
<p></p>
<p id="p0360" class="para_indented">One problem with the informational loss function is that if you assign a probability of 0 to an event that actually occurs, the function’s value is infinity. This corresponds to losing your shirt when gambling. Prudent predictors operating under the informational loss function do not assign zero probability to any outcome. This does lead to a problem when no information is available about that outcome on which to base a prediction. This is called the <em>zero-frequency problem</em>, and various plausible solutions have been proposed, such as the Laplace estimator discussed for Naïve Bayes in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0004.html#c0004">Chapter 4</a> (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0004.html#p0240">page 93</a>).</p>
</div>
<div id="s0060">
<h3 id="st0060">Discussion</h3>
<p id="p0365" class="noindent">If you are in the business of evaluating predictions of probabilities, which of the two loss functions should you use? That’s a good question, and there is no universally agreed-on answer—it’s really a matter of taste. They both do the fundamental job expected of a loss function: They give maximum reward to predictors that are capable of predicting the true probabilities accurately. However, there are some objective differences between the two that may help you form an opinion.</p>
<p id="p0370" class="para_indented">The quadratic loss function takes into account not only the probability assigned to the event that actually occurred but also the other probabilities. For example, in a four-class situation, suppose you assigned 40% to the class that actually came up and distributed the remainder among the other three classes. The quadratic loss will depend on how you distributed it because of the sum of the <em>p<span class="sub">j</span>
</em><sup>2</sup> that occurs in the expression given earlier for the quadratic loss function. The loss will be smallest if the 60% was distributed evenly among the three classes: An uneven distribution will increase the sum of the squares. The informational loss function, on the other hand, depends solely on the probability assigned to the class that actually occurred. If you’re <a id="p163"></a>gambling on a particular event coming up, and it does, who cares about potential winnings from other events?</p>
<p id="p0375" class="para_indented">If you assign a very small probability to the class that actually occurs, the information loss function will penalize you massively. The maximum penalty, for a zero probability, is infinite. The quadratic loss function, on the other hand, is milder, being bounded by</p>
<p class="figure" id="e0100"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si19.jpg" alt="image" width="94" height="40" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si19.jpg"></p>
<p>which can never exceed 2.</p>
<p id="p0380" class="para_indented">Finally, proponents of the informational loss function point to a general theory of performance assessment in learning called the <em>minimum description length (MDL) principle</em>. They argue that the size of the structures that a scheme learns can be measured in bits of information, and if the same units are used to measure the loss, the two can be combined in useful and powerful ways. We return to this in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0110">Section 5.9</a>.</p>
</div>
</div>
<div id="s0065">
<h2 id="st0065">5.7 Counting the cost</h2>
<p id="p0385" class="noindent">The evaluations that have been discussed so far do not take into account the cost of making wrong decisions, wrong classifications. Optimizing the classification rate without considering the cost of the errors often leads to strange results. In one case, machine learning was being used to determine the exact day that each cow in a dairy herd was in estrus, or “in heat.” Cows were identified by electronic ear tags, and various attributes were used such as milk volume and chemical composition (recorded automatically by a high-tech milking machine) and milking order—for cows are regular beasts and generally arrive in the milking shed in the same order, except in unusual circumstances such as estrus. In a modern dairy operation it’s important to know when a cow is ready: Animals are fertilized by artificial insemination and missing a cycle will delay calving unnecessarily, causing complications down the line. In early experiments, machine learning schemes stubbornly predicted that each cow was <em>never</em> in estrus. Like humans, cows have a menstrual cycle of approximately 30 days, so this “null” rule is correct about 97% of the time—an impressive degree of accuracy in any agricultural domain! What was wanted, of course, was rules that predicted the “in estrus” situation more accurately than the “not in estrus” one: The costs of the two kinds of error were different. Evaluation by classification accuracy tacitly assumes equal error costs.</p>
<p id="p0390" class="para_indented">Other examples where errors cost different amounts include loan decisions: The cost of lending to a defaulter is far greater than the lost-business cost of refusing a loan to a nondefaulter. And oil-slick detection: The cost of failing to detect an environment-threatening real slick is far greater than the cost of a false alarm. And load forecasting: The cost of gearing up electricity generators for a storm that doesn’t hit is far less than the cost of being caught completely unprepared. And diagnosis: <a id="p164"></a>The cost of misidentifying problems with a machine that turns out to be free of faults is less than the cost of overlooking problems with one that is about to fail. And promotional mailing: The cost of sending junk mail to a household that doesn’t respond is far less than the lost-business cost of not sending it to a household that would have responded. Why—these are all the examples from <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0001.html#c0001">Chapter 1</a>! In truth, you’d be hard pressed to find an application in which the costs of different kinds of errors were the same.</p>
<p id="p0395" class="para_indented">In the two-class case with classes <em>yes</em> and <em>no</em>—lend or not lend, mark a suspicious patch as an oil slick or not, and so on—a single prediction has the four different possible outcomes shown in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0020">Table 5.3</a>. The <em>true positives</em> (TP) and <em>true negatives</em> (TN) are correct classifications. A <em>false positive</em> (FP) is when the outcome is incorrectly predicted as <em>yes</em> (or positive) when it is actually <em>no</em> (negative). A <em>false negative</em> (FN) is when the outcome is incorrectly predicted as negative when it is actually positive. The <em>true positive rate</em> is TP divided by the total number of positives, which is TP + FN; the <em>false positive rate</em> is FP divided by the total number of negatives, which is FP + TN. The overall success rate is the number of correct classifications divided by the total number of classifications:</p>
<p class="figure" id="e0105"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si20.jpg" alt="image" width="173" height="56" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si20.jpg"></p>
<p>Finally, the error rate is 1 minus this.</p>
<p class="table_caption"><span class="tab_num">Table 5.3. </span> Different Outcomes of a Two-Class Prediction</p>
<p id="t0020" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055t005-001-9780123748560.jpg" alt="image" width="560" height="114" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055t005-001-9780123748560.jpg"></p>
<p id="p0400" class="para_indented">In multiclass prediction, the result on a test set is often displayed as a two-dimensional <em>confusion matrix</em> with a row and column for each class. Each matrix element shows the number of test examples for which the actual class is the row and the predicted class is the column. Good results correspond to large numbers down the main diagonal and small, ideally zero, off-diagonal elements. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0025">Table 5.4(a)</a> shows a numeric example with three classes. In this case, the test set has 200 instances (the sum of the nine numbers in the matrix), and 88 + 40 + 12 = 140 of them are predicted correctly, so the success rate is 70%.</p><a id="p165"></a><p class="table_caption"><span class="tab_num">Table 5.4. </span> Different Outcomes of a Three-Class Prediction: (a) Actual and (b) Expected</p>
<p id="t0025" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055t005-002-9780123748560.jpg" alt="image" width="875" height="200" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055t005-002-9780123748560.jpg"></p>
<p id="p0405" class="para_indented">But is this a fair measure of overall success? How many agreements would you expect <em>by chance</em>? This predictor predicts a total of 120 <em>a</em>’s, 60 <em>b</em>’s, and 20 <em>c</em>’s; what if you had a random predictor that predicted the same total numbers of the three classes? The answer is shown in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0025">Table 5.4</a>(b). Its first row divides the 100 <em>a</em>’s in the test set into these overall proportions, and the second and third rows do the same <a id="p166"></a>thing for the other two classes. Of course, the row and column totals for this matrix are the same as before—the number of instances hasn’t changed, and we have ensured that the random predictor predicts the same number of <em>a</em>’s, <em>b</em>’s, and <em>c</em>’s as the actual predictor.</p>
<p id="p0410" class="para_indented">This random predictor gets 60 + 18 + 4 = 82 instances correct. A measure called the <em>Kappa statistic</em> takes this expected figure into account by deducting it from the predictor’s successes and expressing the result as a proportion of the total for a perfect predictor, to yield 140 – 82 = 58 extra successes out of a possible total of 200 – 82 = 118, or 49.2%. The maximum value of Kappa is 100%, and the expected value for a random predictor with the same column totals is 0. In summary, the Kappa statistic is used to measure the agreement between predicted and observed categorizations of a dataset, while correcting for an agreement that occurs by chance. However, like the plain success rate, it does not take costs into account.</p>
<div id="s0070">
<h3 id="st0070">Cost-Sensitive Classification</h3>
<p id="p0415" class="noindent">If the costs are known, they can be incorporated into a financial analysis of the decision-making process. In the two-class case, in which the confusion matrix is like that of <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0020">Table 5.3</a>, the two kinds of error—false positives and false negatives—will have different costs; likewise, the two types of correct classification may have different benefits. In the two-class case, costs can be summarized in the form of a 2 × 2 matrix in which the diagonal elements represent the two types of correct classification and the off-diagonal elements represent the two types of error. In the multiclass case this generalizes to a square matrix whose size is the number of classes, and again the diagonal elements represent the cost of correct classification. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0030">Table 5.5(a) and (b)</a> shows default cost matrixes for the two- and three-class cases, whose values simply give the number of errors: Misclassification costs are all 1.</p>
<p class="table_caption"><span class="tab_num">Table 5.5. </span> Default Cost Matrixes: (a) Two-Class Case and (b) Three-Class Case</p>
<p id="t0030" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055t005-003-9780123748560.jpg" alt="image" width="560" height="172" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055t005-003-9780123748560.jpg"></p>
<p id="p0420" class="para_indented">Taking the cost matrix into account replaces the success rate by the average cost (or, thinking more positively, profit) per decision. Although we will not do so here, a complete financial analysis of the decision-making process might also take into account the cost of using the machine learning tool—including the cost of gathering the training data—and the cost of using the model, or decision structure, that it <a id="p167"></a>produces—including the cost of determining the attributes for the test instances. If all costs are known, and the projected number of the four different outcomes in the cost matrix can be estimated, say using cross-validation, it is straightforward to perform this kind of financial analysis.</p>
<p id="p0425" class="para_indented">Given a cost matrix, you can calculate the cost of a particular learned model on a given test set just by summing the relevant elements of the cost matrix for the model’s prediction for each test instance. Here, costs are ignored when making predictions, but taken into account when evaluating them.</p>
<p id="p0430" class="para_indented">If the model outputs the probability associated with each prediction, it can be adjusted to minimize the expected cost of the predictions. Given a set of predicted probabilities for each outcome on a certain test instance, one normally selects the most likely outcome. Instead, the model could predict the class with the smallest expected misclassification cost. For example, suppose in a three-class situation the model assigns the classes <em>a, b,</em> and <em>c</em> to a test instance with probabilities <em>p<span class="sub">a</span>, p<span class="sub">b</span>,</em> and <em>p<span class="sub">c</span>
</em>, and the cost matrix is that in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0030">Table 5.5</a>(b). If it predicts <em>a</em>, the expected cost of the prediction is obtained by multiplying the first column of the matrix, [0,1,1], by the probability vector, [<em>p<span class="sub">a</span>, p<span class="sub">b</span>, p<span class="sub">c</span>
</em>], yielding <em>p<span class="sub">b</span> + p<span class="sub">c</span></em>, or 1 – <em>p<span class="sub">a</span></em>, because the three probabilities sum to 1. Similarly, the costs for predicting the other two classes are 1 – <em>p<span class="sub">b</span>
</em> and 1 – <em>p<span class="sub">c</span>
</em>. For this cost matrix, choosing the prediction with the lowest expected cost is the same as choosing the one with the greatest probability. For a different cost matrix it might be different.</p>
<p id="p0435" class="para_indented">We have assumed that the learning scheme outputs probabilities, as Naïve Bayes does. Even if they do not normally output probabilities, most classifiers can easily be adapted to compute them. In a decision tree, for example, the probability distribution for a test instance is just the distribution of classes at the corresponding leaf.</p>
</div>
<div id="s0075">
<h3 id="st0075">Cost-Sensitive Learning</h3>
<p id="p0440" class="noindent">We have seen how a classifier, built without taking costs into consideration, can be used to make predictions that are sensitive to the cost matrix. In this case, costs are ignored at training time but used at prediction time. An alternative is to do just the opposite: Take the cost matrix into account during the training process and ignore costs at prediction time. In principle, better performance might be obtained if the classifier were tailored by the learning algorithm to the cost matrix.</p>
<p id="p0445" class="para_indented">In the two-class situation, there is a simple and general way to make any learning scheme cost sensitive. The idea is to generate training data with a different proportion of <em>yes</em> and <em>no</em> instances. Suppose you artificially increase the number of <em>no</em> instances by a factor of 10 and use the resulting dataset for training. If the learning scheme is striving to minimize the number of errors, it will come up with a decision structure that is biased toward avoiding errors on the <em>no</em> instances because such errors are effectively penalized tenfold. If data with the original proportion of <em>no</em> instances is used for testing, fewer errors will be made on these than on <em>yes</em> instances—that is, there will be fewer false positives than false negatives—because false positives have been weighted 10 times more heavily than false negatives. <a id="p168"></a>Varying the proportion of instances in the training set is a general technique for building cost-sensitive classifiers.</p>
<p id="p0450" class="para_indented">One way to vary the proportion of training instances is to duplicate instances in the dataset. However, many learning schemes allow instances to be weighted. (As we mentioned in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0003.html#s0015">Section 3.2</a>, this is a common technique for handling missing values.) Instance weights are normally initialized to 1. To build cost-sensitive classifiers the weights can be initialized to the relative cost of the two kinds of error, false positives and false negatives.</p>
</div>
<div id="s0080">
<h3 id="st0080">Lift Charts</h3>
<p id="p0455" class="noindent">In practice, costs are rarely known with any degree of accuracy, and people will want to ponder various different scenarios. Imagine you’re in the direct-mailing business and are contemplating a mass mailout of a promotional offer to 1,000,000 households, most of whom won’t respond, of course. Let us say that, based on previous experience, the proportion that normally respond is known to be 0.1% (1000 respondents). Suppose a data mining tool is available that, based on known information about the households, identifies a subset of 100,000 for which the response rate is 0.4% (400 respondents). It may well pay off to restrict the mailout to these 100,000 households; this, of course, depends on the mailing cost compared with the return gained for each response to the offer. In marketing terminology, the increase in response rate, a factor of 4 in this case, is known as the <em>lift</em> factor yielded by the learning tool. If you knew the costs, you could determine the payoff implied by a particular lift factor.</p>
<p id="p0460" class="para_indented">But you probably want to evaluate other possibilities too. The same data mining scheme, with different parameter settings, may be able to identify 400,000 households for which the response rate will be 0.2% (800 respondents), corresponding to a lift factor of 2. Again, whether this would be a more profitable target for the mailout can be calculated from the costs involved. It may be necessary to factor in the cost of creating and using the model, including collecting the information that is required to come up with the attribute values. After all, if developing the model is very expensive, a mass mailing may be more cost effective than a targeted one.</p>
<p id="p0465" class="para_indented">Given a learning scheme that outputs probabilities for the predicted class of each member of the set of test instances (as Naïve Bayes does), your job is to find subsets of test instances that have a high proportion of positive instances, higher than in the test set as a whole. To do this, the instances should be sorted in descending order of predicted probability of <em>yes</em>. Then, to find a sample of a given size with the greatest possible proportion of positive instances, just read the requisite number of instances off the list, starting at the top. If each test instance’s class is known, you can calculate the lift factor by simply counting the number of positive instances that the sample includes, dividing by the sample size to obtain a success proportion, and dividing by the success proportion for the complete test set to determine the lift factor.</p>
<p id="p0470" class="para_indented"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0035">Table 5.6</a><a id="p169"></a> shows an example, for a small dataset that has 150 instances, of which 50 are <em>yes</em> responses—an overall success proportion of 33%. The instances have been sorted in descending probability order according to the predicted probability of a <em>yes</em> response. The first instance is the one that the learning scheme thinks is the most likely to be positive, the second is the next most likely, and so on. The numeric values of the probabilities are unimportant: Rank is the only thing that matters. With each rank is given the actual class of the instance. Thus, the learning scheme was correct about items 1 and 2—they are indeed positives—but wrong about item 3, which turned out to be negative. Now, if you were seeking the most promising sample of size 10, but only knew the predicted probabilities and not the actual classes, your best bet would be the top 10 ranking instances. Eight of these are positive, so the success proportion for this sample is 80%, corresponding to a lift factor of about 2.4.</p>
<p class="table_caption"><span class="tab_num">Table 5.6. </span> Data for a Lift Chart</p>
<table id="t0035" frame="box" rules="all">
<thead>
<tr><td class="tch">Rank</td>
<td class="tch">Predicted</td>
<td class="tch">Actual Class</td></tr>
</thead>
<tbody valign="top">
<tr><td class="tb"> 1</td>
<td class="tb">0.95</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb"> 2</td>
<td class="tb">0.93</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb"> 3</td>
<td class="tb">0.93</td>
<td class="tb"><em>no</em></td></tr>
<tr><td class="tb"> 4</td>
<td class="tb">0.88</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb"> 5</td>
<td class="tb">0.86</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb"> 6</td>
<td class="tb">0.85</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb"> 7</td>
<td class="tb">0.82</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb"> 8</td>
<td class="tb">0.80</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb"> 9</td>
<td class="tb">0.80</td>
<td class="tb"><em>no</em></td></tr>
<tr><td class="tb">10</td>
<td class="tb">0.79</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb">11</td>
<td class="tb">0.77</td>
<td class="tb"><em>no</em></td></tr>
<tr><td class="tb">12</td>
<td class="tb">0.76</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb">13</td>
<td class="tb">0.73</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb">14</td>
<td class="tb">0.65</td>
<td class="tb"><em>no</em></td></tr>
<tr><td class="tb">15</td>
<td class="tb">0.63</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb">16</td>
<td class="tb">0.58</td>
<td class="tb"><em>no</em></td></tr>
<tr><td class="tb">17</td>
<td class="tb">0.56</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb">18</td>
<td class="tb">0.49</td>
<td class="tb"><em>no</em></td></tr>
<tr><td class="tb">19</td>
<td class="tb">0.48</td>
<td class="tb"><em>yes</em></td></tr>
<tr><td class="tb">…</td>
<td class="tb">…</td>
<td class="tb">…</td></tr>
</tbody>
</table>
<p id="p0475" class="para_indented">If you knew the different costs involved, you could work them out for each sample size and choose the most profitable. But a graphical depiction of the various possibilities will often be far more revealing than presenting a single “optimal” decision. Repeating the operation for different-size samples allows you to plot a lift chart like that of <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0025">Figure 5.1</a>. The horizontal axis shows the sample size as a proportion of the total possible mailout. The vertical axis shows the number of responses obtained. The lower left and upper right points correspond to no mailout at all, with a response of 0, and a full mailout, with a response of 1000. The diagonal line gives the expected result for different-size random samples. But we do not choose random samples; we choose those instances that, according to the data mining tool, are most likely to generate a positive response. These correspond to the upper line, which is derived by summing the actual responses over the corresponding percentage of the instance list sorted in probability order. The two particular scenarios described previously are marked: a 10% mailout that yields 400 respondents and a 40% one that yields 800.</p>
<p id="f0025" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055f005-001-9780123748560.jpg" alt="image" width="433" height="281" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055f005-001-9780123748560.jpg"></p>
<p class="figure_legend"><span class="fig_num">FIGURE 5.1</span> A hypothetical lift chart.</p>
<p id="p0480" class="para_indented">Where you’d like to be in a lift chart is near the upper left corner: At the very best, 1000 responses from a mailout of just 1000, where you send only to those <a id="p170"></a>households that will respond and are rewarded with a 100% success rate. Any selection procedure worthy of the name will keep you above the diagonal—otherwise, you’d be seeing a response that is worse than for random sampling. So the operating part of the diagram is the upper triangle, and the farther to the upper left the better.</p>
<p id="p0485" class="para_indented"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0030">Figure 5.2(a)</a> shows a visualization that allows various cost scenarios to be explored in an interactive fashion (called the <em>cost–benefit analyzer</em>, it forms part of the Weka workbench described in Part III). Here it is displaying results for predictions generated by the Naïve Bayes classifier on a real-world direct-mail data set. In this example, 47,706 instances were used for training and a further 47,706 for testing. The test instances were ranked according to the predicted probability of a response to the mailout. The graphs show a lift chart on the left and the total cost (or benefit), plotted against the sample size, on the right. At the lower left is a confusion matrix; at the lower right is a cost matrix.</p><a id="p171"></a><p id="f0030" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055f005-002ab-9780123748560.jpg" alt="image" width="513" height="665" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055f005-002ab-9780123748560.jpg"></p>
<p class="figure_legend"><span class="fig_num">FIGURE 5.2</span> Analyzing the expected benefit of a mailing campaign when the cost of mailing is (a) $0.50 and (b) $0.80.</p>
<p id="p0490" class="para_indented">Cost or benefit values associated with incorrect or correct classifications can be entered into the matrix and affect the shape of the curve above. The horizontal slider in the middle allows users to vary the percentage of the population that is selected from the ranked list. Alternatively, one can determine the sample size by adjusting the recall level (the proportion of positives to be included in the sample) or by adjusting a threshold on the probability of the positive class, which here corresponds to a response to the mailout. When the slider is moved, a large cross shows the corresponding point on both graphs. The total cost or benefit associated with the selected sample size is shown at the lower right, along with the expected response to a random mailout of the same size.</p>
<p id="p0495" class="para_indented"><a id="p172"></a>In the cost matrix in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0030">Figure 5.2(a)</a>, a cost of $0.50—the cost of mailing—has been associated with nonrespondents and a benefit of $15.00 with respondents (after deducting the mailing cost). Under these conditions, and using the Naïve Bayes classifier, there is no subset from the ranked list of prospects that yields a greater profit than mailing to the entire population. However, a slightly higher mailing cost changes the situation dramatically, and <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0030">Figure 5.2(b)</a> shows what happens when it is increased to $0.80. Assuming the same profit of $15.00 per respondent, a maximum profit of $4,560.60 is achieved by mailing to the top 46.7% of the population. In this situation, a random sample of the same size achieves a loss of $99.59.</p>
</div>
<div id="s0085">
<h3 id="st0085">ROC Curves</h3>
<p id="p0500" class="noindent">Lift charts are a valuable tool, widely used in marketing. They are closely related to a graphical technique for evaluating data mining schemes known as <em>ROC curves</em>, which are used in just the same situation, where the learner is trying to select samples of test instances that have a high proportion of positives. The acronym stands for <em>receiver operating characteristic</em>, a term used in signal detection to characterize the tradeoff between hit rate and false-alarm rate over a noisy channel. ROC curves depict the performance of a classifier without regard to class distribution or error costs. They plot the true positive rate on the vertical axis against the true negative rate on the horizontal axis. The former is the number of positives included in the sample, expressed as a percentage of the total number of positives (TP Rate = 100 × TP/(TP + FN)); the latter is the number of negatives included in the sample, expressed as a percentage of the total number of negatives (FP Rate = 100 × FP/(FP + TN)). The vertical axis is the same as the lift chart’s except that it is expressed as a percentage. The horizontal axis is slightly different—it is the number of negatives rather than the sample size. However, in direct marketing situations where the proportion of positives is very small anyway (like 0.1%), there is negligible difference between the size of a sample and the number of negatives it contains, so the ROC curve and lift chart look very similar. As with lift charts, the upper left corner is the place to be.</p>
<p id="p0505" class="para_indented"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0035">Figure 5.3</a> shows an example ROC curve—the jagged line—for the sample of test data shown earlier in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0035">Table 5.6</a>. You can follow it along with the table. From the origin: Go up two (two positives), along one (one negative), up five (five positives), along two (two negatives), up one, along one, up two, and so on. Each point corresponds to drawing a line at a certain position on the ranked list, counting the <em>yes’s</em> and <em>no’s</em> above it, and plotting them vertically and horizontally, respectively. As you go farther down the list, corresponding to a larger sample, the number of positives and negatives both increase.</p>
<p id="f0035" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055f005-003-9780123748560.jpg" alt="image" width="421" height="275" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055f005-003-9780123748560.jpg"></p>
<p class="figure_legend"><span class="fig_num">FIGURE 5.3</span> A sample ROC curve.</p>
<p id="p0510" class="para_indented">The jagged ROC line in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0035">Figure 5.3</a> depends intimately on the details of the particular sample of test data. This sample dependence can be reduced by applying cross-validation. For each different number of <em>no</em>’s—that is, each position along the horizontal axis—take just enough of the highest-ranked instances to include that number of <em>no</em>’s, and count the number of <em>yes</em>’s they contain. Finally, average that <a id="p173"></a>number over different folds of the cross-validation. The result is a smooth curve like that in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0035">Figure 5.3</a>—although in reality such curves do not generally look quite so smooth.</p>
<p id="p0515" class="para_indented">This is just one way of using cross-validation to generate ROC curves. A simpler approach is to collect the predicted probabilities for all the various test sets (of which there are 10 in a tenfold cross-validation), along with the true class labels of the corresponding instances, and generate a single ranked list based on this data. This assumes that the probability estimates from the classifiers built from the different training sets are all based on equally sized random samples of the data. It is not clear which method is preferable. However, the latter method is easier to implement.</p>
<p id="p0520" class="para_indented">If the learning scheme does not allow the instances to be ordered, you can first make it cost-sensitive as described earlier. For each fold of a tenfold cross-validation, weight the instances for a selection of different cost ratios, train the scheme on each weighted set, count the true positives and false positives in the test set, and plot the resulting point on the ROC axes. (It doesn’t matter whether the test set is weighted or not because the axes in the ROC diagram are expressed as the percentage of true and false positives.) However, for probabilistic classifiers such as Naïve Bayes it is far more costly than the method described previously because it involves a separate learning problem for every point on the curve.</p>
<p id="p0525" class="para_indented">It is instructive to look at ROC curves obtained using different learning schemes. For example, in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0040">Figure 5.4</a>, method A excels if a small, focused sample is sought—that is, if you are working toward the left side of the graph. Clearly, if you aim to cover just 40% of the true positives you should choose method A, which gives a false positive rate of around 5%, rather than method B, which gives more than 20% <a id="p174"></a>false positives. But method B excels if you are planning a large sample: If you are covering 80% of the true positives, B will give a false positive rate of 60% as compared with method A’s 80%. The shaded area is called the <em>convex hull</em> of the two curves, and you should always operate at a point that lies on the upper boundary of the convex hull.</p>
<p id="f0040" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055f005-004-9780123748560.jpg" alt="image" width="423" height="280" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055f005-004-9780123748560.jpg"></p>
<p class="figure_legend"><span class="fig_num">FIGURE 5.4</span> ROC curves for two learning schemes.</p>
<p id="p0530" class="para_indented">What about the region in the middle where neither method A nor method B lies on the convex hull? It is a remarkable fact that you can get anywhere in the shaded region by combining methods A and B and using them at random with appropriate probabilities. To see this, choose a particular probability cutoff for method A that gives true and false positive rates of <em>t<span class="sub">A</span>
</em> and <em>f<span class="sub">A</span>
</em>, respectively, and another cutoff for method B that gives <em>t<span class="sub">B</span>
</em> and <em>f<span class="sub">B</span>
</em>. If you use these two schemes at random with probabilities <em>p</em> and <em>q</em>, where <em>p</em> + <em>q</em> = 1, then you will get true and false positive rates of <em>p.t<span class="sub">A</span>
</em> + <em>q.t<span class="sub">B</span>
</em> and <em>p.f<span class="sub">A</span>
</em> + <em>q.f<span class="sub">B</span>
</em>. This represents a point lying on the straight line joining the points (<em>t<span class="sub">A</span>
</em>, <em>f<span class="sub">A</span>
</em>) and (<em>t<span class="sub">B</span>
</em>, <em>f<span class="sub">B</span>
</em>), and by varying <em>p</em> and <em>q</em> you can trace out the whole line between these two points. By this device, the entire shaded region can be reached. Only if a particular scheme generates a point that lies on the convex hull should it be used alone. Otherwise, it would always be better to use a combination of classifiers corresponding to a point that lies on the convex hull.</p>
</div>
<div id="s0090">
<h3 id="st0090">Recall–Precision Curves</h3>
<p id="p0535" class="noindent">People have grappled with the fundamental tradeoff illustrated by lift charts and ROC curves in a wide variety of domains. Information retrieval is a good example. Given a query, a Web search engine produces a list of hits that represent documents <a id="p175"></a>supposedly relevant to the query. Compare one system that locates 100 documents, 40 of which are relevant, with another that locates 400 documents, 80 of which are relevant. Which is better? The answer should now be obvious: It depends on the relative cost of false positives, documents returned that aren’t relevant, and false negatives, documents that are relevant but aren’t returned. Information retrieval researchers define parameters called <em>recall</em> and <em>precision</em>:</p>
<p class="figure" id="e0110"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si21.jpg" alt="image" width="465" height="54" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si21.jpg"></p>
<p></p>
<p class="figure" id="e0115"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si22.jpg" alt="image" width="488" height="54" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si22.jpg"></p>
<p></p>
<p id="p0540" class="para_indented">For example, if the list of <em>yes</em>’s and <em>no</em>’s in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0035">Table 5.6</a> represented a ranked list of retrieved documents and whether they were relevant or not, and the entire collection contained a total of 40 relevant documents, then “recall at 10” would refer to the recall for the top 10 documents—that is, 8/40 = 20%—while “precision at 10” would be 8/10 = 80%. Information retrieval experts use <em>recall–precision curves</em> that plot one against the other, for different numbers of retrieved documents, in just the same way as ROC curves and lift charts—except that, because the axes are different, the curves are hyperbolic in shape and the desired operating point is toward the upper right.</p>
</div>
<div id="s0095">
<h3 id="st0095">Discussion</h3>
<p id="p0545" class="noindent"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0040">Table 5.7</a> summarizes the three different ways introduced for evaluating the same basic tradeoff; TP, FP, TN, and FN are the numbers of true positives, false positives, true negatives, and false negatives, respectively. You want to choose a set of instances with a high proportion of <em>yes</em> instances and a high coverage of the <em>yes</em> instances: You can increase the proportion by (conservatively) using a smaller coverage, or (liberally) increase the coverage at the expense of the proportion. Different techniques give different tradeoffs, and can be plotted as different lines on any of these graphical charts.</p><a id="p176"></a><p class="table_caption"><span class="tab_num">Table 5.7. </span> Different Measures Used to Evaluate False Positive versus False Negative Tradeoff</p>
<p id="t0040" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/t000055tabt0040.jpg" alt="Image" width="872" height="272" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/t000055tabt0040.jpg"></p>
<p id="p0550" class="para_indented">People also seek single measures that characterize performance. Two that are used in information retrieval are <em>three-point average recall</em>, which gives the average precision obtained at recall values of 20%, 50%, and 80%, and <em>11-point average recall</em>, which gives the average precision obtained at recall values of 0%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, and 100%. Also used in information retrieval is the <em>F-measure</em>, which is</p>
<p class="figure" id="e0120"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si23.jpg" alt="image" width="352" height="60" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si23.jpg"></p>
<p></p>
<p id="p0555" class="para_indented">Different terms are used in different domains. Physicians, for example, talk about the <em>sensitivity</em> and <em>specificity</em> of diagnostic tests. Sensitivity refers to the proportion <a id="p177"></a>of people with disease who have a positive test result—that is, <em>tp</em>. Specificity refers to the proportion of people without disease who have a negative test result, which is 1 – <em>fp</em>. Sometimes the product of these is used as an overall measure:</p>
<p class="figure" id="e0125"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si24.jpg" alt="image" width="508" height="60" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si24.jpg"></p>
<p>Finally, of course, there is our old friend the success rate:</p>
<p class="figure" id="e0130"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si25.jpg" alt="image" width="173" height="56" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si25.jpg"></p>
<p></p>
<p id="p0560" class="para_indented">To summarize ROC curves in a single quantity, people sometimes use the area under the curve (AUC) because, roughly speaking, the larger the area the better the model. The area also has a nice interpretation as the probability that the classifier ranks a randomly chosen positive instance above a randomly chosen negative one. Although such measures may be useful if costs and class distributions are unknown and one scheme must be chosen to handle all situations, no single number is able to capture the tradeoff. That can only be done by two-dimensional depictions such as lift charts, ROC curves, and recall–precision diagrams.</p>
<p id="p0565" class="para_indented">Several methods are commonly employed for computing the area under the ROC curve. One, corresponding to a geometric interpretation, is to approximate it by fitting several trapezoids under the curve and summing up their area. Another is to compute the probability that the classifier ranks a randomly chosen positive instance above a randomly chosen negative one. This can be accomplished by calculating the Mann–Whitney <em>U</em> statistic, or, more specifically, the <em>ρ</em> statistic from the <em>U</em> statistic. This value is easily obtained from a list of test instances sorted in descending order of predicted probability of the positive class. For each positive instance, count how many negative ones are ranked below it (increase the count by <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-016-9780123748560.jpg" alt="image" width="25" height="31" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-016-9780123748560.jpg"> if positive and negative instances tie in rank). The <em>U</em> statistic is simply the total of these counts. The <em>ρ</em> statistic is obtained by dividing <em>U</em> by the product of the number of positive and negative instances in the test set—in other words, the <em>U</em> value that would result if all positive instances were ranked above the negative ones.</p>
<p id="p0570" class="para_indented">The area under the precision–recall curve (AUPRC) is an alternative summary statistic that is preferred by some practitioners, particularly in the information retrieval area.</p>
</div>
<div id="s0100">
<h3 id="st0100">Cost Curves</h3>
<p id="p0575" class="noindent">ROC curves and their relatives are very useful for exploring the tradeoffs among different classifiers over a range of scenarios. However, they are not ideal for evaluating machine learning models in situations with known error costs. For example, it is not easy to read off the expected cost of a classifier for a fixed cost matrix and class distribution. Neither can you easily determine the ranges of applicability of different classifiers. For example, from the crossover point between the two ROC <a id="p178"></a>curves in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0040">Figure 5.4</a> it is hard to tell for what cost and class distributions classifier A outperforms classifier B.</p>
<p id="p0580" class="para_indented"><em>Cost curves</em> are a different kind of display on which a single classifier corresponds to a straight line that shows how the performance varies as the class distribution changes. Again, they work best in the two-class case, although you can always make a multiclass problem into a two-class one by singling out one class and evaluating it against the remaining ones.</p>
<p id="p0585" class="para_indented"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0045">Figure 5.5(a)</a> plots the expected error against the probability of one of the classes. You could imagine adjusting this probability by resampling the test set in a nonuniform way. We denote the two classes by + and –. The diagonals show the performance of two extreme classifiers: One always predicts +, giving an expected error of 1 if the dataset contains no + instances and 0 if all its instances are +; the other always predicts –, giving the opposite performance. The dashed horizontal line shows the performance of the classifier that is always wrong, and the <em>x</em>-axis itself represents the classifier that is always correct. In practice, of course, neither of these is realizable. Good classifiers have low error rates, so where you want to be is as close to the bottom of the diagram as possible.</p>
<p id="f0045" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055f005-005ab-9780123748560.jpg" alt="image" width="568" height="272" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055f005-005ab-9780123748560.jpg"></p>
<p class="figure_legend"><span class="fig_num">FIGURE 5.5</span> Effect of varying the probability threshold: (a) error curve and (b) cost curve.</p>
<p id="p0590" class="para_indented">The line marked A represents the error rate of a particular classifier. If you calculate its performance on a certain test set, its false positive rate, <em>fp</em>, is its expected error on a subsample of the test set that contains only examples that are negative (<em>p</em>[+] = 0), and its false negative rate, <em>fn</em>, is the error on a subsample that contains only positive examples, (<em>p</em>[+] = 1). These are the values of the intercepts at the left and right, respectively. You can see immediately from the plot that if <em>p</em>[+] is smaller than about 0.2, predictor A is outperformed by the extreme classifier that always predicts –, while if it is larger than about 0.65, the other extreme classifier is better.</p>
<p id="p0595" class="para_indented"><a id="p179"></a>So far we have not taken costs into account, or rather we have used the default cost matrix in which all errors cost the same. Cost curves, which do take cost into account, look very similar—very similar indeed—but the axes are different. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0045">Figure 5.5(b)</a> shows a cost curve for the same classifier A (note that the vertical scale has been enlarged, for convenience, and ignore the gray lines for now). It plots the expected cost of using A against the probability cost function, which is a distorted version of <em>p</em>[+] that retains the same extremes: 0 when <em>p</em>[+] = 0 and 1 when <em>p</em>[+] = 1. Denote by <em>C</em>[+ | –] the cost of predicting + when the instance is actually –, and the reverse by <em>C</em>[– | +]. Then the axes of <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0045">Figure 5.5(b)</a> are</p>
<p class="figure" id="e0135"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si26.jpg" alt="image" width="481" height="31" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si26.jpg"></p>
<p></p>
<p class="figure" id="e0140"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si27.jpg" alt="image" width="515" height="60" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si27.jpg"></p>
<p>We are assuming here that correct predictions have no cost: <em>C</em>[+ | +] = <em>C</em>[– | –] = 0. If that is not the case, the formulas are a little more complex.</p>
<p id="p0600" class="para_indented">The maximum value that the normalized expected cost can have is 1—that is why it is “normalized.” One nice thing about cost curves is that the extreme cost values at the left and right sides of the graph are <em>fp</em> and <em>fn</em>, just as they are for the error curve, so you can draw the cost curve for any classifier very easily.</p>
<p id="p0605" class="para_indented"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0045">Figure 5.5(b)</a> also shows classifier B, whose expected cost remains the same across the range—that is, its false positive and false negative rates are equal. As you can see, it outperforms classifier A if the probability cost function exceeds about 0.45, and knowing the costs we could easily work out what this corresponds to in terms of class distribution. In situations that involve different class distributions, cost curves make it easy to tell when one classifier will outperform another.</p>
<p id="p0610" class="para_indented">In what circumstances might this be useful? To return to our example of predicting when cows will be in estrus, their 30-day cycle, or 1/30 prior probability, is unlikely to vary greatly (barring a genetic cataclysm!). But a particular herd may have different proportions of cows that are likely to reach estrus in any given week, perhaps synchronized with—who knows?—the phase of the moon. Then, different classifiers would be appropriate at different times. In the oil spill example, different batches of data may have different spill probabilities. In these situations cost curves can help to show which classifier to use when.</p>
<p id="p0615" class="para_indented">Each point on a lift chart, ROC curve, or recall–precision curve represents a classifier, typically obtained by using different threshold values for a method such as Naïve Bayes. Cost curves represent each classifier by a straight line, and a suite of classifiers will sweep out a curved envelope whose lower limit shows how well that type of classifier can do if the parameter is well chosen. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#f0045">Figure 5.5(b)</a> indicates this with a few gray lines. If the process were continued, it would sweep out the dotted parabolic curve.</p>
<p id="p0620" class="para_indented">The operating region of classifier B ranges from a probability cost value of about 0.25 to a value of about 0.75. Outside this region, classifier B is outperformed by the trivial classifiers represented by dashed lines. Suppose we decide to use classifier <a id="p180"></a>B within this range and the appropriate trivial classifier below and above it. All points on the parabola are certainly better than this scheme. But how much better? It is hard to answer such questions from an ROC curve, but the cost curve makes them easy. The performance difference is negligible if the probability cost value is around 0.5, and below a value of about 0.2 and above 0.8 it is barely perceptible. The greatest difference occurs at probability cost values of 0.25 and 0.75 and is about 0.04, or 4% of the maximum possible cost figure.</p>
</div>
</div>
<div id="s0105">
<h2 id="st0105">5.8 Evaluating numeric prediction</h2>
<p id="p0625" class="noindent">All the evaluation measures we have described pertain to classification situations rather than numeric prediction situations. The basic principles—using an independent test set rather than the training set for performance evaluation, the holdout method, cross-validation—apply equally well to numeric prediction. But the basic quality measure offered by the error rate is no longer appropriate: Errors are not simply present or absent; they come in different sizes.</p>
<p id="p0630" class="para_indented">Several alternative measures, some of which are summarized in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0045">Table 5.8</a>, can be used to evaluate the success of numeric prediction. The predicted values on the test instances are <em>p</em>
<span class="sub">1</span>, <em>p</em>
<span class="sub">2</span>, …, <em>p<span class="sub">n</span>
</em>; the actual values are <em>a</em>
<span class="sub">1</span>, <em>a</em>
<span class="sub">2</span>, …, <em>a<span class="sub">n</span>
</em>. Notice that <em>p<span class="sub">i</span>
</em> means <a id="p181"></a>something very different here from what it meant in the last section: There it was the probability that a particular prediction was in the <em>i</em>th class; here it refers to the numerical value of the prediction for the <em>i</em>th test instance.</p>
<p class="table_caption"><span class="tab_num">Table 5.8. </span> Performance Measures for Numeric Prediction</p>
<table id="t0045" frame="box" rules="all">
<tbody valign="top">
<tr><td class="tb">Mean-squared error</td>
<td class="tb"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-022-9780123748560.jpg" alt="image" width="396" height="100" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-022-9780123748560.jpg"></td></tr>
<tr><td class="tb">Root mean-squared error</td>
<td class="tb"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-023-9780123748560.jpg" alt="image" width="421" height="108" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-023-9780123748560.jpg"></td></tr>
<tr><td class="tb">Mean-absolute error</td>
<td class="tb"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-024-9780123748560.jpg" alt="image" width="350" height="100" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-024-9780123748560.jpg"></td></tr>
<tr><td class="tb">Relative-squared error<sup><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#tn0010" id="cc000055tn0010" class="totri-footnote">*</a></sup></td>
<td class="tb"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-025-9780123748560.jpg" alt="image" width="396" height="108" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-025-9780123748560.jpg"></td></tr>
<tr><td class="tb">Root relative-squared error<sup><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#tn0010" class="totri-footnote">*</a></sup></td>
<td class="tb"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-026-9780123748560.jpg" alt="image" width="421" height="117" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-026-9780123748560.jpg"></td></tr>
<tr><td class="tb">Relative-absolute error<sup><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#tn0010" class="totri-footnote">*</a></sup></td>
<td class="tb"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-027-9780123748560.jpg" alt="image" width="350" height="108" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-027-9780123748560.jpg"></td></tr>
<tr><td class="tb">Correlation coefficient<sup><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#tn0015" id="cc000055tn0015">**</a></sup></td>
<td class="tb"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-028-9780123748560.jpg" alt="image" width="47" height="40" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-028-9780123748560.jpg">, where <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-029-9780123748560.jpg" alt="image" width="379" height="108" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-029-9780123748560.jpg">, <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-030-9780123748560.jpg" alt="image" width="279" height="108" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-030-9780123748560.jpg">, <img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-031-9780123748560.jpg" alt="image" width="275" height="108" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-031-9780123748560.jpg"></td></tr>
</tbody>
</table>
<p id="tn0010" class="table_footnotes"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#cc000055tn0010" class="totri-footnote"><span class="sup">*</span></a> Here,<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-032-9780123748560.jpg" alt="image" width="14" height="17" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-032-9780123748560.jpg"> is the mean value over the training data.</p>
<p id="tn0015" class="table_footnotes"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#cc000055tn0015"><span class="sup">**</span></a> Here,<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-033-9780123748560.jpg" alt="image" width="14" height="17" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-033-9780123748560.jpg"> is the mean value over the test data.</p>
<p id="p0635" class="para_indented"><em>Mean-squared error</em> is the principal and most commonly used measure; sometimes the square root is taken to give it the same dimensions as the predicted value itself. Many mathematical techniques (such as linear regression, explained in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0004.html#c0004">Chapter 4</a>) use the mean-squared error because it tends to be the easiest measure to manipulate mathematically: It is, as mathematicians say, “well behaved.” However, here we are considering it as a performance measure: All the performance measures are easy to calculate, so mean-squared error has no particular advantage. The question is, is it an appropriate measure for the task at hand?</p>
<p id="p0640" class="para_indented"><em>Mean absolute error</em> is an alternative: Just average the magnitude of the individual errors without taking account of their sign. Mean-squared error tends to exaggerate the effect of outliers—instances when the prediction error is larger than the others—but absolute error does not have this effect: All sizes of error are treated evenly according to their magnitude.</p>
<p id="p0645" class="para_indented">Sometimes it is the <em>relative</em> rather than <em>absolute</em> error values that are of importance. For example, if a 10% error is equally important whether it is an error of 50 in a prediction of 500 or an error of 0.2 in a prediction of 2, then averages of absolute error will be meaningless—relative errors are appropriate. This effect would be taken into account by using the relative errors in the mean-squared error calculation or the mean absolute error calculation.</p>
<p id="p0650" class="para_indented"><em>Relative squared</em> error in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0045">Table 5.8</a> refers to something quite different. The error is made relative to what it would have been if a simple predictor had been used. The simple predictor in question is just the average of the actual values from the training data, denoted by<img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055if005-017-9780123748560.jpg" alt="image" width="15" height="18" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055if005-017-9780123748560.jpg">. Thus, relative squared error takes the total squared error and normalizes it by dividing by the total squared error of the default predictor. The root relative squared error is obtained in the obvious way.</p>
<p id="p0655" class="para_indented">The next error measure goes by the glorious name of <em>relative absolute error</em> and is just the total absolute error, with the same kind of normalization. In these three relative error measures, the errors are normalized by the error of the simple predictor that predicts average values.</p>
<p id="p0660" class="para_indented">The final measure in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0045">Table 5.8</a> is the correlation coefficient, which measures the statistical correlation between the <em>a</em>’s and the <em>p</em>’s. The correlation coefficient ranges from 1 for perfectly correlated results, through 0 when there is no correlation, to –1 when the results are perfectly correlated negatively. Of course, negative values should not occur for reasonable prediction methods. Correlation is slightly different from the other measures because it is scale independent in that, if you take a particular set of predictions, the error is unchanged if all the predictions are multiplied by a constant factor and the actual values are left unchanged. This factor appears in every term of <em>S<span class="sub">PA</span>
</em> in the numerator and in every term of <em>S<span class="sub">P</span>
</em> in the denominator, thus canceling out. (This is not true for the relative error figures, despite normalization: If you multiply all the predictions by a large constant, then the difference between the predicted and actual values will change dramatically, as will the percentage <a id="p182"></a>errors.) It is also different in that good performance leads to a large value of the correlation coefficient, whereas because the other methods measure error, good performance is indicated by small values.</p>
<p id="p0665" class="para_indented">Which of these measures is appropriate in any given situation is a matter that can only be determined by studying the application itself. What are we trying to minimize? What is the cost of different kinds of error? Often it is not easy to decide. The squared error measures and root-squared error measures weigh large discrepancies much more heavily than small ones, whereas the absolute error measures do not. Taking the square root (root mean-squared error) just reduces the figure to have the same dimensionality as the quantity being predicted. The relative error figures try to compensate for the basic predictability or unpredictability of the output variable: If it tends to lie fairly close to its average value, then you expect prediction to be good and the relative figure compensates for this. Otherwise, if the error figure in one situation is far greater than in another situation, it may be because the quantity in the first situation is inherently more variable and therefore harder to predict, not because the predictor is any worse.</p>
<p id="p0670" class="para_indented">Fortunately, it turns out that in most practical situations the best numerical prediction method is still the best no matter which error measure is used. For example, <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#t0050">Table 5.9</a> shows the result of four different numeric prediction techniques on a given dataset, measured using cross-validation. Method D is the best according to all five metrics: It has the smallest value for each error measure and the largest correlation coefficient. Method C is the second best by all five metrics. The performance of A and B is open to dispute: They have the same correlation coefficient; A is better than B according to mean-squared and relative squared errors, and the reverse is true for absolute and relative absolute error. It is likely that the extra emphasis that the squaring operation gives to outliers accounts for the differences in this case.</p>
<p class="table_caption"><span class="tab_num">Table 5.9. </span> Performance Measures for Four Numeric Prediction Models</p>
<p id="t0050" class="figure"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/t000055tabt0050.jpg" alt="Image" width="560" height="137" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/t000055tabt0050.jpg"></p>
<p id="p0675" class="para_indented">When comparing two different learning schemes that involve numeric prediction, the methodology developed in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0040">Section 5.5</a> still applies. The only difference is that success rate is replaced by the appropriate performance measure (e.g., root mean-squared error) when performing the significance test.</p>
</div>
<div id="s0110">
<h2 id="st0110">5.9 <a id="p183"></a>Minimum description length principle</h2>
<p id="p0680" class="noindent">What is learned by a machine learning scheme is a kind of “theory” of the domain from which the examples are drawn, a theory that is predictive in that it is capable of generating new facts about the domain—in other words, the class of unseen instances. <em>Theory</em> is rather a grandiose term: We are using it here only in the sense of a predictive model. Thus, theories might comprise decision trees or sets of rules—they don’t have to be any more “theoretical” than that.</p>
<p id="p0685" class="para_indented">There is a long-standing tradition in science that, other things being equal, simple theories are preferable to complex ones. This is known as <em>Occam’s Razor</em> after the medieval philosopher William of Occam (or Ockham). Occam’s Razor shaves philosophical hairs off a theory. The idea is that the best scientific theory is the smallest one that explains all the facts. As Einstein is reputed to have said, “Everything should be made as simple as possible, but no simpler.” Of course, quite a lot is hidden in the phrase “other things being equal,” and it can be hard to assess objectively whether a particular theory really does “explain” all the facts on which it is based—that’s what controversy in science is all about.</p>
<p id="p0690" class="para_indented">In our case, in machine learning, most theories make errors. And if what is learned is a theory, then the errors it makes are like <em>exceptions</em> to the theory. One way to ensure that other things <em>are</em> equal is to insist that the information embodied in the exceptions is included as part of the theory when its “simplicity” is judged.</p>
<p id="p0695" class="para_indented">Imagine an imperfect theory for which there are a few exceptions. Not all the data is explained by the theory, but most is. What we do is simply adjoin the exceptions to the theory, specifying them explicitly as exceptions. This new theory is larger: That is a price that, quite justifiably, has to be paid for its inability to explain all the data. However, it may be that the simplicity—is it too much to call it <em>elegance</em>?—of the original theory is sufficient to outweigh the fact that it does not quite explain everything compared with a large, baroque theory that is more comprehensive and accurate.</p>
<p id="p0700" class="para_indented">For example, even though Kepler’s three laws of planetary motion did not at the time account for the known data quite so well as Copernicus’ latest refinement of the Ptolemaic theory of epicycles, they had the advantage of being far less complex, and that would have justified any slight apparent inaccuracy. Kepler was well aware of the benefits of having a theory that was compact, despite the fact that his theory violated his own aesthetic sense because it depended on “ovals” rather than pure circular motion. He expressed this in a forceful metaphor: “I have cleared the Augean stables of astronomy of cycles and spirals, and left behind me only a single cartload of dung.”</p>
<p id="p0705" class="para_indented">The <em>minimum description length</em>, or MDL, principle takes the stance that the best theory for a body of data is one that minimizes the size of the theory plus the amount of information necessary to specify the exceptions relative to the theory—the smallest “cartload of dung.” In statistical estimation theory, this has been applied successfully to various parameter-fitting problems. It applies to machine learning as follows: Given a set of instances, a learning scheme infers a theory—be it ever so simple; <a id="p184"></a>unworthy, perhaps, to be called a “theory”—from them. Using a metaphor of communication, imagine that the instances are to be transmitted through a noiseless channel. Any similarity that is detected among them can be exploited to give a more compact coding. According to the MDL principle, the best theory is the one that minimizes the number of bits required to communicate the theory, along with the labels of the examples from which it was made.</p>
<p id="p0710" class="para_indented">Now the connection with the informational loss function introduced in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0045">Section 5.6</a> should be starting to emerge. That function measures the error in terms of the number of bits required to transmit the instances’ class labels, given the probabilistic predictions made by the theory. According to the MDL principle, we need to add to this the “size” of the theory in bits, suitably encoded, to obtain an overall figure for complexity. However, the MDL principle refers to the information required to transmit the examples from which the theory was formed—that is, the <em>training</em> instances, not a test set. The overfitting problem is avoided because a complex theory that overfits will be penalized relative to a simple one by virtue of the fact that it takes more bits to encode. At one extreme is a very complex, highly overfitted theory that makes no errors on the training set. At the other is a very simple theory—the null theory—which does not help at all when transmitting the training set. And in between are theories of intermediate complexity, which make probabilistic predictions that are imperfect and need to be corrected by transmitting some information about the training set. The MDL principle provides a means of comparing all these possibilities on an equal footing to see which is the best. We have found the holy grail: an evaluation scheme that works on the training set alone and does not need a separate test set. But the devil is in the details, as we will see.</p>
<p id="p0715" class="para_indented">Suppose a learning scheme comes up with a theory <em>T</em>, based on a training set <em>E</em> of examples, that requires a certain number of bits L[<em>T</em>] to encode, where L is for length. We are only interested in predicting class labels correctly, so we assume that <em>E</em> stands for the collection of class labels in the training set. Given the theory, the training set itself can be encoded in a certain number of bits, L[<em>E</em> | <em>T</em>]. L[<em>E</em> | <em>T</em>] is in fact given by the informational loss function summed over all members of the training set. Then the total description length of theory plus training set is</p>
<p class="figure" id="e0145"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si28.jpg" alt="image" width="123" height="29" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si28.jpg"></p>
<p>and the MDL principle recommends choosing the theory <em>T</em> that minimizes this sum.</p>
<p id="p0720" class="para_indented">There is a remarkable connection between the MDL principle and basic probability theory. Given a training set <em>E</em>, we seek the “most likely” theory <em>T</em>—that is, the theory for which the a posteriori probability Pr[<em>T</em> | <em>E</em>]—the probability after the examples have been seen—is maximized. Bayes’ rule of conditional probability (the very same rule that we encountered in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0004.html#s0025">Section 4.2</a>) dictates that</p>
<p class="figure" id="e0150"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si29.jpg" alt="image" width="215" height="60" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si29.jpg"></p>
<p><a id="p185"></a>Taking negative logarithms,</p>
<p class="figure" id="e0155"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si30.jpg" alt="image" width="448" height="29" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si30.jpg"></p>
<p></p>
<p id="p0725" class="para_indented">Maximizing the probability is the same as minimizing its negative logarithm. Now (as we saw in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0045">Section 5.6</a>) the number of bits required to code something is just the negative logarithm of its probability. Furthermore, the final term, log Pr[<em>E</em>], depends solely on the training set and not on the learning method. Thus, choosing the theory that maximizes the probability Pr[<em>T</em> | <em>E</em>] is tantamount to choosing the theory that minimizes</p>
<p class="figure" id="e0160"><img src="https://www.safaribooksonline.com/library/view/data-mining-practical/9780123748560/images/f000055si31.jpg" alt="image" width="131" height="27" data-mfp-src="/library/view/data-mining-practical/9780123748560/images/f000055si31.jpg"></p>
<p>In other words, the MDL principle!</p>
<p id="p0730" class="para_indented">This astonishing correspondence with the notion of maximizing the a posteriori probability of a theory after the training set has been taken into account gives credence to the MDL principle. But it also points out where the problems will sprout when the principle is applied in practice. The difficulty with applying Bayes’ rule directly is in finding a suitable prior probability distribution Pr[<em>T</em>] for the theory. In the MDL formulation, that translates into finding how to code the theory <em>T</em> into bits in the most efficient way. There are many ways of coding things, and they all depend on presuppositions that must be shared by encoder and decoder. If you know in advance that the theory is going to take a certain form, you can use that information to encode it more efficiently. How are you going to actually encode <em>T</em>? The devil is in the details.</p>
<p id="p0735" class="para_indented">Encoding <em>E</em> with respect to <em>T</em> to obtain L[<em>E</em> | <em>T</em>] seems a little more straightforward: We have already met the informational loss function. But actually, when you encode one member of the training set after another, you are encoding a <em>sequence</em> rather than a <em>set</em>. It is not necessary to transmit the training set in any particular order, and it ought to be possible to use that fact to reduce the number of bits required. Often, this is simply approximated by subtracting log <em>n!</em> (where <em>n</em> is the number of elements in <em>E</em>), which is the number of bits needed to specify a particular permutation of the training set (and because this is the same for all theories, it doesn’t actually affect the comparison between them). But one can imagine using the frequency of the individual errors to reduce the number of bits needed to code them. Of course, the more sophisticated the method that is used to code the errors, the less the need for a theory in the first place—so whether a theory is justified or not depends to some extent on how the errors are coded. The details, the details.</p>
<p id="p0740" class="para_indented">We end this section as we began, on a philosophical note. It is important to appreciate that Occam’s Razor, the preference of simple theories over complex ones, has the status of a philosophical position or “axiom” rather than something that can be proven from first principles. While it may seem self-evident to us, this is a function of our education and the times we live in. A preference for simplicity is—or may be—culture specific rather than absolute.</p>
<p id="p0745" class="para_indented"><a id="p186"></a>The Greek philosopher Epicurus (who enjoyed good food and wine and supposedly advocated sensual pleasure—in moderation—as the highest good) expressed almost the opposite sentiment. His <em>principle of multiple explanations</em> advises that “If more than one theory is consistent with the data, keep them all” on the basis that if several explanations are equally in agreement, it may be possible to achieve a higher degree of precision by using them together—and, anyway, it would be unscientific to discard some arbitrarily. This brings to mind instance-based learning, in which all the evidence is retained to provide robust predictions, and resonates strongly with decision combination methods such as bagging and boosting (described in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0008.html#c0008">Chapter 8</a>) that actually do gain predictive power by using multiple explanations together.</p>
</div>
<div id="s0115">
<h2 id="st0115">5.10 Applying the MDL principle to clustering</h2>
<p id="p0750" class="noindent">One of the nice things about the minimum description length principle is that, unlike other evaluation criteria, it can be applied under widely different circumstances. Although in some sense equivalent to Bayes’ rule in that, as we have seen, devising a coding scheme for theories is tantamount to assigning them a prior probability distribution, schemes for coding are somehow far more tangible and easier to think about in concrete terms than intuitive prior probabilities. To illustrate this we will briefly describe—without entering into coding details—how you might go about applying the MDL principle to clustering.</p>
<p id="p0755" class="para_indented">Clustering seems intrinsically difficult to evaluate. Whereas classification or association learning has an objective criterion of success—predictions made on test cases are either right or wrong—this is not so with clustering. It seems that the only realistic evaluation is whether the result of learning—the clustering—proves useful in the application context. (It is worth pointing out that really this is the case for all types of learning, not just clustering.)</p>
<p id="p0760" class="para_indented">Despite this, clustering can be evaluated from a description-length perspective. Suppose a cluster-learning technique divides the training set <em>E</em> into <em>k</em> clusters. If these clusters are natural ones, it should be possible to use them to encode <em>E</em> more efficiently. The best clustering will support the most efficient encoding.</p>
<p id="p0765" class="para_indented">One way of encoding the instances in <em>E</em> with respect to a given clustering is to start by encoding the cluster centers—the average value of each attribute over all instances in the cluster. Then, for each instance in <em>E</em>, transmit which cluster it belongs to (in log<span class="sub">2</span><em>k</em> bits) followed by its attribute values with respect to the cluster center—perhaps as the numeric difference of each attribute value from the center. Couched as it is in terms of averages and differences, this description presupposes numeric attributes and raises thorny questions of how to code numbers efficiently. Nominal attributes can be handled in a similar manner: For each cluster there is a probability distribution for the attribute values, and the distributions are different for different clusters. The coding issue becomes more straightforward: Attribute values are coded with respect to the relevant probability distribution, a standard operation in data compression.</p>
<p id="p0770" class="para_indented"><a id="p187"></a>If the data exhibits extremely strong clustering, this technique will result in a smaller description length than simply transmitting the elements of <em>E</em> without any clusters. However, if the clustering effect is not so strong, it will likely increase rather than decrease the description length. The overhead of transmitting cluster-specific distributions for attribute values will more than offset the advantage gained by encoding each training instance relative to the cluster it lies in. This is where more sophisticated coding techniques come in. Once the cluster centers have been communicated, it is possible to transmit cluster-specific probability distributions adaptively, in tandem with the relevant instances: The instances themselves help to define the probability distributions, and the probability distributions help to define the instances. We will not venture further into coding techniques here. The point is that the MDL formulation, properly applied, may be flexible enough to support the evaluation of clustering. But actually doing it satisfactorily in practice is not easy.</p>
</div>
<div id="s0120">
<h2 id="st0120">5.11 Further reading</h2>
<p id="p0775" class="noindent">The statistical basis of confidence tests is well covered in most statistics texts, which also give tables of the normal distribution and Student’s distribution. (We use an excellent course text by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib317">Wild and Seber (1995)</a> that we recommend very strongly if you can get hold of it.) “Student” is the <em>nom de plume</em> of a statistician called William Gosset, who obtained a post as a chemist in the Guinness brewery in Dublin, Ireland, in 1899 and invented the <em>t</em>-test to handle small samples for quality control in brewing. The corrected resampled <em>t</em>-test was proposed by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib236">Nadeau and Bengio (2003)</a>. Cross-validation is a standard statistical technique, and its application in machine learning has been extensively investigated and compared with the bootstrap by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib184">Kohavi (1995a)</a>. The bootstrap technique itself is thoroughly covered by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib92">Efron and Tibshirani (1993)</a>.</p>
<p id="p0780" class="para_indented">The Kappa statistic was introduced by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib62">Cohen (1960)</a>. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib294">Ting (2002)</a> has investigated a heuristic way of generalizing to the multiclass case the algorithm given in <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#s0065">Section 5.7</a> to make two-class learning schemes cost sensitive. Lift charts are described by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib22">Berry and Linoff (1997)</a>. The use of ROC analysis in signal detection theory is covered by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib93">Egan (1975)</a>; this work has been extended for visualizing and analyzing the behavior of diagnostic systems (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib293">Swets, 1988</a>) and is also used in medicine (<a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib20">Beck and Schultz, 1986</a>). <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib253">Provost and Fawcett (1997)</a> brought the idea of ROC analysis to the attention of the machine learning and data mining community. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib321">Witten et al. (1999b)</a> explain the use of recall and precision in information retrieval systems; the <em>F</em>-measure is described by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib302">van Rijsbergen (1979)</a>. <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib88">Drummond and Holte (2000)</a> introduced cost curves and investigated their properties.</p>
<p id="p0785" class="para_indented">The MDL principle was formulated by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib267">Rissanen (1985)</a>. Kepler’s discovery of his economical three laws of planetary motion, and his doubts about them, are recounted by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib183">Koestler (1964)</a>.</p>
<p id="p0790" class="para_indented">Epicurus’ principle of multiple explanations is mentioned by <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib207">Li and Vityani (1992)</a>, quoting from <a href="/Library/view/data-mining-practical/9780123748560/xhtml/bib00023.html#bib13">Asmis (1984)</a>.<a id="p188"></a></p>
</div>
</div>
<div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-0" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#">Copy</a></li>
		
		<li class="add-highlight"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#">Add Highlight</a></li>
		<li class="add-note"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0004.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">Chapter 4. Algorithms</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="/Library/view/data-mining-practical/9780123748560/xhtml/p3.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">PART II. Advanced Data Mining</div>
        </a>
    
  
  </div>


        
    </section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 68.0057px;">
    <a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" class="icon-up"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/playlists/">Playlists</a>
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2018 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>




    

    

<div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.27947903069523417"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.11588983442097045" width="0" height="0" alt="" src="https://bat.bing.com/action/0?ti=5794699&amp;Ver=2&amp;mid=25d3b08c-4c33-61cd-b0d8-63ff047c497e&amp;pi=-371479882&amp;lg=en-US&amp;sw=1280&amp;sh=800&amp;sc=24&amp;tl=Chapter%205.%20Credibility%20-%20Data%20Mining%3A%20Practical%20Machine%20Learning%20Tools%20and%20Techniques,%203rd%20Edition&amp;p=https%3A%2F%2Fwww.safaribooksonline.com%2Flibrary%2Fview%2Fdata-mining-practical%2F9780123748560%2Fxhtml%2Fc0005.html&amp;r=&amp;evt=pageLoad&amp;msclkid=N&amp;rn=178200"></div>



    
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 201.011px; left: 1081.01px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="/Library/view/data-mining-practical/9780123748560/xhtml/c0005.html#">Reset</a>
</div>
</div></body></html>