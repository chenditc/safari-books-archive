<!--[if IE]><![endif]--><!DOCTYPE html><!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/site-reliability-engineering/9781491929117/ch17.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="859452"
  data-user-uuid="4d373bec-fada-4717-9823-769db3ed3a36"
  data-username="dchen267"
  data-account-type="B2B"
  
  data-activated-trial-date="04/25/2016"


  data-archive="9781491929117"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch17.html"
  data-epub-title="Site Reliability Engineering" data-debug=0 data-testing=0><![endif]--><!--[if gt IE 8]><!--><html class=" js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/site-reliability-engineering/9781491929117/ch17.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="859452" data-user-uuid="4d373bec-fada-4717-9823-769db3ed3a36" data-username="dchen267" data-account-type="B2B" data-activated-trial-date="04/25/2016" data-archive="9781491929117" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch17.html" data-epub-title="Site Reliability Engineering" data-debug="0" data-testing="0"><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491929117"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900,200italic,300italic,400italic,600italic,700italic,900italic" rel="stylesheet" type="text/css"><title>17. Testing for Reliability - Site Reliability Engineering</title><link rel="stylesheet" href="https://www.safaribooksonline.com/static/CACHE/css/c1c7ad294784.css" type="text/css"><link rel="stylesheet" type="text/css" href="https://www.safaribooksonline.com/static/css/annotator.min.fd58f69f4908.css"><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"><style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content font,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}@page{margin:5px !important}#sbo-rt-content p{margin:8px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content sup{font-size:x-small;vertical-align:super}#sbo-rt-content sub{font-size:smaller;vertical-align:sub}#sbo-rt-content span.lineannotation{font-style:italic;color:#A62A2A;font-family:serif,"DejaVuSerif"}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#FFF}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center;-webkit-border-radius:5px;border-radius:5px;border:1px solid #DCDCDC;padding:15px 5px 15px 5px !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif,"DejaVuSerif";color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;-webkit-border-radius:5px;border-radius:5px;border:1px solid #DCDCDC;background-color:#F7F7F7;font-size:90%;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif,"DejaVuSans";text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif,"DejaVuSerif";color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:15px}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div.caution,#sbo-rt-content div.sidebar div.important{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content div.sidebar div.figure,#sbo-rt-content aside[data-type="sidebar"] figure{border:none}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-family:sans-serif;font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;font-family:serif,"DejaVuSerif";margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle{font-size:1em;font-weight:normal;text-align:center}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1em;font-family:serif,"DejaVuSerif";font-weight:bold;color:#8e0012;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{font-size:1em;font-family:serif,"DejaVuSerif";font-weight:normal;text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);position:absolute;bottom:0;max-width:100%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif,"DejaVuSerif";font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif,"DejaVuSerif";font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif,"DejaVuSerif";margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif,"DejaVuSerif";font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif,"DejaVuSerif";font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10pt}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-family:serif,"DejaVuSerif";font-style:italic}#sbo-rt-content blockquote div.attribution{margin:5px 0 0 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p{font-style:normal}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{font-size:85%;border-top:2px solid black;padding-left:1.5em;margin-top:1.5em}#sbo-rt-content p[data-type="footnote"]{margin-top:-.5em}#sbo-rt-content p[data-type="footnote"] sup{left:-1em;top:1.2em;position:relative;display:block}#sbo-rt-content div.refnamediv h2,#sbo-rt-content div.refnamediv h3,#sbo-rt-content div.refsynopsisdiv h2{font-size:1.1em;color:#000;margin-top:15px !important;margin-bottom:0 !important}#sbo-rt-content div.refentry div.refsect1 h2{font-size:1.1em;color:#000;margin-top:15px !important;margin-bottom:0 !important}#sbo-rt-content div.refsect2 h3{font-size:1em;color:#000;margin-top:10px !important;margin-bottom:0 !important}#sbo-rt-content div.refnamediv p{margin-left:15px !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dt span.term{font-weight:bold;font-style:italic}#sbo-rt-content dt span.term code.literal{font-style:normal;font-weight:normal}#sbo-rt-content dd{margin-left:1.5em !important}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ol{list-style-type:decimal;margin-top:8px !important;margin-bottom:8px !important;margin-left:20px !important;padding-left:25px !important}#sbo-rt-content ol ol{list-style-type:lower-alpha}#sbo-rt-content ol ol ol{list-style-type:lower-roman}#sbo-rt-content ul{list-style-type:square;margin-top:8px !important;margin-bottom:8px !important;margin-left:5px !important;padding-left:20px !important}#sbo-rt-content ul ul{list-style-type:none;padding-left:0 !important;margin-left:0 !important}#sbo-rt-content ol li,#sbo-rt-content ul li,#sbo-rt-content dd{margin-bottom:.25em}#sbo-rt-content ul ul li p:before{content:"— "}#sbo-rt-content ul ul ul li p:before{content:""}#sbo-rt-content ul ul ul{list-style-type:square;margin-left:20px !important;padding-left:30px !important}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist{margin-left:20px !important;margin-bottom:10px}#sbo-rt-content table.simplelist td{border:none;font-size:90%}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img{padding:0}#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;-webkit-border-radius:5px;border-radius:5px;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{font-weight:bold;font-size:110%;font-family:sans-serif,"DejaVuSans";text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;-webkit-border-radius:0;border-radius:0;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px auto 30px auto !important;max-width:95%;border-collapse:collapse;border-spacing:0}#sbo-rt-content div.table,#sbo-rt-content div.informaltable{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif,"DejaVuSans";color:#000;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{padding:.3em;text-align:left;vertical-align:baseline;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif,"DejaVuSerif";margin:10px 0 10px 0 !important;text-align:center;padding:0;page-break-after:avoid}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title{font-style:italic;font-weight:normal;font-family:serif,"DejaVuSerif";margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{font-weight:bold;text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:20px}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif,"DejaVuSerif";text-align:left}#sbo-rt-content span.roman_text{font-style:normal !important}
    </style><link rel="canonical" href="/site/library/view/site-reliability-engineering/9781491929117/ch17.html"><meta name="description" content=" Chapter 17. Testing for Reliability Written by Alex Perry and Max Luebbe Edited by Diane Bates If you haven’t tried it, assume it’s broken. Unknown One key responsibility ... "><meta property="og:title" content="17. Testing for Reliability"><meta itemprop="isPartOf" content="/library/view/site-reliability-engineering/9781491929117/"><meta itemprop="name" content="17. Testing for Reliability"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/ch17.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491929117/"><meta property="og:description" itemprop="description" content=" Chapter 17. Testing for Reliability Written by Alex Perry and Max Luebbe Edited by Diane Bates If you haven’t tried it, assume it’s broken. Unknown One key responsibility ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491929124"><meta property="og:book:author" itemprop="author" content="Niall Richard Murphy"><meta property="og:book:author" itemprop="author" content="Jennifer Petoff"><meta property="og:book:author" itemprop="author" content="Chris Jones"><meta property="og:book:author" itemprop="author" content="Betsy Beyer"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta property="og:book:tag" itemprop="about" content="Networking"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: <%= font_size %> !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: <%= font_family %> !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: <%= column_width %>% !important; margin: 0 auto !important; }"></style><!--[if lt IE 9]><script src="/static/js/src/respond.min.cf5c9b7980e5.js"></script><![endif]--></head>


<body class="reading sidenav nav-collapsed  js-show-related scalefonts" data-gr-c-s-loaded="true">

    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        




<a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#container" class="skip">Skip to content</a><header class="topbar t-topbar" style="display:None"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg width="20" height="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z" fill="currentColor"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z" fill="currentColor"></path></g></svg><span>Queue</span></a></li><li class="search"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z" fill="currentColor"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z" fill="currentColor"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z" fill="currentColor"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z" fill="currentColor"></path></g></svg><span>Tutorials</span></a></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/003o000000t5q9fAAA/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z" fill="currentColor"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z" fill="currentColor"></path></g></svg><span>Settings</span></a></li><li><a href="https://community.safaribooksonline.com/" class="l1 no-icon">Feedback</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z" fill="currentColor"></path></g></svg><span>Settings</span></a></li><li><a href="https://community.safaribooksonline.com/" class="l2">Feedback</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Site Reliability Engineering
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491929117/chapter/ch17.html"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/ch17.html&amp;text=Site%20Reliability%20Engineering&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/ch17.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/ch17.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%2017.%20Testing%20for%20Reliability&amp;body=https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/ch17.html%0D%0Afrom%20Site%20Reliability%20Engineering%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
      
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="/site/library/view/site-reliability-engineering/9781491929117/ch16.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">16. Tracking Outages</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="/site/library/view/site-reliability-engineering/9781491929117/ch18.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">18. Software Engineering in SRE</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content" style="transform: none;"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 17. Testing for Reliability"><div class="chapter" id="chapter_testing">
<h1><span class="label">Chapter 17. </span>Testing for Reliability</h1>


<p class="byline">Written by Alex Perry and Max Luebbe</p>

<p class="byline">Edited by Diane Bates</p>
<blockquote data-type="epigraph" epub:type="epigraph">
<p>If you haven’t tried it, assume it’s broken.</p>
<p data-type="attribution">Unknown</p>
</blockquote>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="goals of" id="idm140203532184320"></a><a data-type="indexterm" data-primary="testing" data-see="reliability testing" id="idm140203532183376"></a>One key responsibility of Site Reliability Engineers is to quantify
confidence in the systems they maintain. SREs perform this task by
adapting classical software testing techniques to systems at
scale.<sup><a data-type="noteref" id="idm140203532182080-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532182080">1</a></sup>
Confidence can be measured both by past reliability and future
reliability. The former is captured by analyzing data provided by
monitoring historic system behavior, while the latter is quantified by
making predictions from data about past system behavior. In order for
these predictions to be strong enough to be useful, one of the
following conditions must hold:</p>

<ul>
<li>
<p>The site remains completely unchanged over time with no software
releases or changes in the server fleet, which means that future
behavior will be similar to past behavior.</p>
</li>
<li>
<p>You can confidently describe all changes to the site, in order for
analysis to allow for the uncertainty incurred by each of these
changes.</p>
</li>
</ul>

<p>Testing is the mechanism you use to demonstrate specific areas of
equivalence when changes occur.<sup><a data-type="noteref" id="idm140203532177296-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532177296">2</a></sup>
Each test that passes both before and after a change reduces the
uncertainty for which the analysis needs to allow. Thorough testing
helps us predict the future reliability of a given site with enough
detail to be practically useful.</p>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="amount required" id="idm140203532174752"></a>The amount of testing you need to conduct depends on the reliability
requirements for your system. As the percentage of your codebase
covered by tests increases, you reduce uncertainty and the potential
decrease in reliability from each change. Adequate testing coverage
means that you can make more changes before reliability falls below an
acceptable level. If you make too many changes too quickly, the
predicted reliability approaches the acceptability limit. At this
point, you may want to stop making changes while new monitoring data
accumulates. The accumulating data supplements the tested coverage,
which validates the reliability being asserted for revised execution
paths.  Assuming the served clients are randomly distributed
<a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/bibliography01.html#Woo96">[Woo96]</a>, sampling statistics can extrapolate from monitored metrics
whether the aggregate behavior is making use of new paths. These
statistics identify the areas that need better testing or other
retrofitting.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm140203532171744">
<h5>Relationships Between Testing and Mean Time to Repair</h5>
<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="MTTR and" id="idm140203532170576"></a><a data-type="indexterm" data-primary="mean time" data-secondary="to repair (MTTR)" id="idm140203532169632"></a>Passing a test or a series of tests doesn’t necessarily prove
reliability. However, tests that are failing generally prove the
absence of reliability.</p>

<p>A monitoring system can uncover bugs, but only as quickly as the
reporting pipeline can react. The <em>Mean Time to Repair</em> (MTTR)
measures how long it takes the operations team to fix the bug, either
through a rollback or another action.</p>

<p><a data-type="indexterm" data-primary="mean time" data-secondary="between failures (MTBF)" id="idm140203532167024"></a>It’s possible for a testing system to identify a bug with zero
MTTR. Zero MTTR occurs when a system-level test is applied to a
subsystem, and that test detects the exact same problem that
monitoring would detect. Such a test enables the push to be blocked so
the bug never reaches production (though it still needs to be repaired
in the source code). Repairing zero MTTR bugs by blocking a push is
both quick and convenient. The more bugs you can find with zero MTTR,
the higher the <em>Mean Time Between Failures</em> (MTBF) experienced by your
users.</p>

<p>As MTBF increases in response to better testing, developers are
encouraged to release features faster. Some of these features will, of
course, have bugs. New bugs result in an opposite adjustment to
release velocity as these bugs are found and fixed.</p>
</div></aside>

<p>Authors writing about software testing largely agree on what
coverage is needed. Most conflicts of opinion stem from conflicting
terminology, differing emphasis on the impact of testing in each of
the software lifecycle phases, or the particularities of the systems
on which they’ve conducted testing. For a discussion about testing at
Google in general, see <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/bibliography01.html#Whi12">[Whi12]</a>. The following sections specify how
software testing–related terminology is used in this chapter.</p>






<section data-type="sect1" data-pdf-bookmark="Types of Software Testing"><div class="sect1" id="idm140203532162256">
<h1>Types of Software Testing</h1>

<p>Software tests broadly fall into two categories: traditional and
production. Traditional tests are more common in software development
to evaluate the correctness of software offline, during
development. Production tests are performed on a live web
service to evaluate whether a deployed software system is working
correctly.</p>








<section data-type="sect2" data-pdf-bookmark="Traditional Tests"><div class="sect2" id="idm140203532160480">
<h2>Traditional Tests</h2>

<p>As shown in <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#fig_testing_hierarchy">Figure&nbsp;17-1</a>, traditional software testing begins with unit tests. Testing of more
complex functionality is layered atop unit tests.</p>

<figure><div id="fig_testing_hierarchy" class="figure">
<img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/srle_1701.png" alt="The hierarchy of traditional tests." width="1007" height="872">
<h6><span class="label">Figure 17-1. </span>The hierarchy of traditional tests</h6>
</div></figure>










<section data-type="sect3" data-pdf-bookmark="Unit tests"><div class="sect3" id="idm140203532155984">
<h3>Unit tests</h3>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="unit tests" id="idm140203532154848"></a><a data-type="indexterm" data-primary="unit tests" id="idm140203532153904"></a>A <em>unit test</em> is the smallest and simplest form of software
testing. These tests are employed to assess a separable unit of
software, such as a class or function, for correctness independent of
the larger software system that contains the unit. Unit tests are also
employed as a form of specification to ensure that a function or
module exactly performs the behavior required by the system. Unit
tests are commonly used to introduce test-driven development concepts.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Integration tests"><div class="sect3" id="idm140203532151872">
<h3>Integration tests</h3>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="integration tests" id="idm140203532150736"></a><a data-type="indexterm" data-primary="integration tests" id="idm140203532149792"></a>Software components that pass individual unit tests are assembled into
larger components. Engineers then run an <em>integration test</em> on an
assembled component to verify that it functions correctly. Dependency
injection, which is performed with tools such as Dagger,<sup><a data-type="noteref" id="idm140203532148304-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532148304">3</a></sup> is an extremely powerful technique
for creating mocks of complex dependencies so that an engineer can
cleanly test a component. A common example of a dependency injection
is to replace a stateful database with a lightweight mock that has
precisely specified behavior.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="System tests"><div class="sect3" id="idm140203532145856">
<h3>System tests</h3>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="system tests" id="idm140203532144720"></a><a data-type="indexterm" data-primary="system tests" id="idm140203532143776"></a>A <em>system test</em> is the largest scale test that engineers run for an
undeployed system. All modules belonging to a specific component, such
as a server that passed integration tests, are assembled into the
system. Then the engineer tests the end-to-end functionality of the
system. System tests come in many different flavors:</p>
<dl>
<dt>Smoke tests</dt>
<dd>
<p><em>Smoke tests</em>, <a data-type="indexterm" data-primary="reliability testing" data-secondary="smoke tests" id="idm140203532140448"></a><a data-type="indexterm" data-primary="reliability testing" data-secondary="sanity testing" id="idm140203532139504"></a><a data-type="indexterm" data-primary="smoke tests" id="idm140203532138560"></a><a data-type="indexterm" data-primary="sanity testing" id="idm140203532137888"></a>in which engineers test very simple but critical
behavior, are among the simplest type of system tests. Smoke tests are
also known as <em>sanity testing</em>, and serve to short-circuit additional
and more expensive testing.</p>
</dd>
<dt>Performance tests</dt>
<dd>
<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="performance tests" id="idm140203532135264"></a><a data-type="indexterm" data-primary="performance tests" id="idm140203532134320"></a>Once basic correctness is established via a smoke test, a common next
step is to write another variant of a system test to ensure that the
performance of the system stays acceptable over the duration of its
lifecycle. Because response times for dependencies or resource requirements
may change dramatically during the course of development, a system
needs to be tested to make sure that it doesn’t become incrementally
slower without anyone noticing (before it gets released to users).
For example, a given program may
evolve to need 32 GB of memory when it formerly only needed 8 GB, or a
10 ms response time might turn into 50 ms, and then into 100 ms. A
performance test ensures that over time, a system doesn’t degrade or
become too expensive.</p>
</dd>
<dt>Regression tests</dt>
<dd>
<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="regression tests" id="idm140203532131568"></a><a data-type="indexterm" data-primary="regression tests" id="idm140203532130624"></a>Another type of system test involves preventing bugs from sneaking
back into the codebase. Regression tests can be analogized to a
gallery of rogue bugs that historically caused the system to fail or
produce incorrect results. By documenting these bugs as tests at the
system or integration level, engineers refactoring the codebase can
be sure that they don’t accidentally introduce bugs that they’ve
already invested time and effort to eliminate.</p>

<p>It’s important to note that tests have a cost, both in terms of time
and computational resources. At one extreme, unit tests are very cheap
in both dimensions, as they can usually be completed in milliseconds
on the resources available on a laptop. At the other end of the
spectrum, bringing up a complete server with required dependencies (or
mock equivalents) to run related tests can take significantly more
time—from several minutes to multiple hours—and possibly require
dedicated computing resources. Mindfulness of these costs is essential
to developer productivity, and also encourages more efficient use of
testing resources.</p>
</dd>
</dl>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Production Tests"><div class="sect2" id="idm140203532127488">
<h2>Production Tests</h2>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="production tests" id="idm140203532126352"></a><a data-type="indexterm" data-primary="production tests" id="idm140203532125408"></a>Production tests interact with a live production system, as opposed to
a system in a hermetic testing environment. These tests are in
many ways similar to black-box monitoring (see <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch06.html#chapter_monitoring">Chapter&nbsp;6</a>), and are therefore sometimes
called <em>black-box testing</em>. Production tests are essential to running
a reliable production service.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm140203532122896">
<h5>Rollouts Entangle Tests</h5>
<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="timing of" id="idm140203532121760"></a>It’s often said that testing is (or should be) performed in a hermetic
environment <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/bibliography01.html#Nar12">[Nar12]</a>. This statement implies that production is not
hermetic. Of course, production usually isn’t hermetic, because
rollout cadences make live changes to the production environment in
small and well-understood chunks.</p>

<p>To manage uncertainty and hide risk from users, changes might not be
pushed live in the same order that they were added to source
control. Rollouts often happen in stages, using mechanisms that
gradually shuffle users around, in addition to monitoring at each
stage to ensure that the new environment isn’t hitting anticipated yet
unexpected problems. As a result, the entire production environment is
intentionally not representative of any given version of a binary
that’s checked into source control.</p>

<p>It’s possible for source control to have more than one version of a
binary and its associated configuration file waiting to be made
live. This scenario can cause problems when tests are conducted
against the live environment. For example, the test might use the
latest version of a configuration file located in source control along
with an older version of the binary that’s live. Or it might test an
older version of the configuration file and find a bug that’s been
fixed in a newer version of the file.</p>

<p>Similarly, a system test can use the configuration files to assemble
its modules before running the test. If the test passes, but its
version is one in which the configuration test (discussed in the following section) fails, the result of
the test is valid hermetically, but not operationally. Such an outcome
is inconvenient.</p>
</div></aside>










<section data-type="sect3" data-pdf-bookmark="Configuration test"><div class="sect3" id="idm140203532116608">
<h3>Configuration test</h3>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="configuration tests" id="idm140203532115472"></a><a data-type="indexterm" data-primary="configuration tests" id="idm140203532114528"></a>At Google, web service configurations are described in files that are
stored in our version control system. For each configuration file, a
separate <em>configuration test</em> examines production to see how a
particular binary is actually configured and reports discrepancies
against that file. Such tests are inherently not hermetic, as they
operate outside the test infrastructure sandbox.</p>

<p>Configuration tests are built and tested for a specific version of the
checked-in configuration file. Comparing which version of the test is
passing in relation to the goal version for automation implicitly
indicates how far actual production currently lags behind ongoing
engineering work.</p>

<p>These nonhermetic configuration tests tend to be especially valuable as part of a distributed monitoring solution since the pattern of passes/fails across production can identify paths through the service stack that don’t have sensible combinations of the local configurations. The monitoring solution’s rules try to match paths of actual user requests (from the trace logs) against that set of undesirable paths. Any matches found by the rules become alerts that ongoing releases and/or pushes are not proceeding safely and remedial action is needed.</p>

<p>Configuration tests can be very simple when the production deployment uses the actual file content and offers a real-time query to retrieve a copy of the content. In this case, the test code simply issues that query and diffs the response against the file. The tests become more complex when the configuration does one of the following:</p>

<ul>
<li>
<p>Implicitly incorporates defaults that are built into the binary (meaning that the tests are separately versioned as a result)</p>
</li>
<li>
<p>Passes through a preprocessor such as bash into command-line flags (rendering the tests subject to expansion rules)</p>
</li>
<li>
<p>Specifies behavioral context for a shared runtime (making the tests depend on that runtime’s release schedule)</p>
</li>
</ul>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Stress test"><div class="sect3" id="idm140203532106672">
<h3>Stress test</h3>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="stress tests" id="idm140203532105536"></a><a data-type="indexterm" data-primary="stress tests" id="idm140203532104592"></a>In order to safely operate a system, SREs need
to understand the limits of both the system and its components. In
many cases, individual components don’t gracefully degrade beyond a
certain point—instead, they catastrophically fail. Engineers use
<em>stress tests</em> to find the limits on a web service. Stress tests
answer questions such as:</p>

<ul>
<li>
<p>How full can a database get before writes start to fail?</p>
</li>
<li>
<p>How many queries a second can be sent to an application server
before it becomes overloaded, causing requests to fail?</p>
</li>
</ul>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Canary test"><div class="sect3" id="idm140203532100304">
<h3>Canary test</h3>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="canary tests" id="idm140203532099168"></a><a data-type="indexterm" data-primary="canarying" id="idm140203532098224"></a>The <em>canary test</em> is conspicuously absent from this list of production
tests. The term <em>canary</em> comes from the phrase “canary in a coal mine,”
and refers to the practice of using a live bird to detect toxic gases
before humans were poisoned.</p>

<p>To conduct a canary test, a subset of servers is upgraded to a new
version or configuration and then left in an incubation period. Should
no unexpected variances <span class="keep-together">occur, the</span> release continues and the rest of the
servers are upgraded in a progressive fashion.<sup><a data-type="noteref" id="idm140203532094944-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532094944">4</a></sup>  Should anything go awry, the single
modified server can be quickly reverted to a known good state. We
commonly refer to the incubation period for the upgraded server as
“baking the binary.”</p>

<p>A canary test isn’t really a test; rather, it’s structured user
acceptance. Whereas configuration and stress tests confirm the
existence of a specific condition over deterministic software, a
canary test is more ad hoc. It only exposes the code under test to
less predictable live production traffic, and thus, it isn’t perfect
and doesn’t always catch newly introduced faults.</p>

<p>To provide a concrete example of how a canary might proceed: consider
a given underlying fault that relatively rarely impacts user traffic
and is being deployed with an upgrade rollout that is exponential.
We expect a growing cumulative number of reported variances
<img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_7.png" alt="upper C upper U equals upper R upper K" width="118" height="20"> where <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_8.png" alt="upper R" width="19" height="19"> is the rate
of those reports, <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_9.png" alt="upper U" width="19" height="20"> is the order of the fault (defined
later), and <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_10.png" alt="upper K" width="20" height="19"> is the period over which the traffic grows
by a factor of <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_11.png" alt="e" width="12" height="13">, or 172%.<sup><a data-type="noteref" id="idm140203532088592-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532088592">5</a></sup></p>

<p>In order to avoid user impact, a rollout that triggers undesirable
variances needs to be quickly rolled back to the prior
configuration. In the short time it takes automation to observe the
variances and respond, it is likely that several additional reports
will be generated. Once the dust has settled, these reports can
estimate both the cumulative number <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_13.png" alt="upper C" width="19" height="20"> and rate
<img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_14.png" alt="upper R" width="19" height="19">.</p>

<p>Dividing and correcting for <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_15.png" alt="upper K" width="20" height="19"> gives an estimate of
<img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_16.png" alt="upper U" width="19" height="20">, the order of the underlying fault.<sup><a data-type="noteref" id="idm140203532083024-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532083024">6</a></sup> Some examples:</p>

<ul>
<li>
<p>U=1: The user’s request encountered code that is simply broken.</p>
</li>
<li>
<p>U=2: This user’s request randomly damages data that a future user’s
request may see.</p>
</li>
<li>
<p>U=3: The randomly damaged data is also a valid identifier to a previous request.</p>
</li>
</ul>

<p>Most bugs are of order one: they scale linearly with the amount of
user traffic <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/bibliography01.html#Per07">[Per07]</a>. You can generally track down these bugs by
converting logs of all requests with unusual responses into new
regression tests. This strategy doesn’t work for higher-order bugs; a
request that repeatedly fails if all the preceding requests are
attempted in order will suddenly pass if some requests are omitted. It
is important to catch these higher-order bugs during release, because
otherwise, operational workload can increase very quickly.</p>

<p>Keeping the dynamics of higher- versus lower-order bugs in mind, when you are using an exponential rollout strategy, it isn’t necessary to attempt
to achieve fairness among fractions of user traffic. As long as each
method for establishing a fraction uses the same <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_17.png" alt="upper K" width="20" height="19">
interval, the estimate of <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_18.png" alt="upper U" width="19" height="20"> will be valid even though
you can’t yet determine which method was instrumental in illuminating
the fault. Using many methods sequentially while permitting some
overlap keeps the value of <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_19.png" alt="upper K" width="20" height="19"> small. This strategy
minimizes the total number of user-visible variances <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_20.png" alt="upper C" width="19" height="20">
while still allowing an early estimate of <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_21.png" alt="upper U" width="19" height="20"> (hoping for
1, of course).</p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Creating a Test and Build Environment"><div class="sect1" id="idm140203534092544">
<h1>Creating a Test and Build Environment</h1>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="creating test and build environments" id="idm140203534091392"></a><a data-type="indexterm" data-primary="test environments" data-seealso="reliability testing" id="idm140203534090432"></a><a data-type="indexterm" data-primary="build environments" id="idm140203534089488"></a>While it’s wonderful to think about these types of tests and failure
scenarios on day one of a project, frequently SREs join a developer
team when a project is already well underway—once the team’s project
validates its research model, its library proves that the project’s
underlying algorithm is scalable, or perhaps when all of the user
interface mocks are finally acceptable. The team’s codebase is still a
prototype and comprehensive testing hasn’t yet been designed or
deployed. In such situations, where should your testing efforts begin?
Conducting unit tests for every key function and class is a completely
overwhelming prospect if the current test coverage is low or
nonexistent. Instead, start with testing that delivers the most impact
with the least effort.</p>

<p>You can start your approach by asking the following questions:</p>

<ul>
<li>
<p>Can you prioritize the codebase in any way? To borrow a technique
from feature development and project management, if every task is
high priority, none of the tasks are high priority.  Can you stack-rank the components of the system you’re testing by any measure of
importance?</p>
</li>
<li>
<p>Are there particular functions or classes that are absolutely
mission-critical or business-critical? For example, code that
involves billing is a commonly business-critical. Billing code is
also frequently cleanly separable from other parts of the system.</p>
</li>
<li>
<p>Which APIs are other teams integrating against? Even the kind of
breakage that never makes it past release testing to a user can be
extremely harmful if it confuses another developer team, causing
them to write wrong (or even just suboptimal) clients for your API.</p>
</li>
</ul>

<p>Shipping software that is obviously broken is among the most cardinal
sins of a developer. It takes little effort to create a series of
smoke tests to run for every release. This type of low-effort,
high-impact first step can lead to highly tested, reliable <span class="keep-together">software</span>.</p>

<p>One way to establish a strong testing culture<sup><a data-type="noteref" id="idm140203534081616-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534081616">7</a></sup> is to start
documenting all reported bugs as test cases. If every bug is converted
into a test, each test is supposed to initially fail because the bug
hasn’t yet been fixed. As engineers fix the bugs, the software passes
testing and you’re on the road to developing a comprehensive
regression test suite.</p>

<p>Another key task for creating well-tested software is to set up a
testing infrastructure. The foundation for a strong testing
infrastructure is a versioned source control system that tracks every
change to the codebase.</p>

<p>Once source control is in place, you can add a continuous build system
that builds the software and runs tests every time code is
submitted. We’ve found it optimal if the build system notifies
engineers the moment a change breaks a software project. At the risk
of sounding obvious, it’s essential that the latest version of a
software project in source control is working completely. When the
build system notifies engineers about broken code, they should drop
all of their other tasks and prioritize fixing the problem. It is
appropriate to treat defects this seriously for a few reasons:</p>

<ul>
<li>
<p>It’s usually harder to fix what’s broken if there are changes to
the codebase after the defect is introduced.</p>
</li>
<li>
<p>Broken software slows down the team because they must work around
the <span class="keep-together">breakage</span>.</p>
</li>
<li>
<p>Release cadences, such as nightly and weekly builds, lose their
value.</p>
</li>
<li>
<p>The ability of the team to respond to a request for an emergency
release (for example, in response to a security vulnerability
disclosure) becomes much more complex and difficult.</p>
</li>
</ul>

<p>The concepts of stability and agility are traditionally in tension in
the world of SRE. The last bullet point provides an interesting case
where stability actually drives agility. When the build is predictably
solid and reliable, developers can iterate faster!</p>

<p>Some build systems like Bazel<sup><a data-type="noteref" id="idm140203534071776-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534071776">8</a></sup> have valuable features that afford
more precise control over testing. For example, Bazel creates
dependency graphs for software projects. When a change is made to a
file, Bazel only rebuilds the part of the software that depends on
that file. Such systems provide reproducible builds. Instead of
running all tests at every submit, tests only run for changed code. As
a result, tests execute cheaper and faster.</p>

<p>There are a variety of tools to help you quantify and
visualize
the level of test coverage you need <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/bibliography01.html#Cra10">[Cra10]</a>. Use these tools to shape the
focus of your testing: approach the prospect of creating highly tested
code as an engineering project rather than a philosophical mental
exercise. Instead of repeating the ambiguous refrain “We need more
tests,” set explicit goals and deadlines.</p>

<p>Remember that not all software is created equal. Life-critical or
revenue-critical systems demand substantially higher levels of test
quality and coverage than a non-production script with a short shelf
life.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Testing at Scale"><div class="sect1" id="idm140203534066912">
<h1>Testing at Scale</h1>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="testing at scale" id="RTscale17"></a>Now that we’ve covered the fundamentals of testing, let’s examine how
SRE takes a systems perspective to testing in order to drive
reliability at scale.</p>

<p>A small unit test might have a short list of dependencies: one source
file, the testing library, the runtime libraries, the compiler, and
the local hardware running the tests. A robust testing environment
dictates that those dependencies each have their own test coverage,
with tests that specifically address use cases that other parts of the
environment expect. If the implementation of that unit test depends on
a code path inside a runtime library that doesn’t have test coverage,
an unrelated change in the environment<sup><a data-type="noteref" id="idm140203534063296-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534063296">9</a></sup> can lead the unit test to consistently pass
testing, regardless of faults in the code under test.</p>

<p>In contrast, a release test might depend on so many parts that it has
a transitive dependency on every object in the code repository. If the
test depends on a clean copy of the production environment, in
principle, every small patch requires performing a full disaster
recovery iteration. Practical testing environments try to select
branch points among the versions and merges. Doing so resolves the
maximum amount of dependent uncertainty for the minimum number of
iterations. Of course, when an area of uncertainty resolves into a
fault, you need to select additional branch points.</p>








<section data-type="sect2" data-pdf-bookmark="Testing Scalable Tools"><div class="sect2" id="xref_testing_scalable-tools">
<h2>Testing Scalable Tools</h2>

<p><a data-type="indexterm" data-primary="SRE tools" data-secondary="testing" id="idm140203534059520"></a>As pieces of software, SRE tools also need testing.<sup><a data-type="noteref" id="idm140203534058384-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534058384">10</a></sup> SRE-developed
tools might perform tasks such as the following:</p>

<ul>
<li>
<p>Retrieving and propagating database performance metrics</p>
</li>
<li>
<p>Predicting usage metrics to plan for capacity risks</p>
</li>
<li>
<p>Refactoring data within a service replica that isn’t user
accessible</p>
</li>
<li>
<p>Changing files on a server</p>
</li>
</ul>

<p>SRE tools share two characteristics:</p>

<ul>
<li>
<p>Their side effects remain within the tested mainstream API</p>
</li>
<li>
<p>They’re isolated from user-facing production by an existing
validation and release barrier</p>
</li>
</ul>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm140203534050016">
<h5>Barrier Defenses Against Risky Software</h5>
<p><a data-type="indexterm" data-primary="SRE tools" data-secondary="barrier tools" id="idm140203534048864"></a><a data-type="indexterm" data-primary="barrier tools" id="idm140203534047920"></a>Software that bypasses the usual heavily tested API (even if it does
so for a good cause) could wreak havoc on a live service. For example, a database engine implementation might allow administrators to temporarily turn off transactions in order to shorten maintenance windows. If the implementation is used by batch update software, user-facing isolation may be lost if that utility is ever accidentally launched against a user-facing replica. Avoid this risk of havoc with design:</p>
<ol>
<li>
<p>Use a separate tool to place a barrier in the replication
configuration so that the replica cannot pass its health check. As a
result, the replica isn’t released to users.</p>
</li>
<li>
<p>Configure the risky software to check for the barrier upon
startup. Allow the risky software to only access unhealthy replicas.</p>
</li>
<li>
<p>Use the replica health validating tool you use for black-box
monitoring to remove the barrier.</p>
</li>

</ol>
</div></aside>

<p><a data-type="indexterm" data-primary="SRE tools" data-secondary="automation tools" id="idm140203534042688"></a><a data-type="indexterm" data-primary="automation tools" id="idm140203534041744"></a>Automation tools are also software. Because their risk footprint
appears out-of-band for a different layer of the service, their
testing needs are more subtle. Automation tools perform tasks like the
following:</p>

<ul>
<li>
<p>Database index selection</p>
</li>
<li>
<p>Load balancing between datacenters</p>
</li>
<li>
<p>Shuffling relay logs for fast remastering</p>
</li>
</ul>

<p>Automation tools share two characteristics:</p>

<ul>
<li>
<p>The actual operation performed is against a robust, predictable,
and well-tested API</p>
</li>
<li>
<p>The purpose of the operation is the side effect that is an
invisible discontinuity to another API client</p>
</li>
</ul>

<p>Testing can demonstrate the desired behavior of the other service
layer, both before and after the change. It’s often possible to test
whether internal state, as seen through the API, is constant across
the operation. For example, databases pursue correct answers, even if
a suitable index isn’t available for the query. On the other hand,
some documented API invariants (such as a DNS cache holding until the
TTL) may not hold across the operation. For example, if a runlevel
change replaces a local nameserver with a caching proxy, both choices
can promise to retain completed lookups for many seconds. It’s
unlikely that the cache state is handed over from one to the other.</p>

<p>Given that automation tools imply additional release tests for other
binaries to handle environmental transients, how do you define the
environment in which those automation tools run? After all, the
automation for shuffling containers to improve usage is likely to try
to shuffle itself at some point if it also runs in a container. It
would be embarrassing if a new release of its internal algorithm
yielded dirty memory pages so quickly that the network bandwidth of
the associated mirroring ended up preventing the code from finalizing
the live migration. Even if there’s an integration test for which the
binary intentionally shuffles itself around, the test likely doesn’t
use a production-sized model of the container fleet. It almost
certainly isn’t allowed to use scarce high-latency intercontinental
bandwidth for testing such races.</p>

<p class="pagebreak-before">Even more amusingly, one automation tool might be changing the
environment in which another automation tool runs. Or both tools might
be changing the environment of the other automation tool
simultaneously! For example, a fleet upgrading tool likely consumes
the most resources when it’s pushing upgrades. As a result, the
container rebalancing would be tempted to move the tool. In turn, the
container rebalancing tool occasionally needs upgrading. This circular
dependency is fine if the associated APIs have restart semantics,
someone remembered to implement test coverage for those semantics, and
checkpoint health is assured independently.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Testing Disaster"><div class="sect2" id="idm140203534030576">
<h2>Testing Disaster</h2>

<p><a data-type="indexterm" data-primary="SRE tools" data-secondary="disaster recovery tools" id="idm140203534029440"></a><a data-type="indexterm" data-primary="disaster recovery tools" id="idm140203534028496"></a>Many disaster recovery tools can be carefully designed to operate
<em>offline</em>. Such tools do the following:</p>

<ul>
<li>
<p><a data-type="indexterm" data-primary="checkpoint state" id="idm140203534026288"></a>Compute a <em>checkpoint</em> state that is equivalent to cleanly stopping
the service</p>
</li>
<li>
<p>Push the checkpoint state to be <em>loadable</em> by existing nondisaster
validation tools</p>
</li>
<li>
<p><a data-type="indexterm" data-primary="barrier tools" id="idm140203534022832"></a><a data-type="indexterm" data-primary="SRE tools" data-secondary="barrier tools" id="idm140203534022160"></a>Support the usual release <em>barrier</em> tools, which trigger the <em>clean
start</em> procedure</p>
</li>
</ul>

<p>In many cases, you can implement these phases so that the associated
tests are easy to write and offer excellent coverage. If any of the constraints (offline, checkpoint, loadable, barrier,
or clean start) must be broken, it’s much harder to show confidence
that the associated tool implementation will work at any time on short
notice.</p>

<p>Online repair tools inherently operate outside the mainstream API and
therefore become more interesting to test. One challenge you face in a
distributed system is determining if normal behavior, which may be
eventually consistent by nature, will interact badly with the
repair. For example, consider a race condition that you can attempt to
analyze using the offline tools. An offline tool is generally written
to expect instant consistency, as opposed to eventual consistency,
because instant consistency is less challenging to test. This
situation becomes complicated because the repair binary is generally
built separately from the serving production binary that it’s racing
against. Consequently, you might need to build a unified instrumented
binary to run within these tests so that the tools can observe
transactions.</p>
<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before"><div class="sidebar" id="idm140203534017616">
<h5>Using Statistical Tests</h5>
<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="statistical tests" id="idm140203534016208"></a><a data-type="indexterm" data-primary="statistical tests" id="idm140203534015264"></a><a data-type="indexterm" data-primary="Chaos Monkey" id="idm140203534014592"></a>Statistical techniques, such as Lemon <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/bibliography01.html#Ana07">[Ana07]</a>
for fuzzing, and Chaos Monkey<sup><a data-type="noteref" id="idm140203534012896-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534012896">11</a></sup> and Jepsen<sup><a data-type="noteref" id="idm140203534010992-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534010992">12</a></sup> for
distributed state, aren’t necessarily repeatable tests. Simply rerunning such tests
after a code change doesn’t definitively prove that the observed fault
is fixed.<sup><a data-type="noteref" id="idm140203534008960-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534008960">13</a></sup>
 However, these techniques can be useful:</p>

<ul>
<li>
<p>They can provide a log of all the randomly selected actions that
are taken in a given run—sometimes simply by logging the random
number generator seed.</p>
</li>
<li>
<p>If this log is immediately refactored as a release test, running it
a few times before starting on the bug report is often helpful. The
rate of nonfailure on replay tells you how hard it will be to
later assert that the fault is fixed.</p>
</li>
<li>
<p>Variations in how the fault is expressed help you pinpoint
suspicious areas in the code.</p>
</li>
<li>
<p>Some of those later runs may demonstrate failure situations that
are more severe than those in the original run. In response, you
may want to escalate the bug’s severity and impact.</p>
</li>
</ul>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Need for Speed"><div class="sect2" id="idm140203534002816">
<h2>The Need for Speed</h2>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="speed of" id="idm140203534001680"></a>For every version (patch) in the code repository, every defined test
provides a pass or fail indication. That indication may change for
repeated and seemingly identical runs. You can estimate the actual
likelihood of a test passing or failing by averaging over those many
runs and computing the statistical uncertainty of that
likelihood. However, performing this calculation for every test at
every version point is computationally infeasible.</p>

<p>Instead, you must form hypotheses about the many scenarios of interest
and run the appropriate number of repeats of each test and version to
allow a reasonable inference. Some of these scenarios are benign (in a
code quality sense), while others are actionable. These scenarios
affect all the test attempts to varying extents and, because they are
coupled, reliably and quickly obtaining a list of actionable
hypotheses (i.e., components that are actually broken) means
estimating all scenarios at the same time.</p>

<p>Engineers who use the testing infrastructure want to know if their
code—usually a tiny fraction of all the source behind a given test
run—is broken. Often, not being broken implies that any observed
failures can be blamed on someone else’s code. In other words, the
engineer wants to know if their code has an unanticipated race
condition that makes the test flaky (or more flaky than the test
already was due to other factors).</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm140203533998176">
<h5>Testing Deadlines</h5>
<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="coordination of" id="idm140203533997040"></a>Most tests are simple, in the sense that they run as a self-contained
hermetic binary that fits in a small compute container for a few
seconds. These tests give engineers interactive feedback about
mistakes before the engineer switches context to the next bug or task.</p>

<p>Tests that require orchestration across many binaries and/or across a
fleet that has many containers tend to have startup times measured in
seconds. Such tests are usually unable to offer interactive feedback,
so they can be classified as batch tests. Instead of saying “don’t
close the editor tab” to the engineer, these test failures are saying
“this code is not ready for review” to the code reviewer.</p>

<p>The informal deadline for the test is the point at which the engineer
makes the next context switch. Test results are best given to the
engineer before he or she switches context, because otherwise the next
context may involve XKCD compiling.<sup><a data-type="noteref" id="idm140203533994160-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533994160">14</a></sup></p>
</div></aside>

<p>Suppose an engineer is working on a service with over 21,000 simple
tests and occasionally proposes a patch against the service’s
codebase. To test the patch, you want to compare the vector of
pass/fail results from the codebase before the patch with the vector
of results from the codebase after the patch. A favorable comparison
of those two vectors provisionally qualifies the codebase as
releasable.  This qualification creates an incentive to run the many
release and integration tests, as well as other distributed binary
tests that examine scaling of the system (in case the patch uses
significantly more local compute resources) and complexity (in case
the patch creates a superlinear workload elsewhere).</p>

<p>At what rate can you incorrectly flag a user’s patch as damaging by
miscalculating environmental flakiness? It seems likely that users
would vehemently complain if 1 in 10 patches is rejected. But a
rejection of 1 patch among 100 perfect patches might go
without comment.</p>

<p class="pagebreak-before">This means you’re interested in the 42,000th root
(one for each defined test before the patch, and one for each defined
test after the patch) of 0.99 (the fraction of patches
that can be rejected). This <span class="keep-together">calculation:</span></p>
<div data-type="equation">
<img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_22.png" alt="0.99 Superscript StartFraction 1 Over 2 times 21000 EndFraction" width="227" height="71">
</div>

<p>suggests that those individual tests must run correctly
over 99.9999% of the time. Hmm.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Pushing to Production"><div class="sect2" id="idm140203533986672">
<h2>Pushing to Production</h2>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="segregated environments and" id="idm140203533985536"></a>While production configuration management is commonly kept in a source
control repository, configuration is often separate from the developer
source code. Similarly, the software testing infrastructure often
can’t see production configuration. Even if the two are located in the
same repository, changes for configuration management are made in
branches and/or a segregated directory tree that test automation has
historically ignored.</p>

<p>In a legacy corporate environment where software engineers develop
binaries and throw them over the wall to the administrators who update
the servers, segregation of testing infrastructure and production
configuration is at best annoying, and at worst can damage reliability
and agility. Such segregation might also lead to tool duplication. In
a nominally integrated Ops environment, this segregation degrades
resiliency because it creates subtle inconsistencies between the
behavior for the two sets of tools. This segregation also limits
project velocity because of commit races between the versioning
systems.</p>

<p>In the SRE model, the impact of segregating testing infrastructure
from production configuration is appreciably worse, as it prevents
relating the model describing production to the model describing the
application behavior. This discrepancy impacts engineers who want to
find statistical inconsistencies in expectations at development
time. However, this segregation doesn’t slow down development so much
as prevent the system architecture from changing, because there is no
way to eliminate migration risk.</p>

<p>Consider a scenario of unified versioning and unified testing, so that
the SRE methodology is applicable. What impact would the failure of a
distributed architecture migration have? A fair amount of testing will
probably occur. So far, it’s assumed that a software engineer would
likely accept the test system giving the wrong answer 1 time in 10
or so.  What risk are you willing to take with the migration if you
know that testing may return a false negative and the situation could
become really exciting, really quickly? Clearly, some areas of test
coverage need a higher level of paranoia than others. This distinction
can be generalized: some test failures are indicative of a larger
impact risk than other test failures.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Expect Testing Fail"><div class="sect2" id="idm140203533980528">
<h2>Expect Testing Fail</h2>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="expecting test failure" id="RTfail17"></a><a data-type="indexterm" data-primary="mean time" data-secondary="between failures (MTBF)" id="idm140203533978176"></a>Not too long ago, a software product might have released once per
year. Its binaries were generated by a compiler toolchain over many
hours or days, and most of the testing was performed by humans against
manually written instructions. This release process was inefficient,
but there was little need to automate it. The release effort was
dominated by documentation, data migration, user retraining, and other
factors. Mean Time Between Failure (MTBF) for those releases was one
year, no matter how much testing took place. So many changes happened
per release that some user-visible breakage was bound to be hiding in
the software. Effectively, the reliability data from the previous
release was irrelevant for the next release.</p>

<p>Effective API/ABI management tools and interpreted languages that
scale to large amounts of code now support building and executing a
new software version every few minutes. In principle, a sufficiently
large army of humans<sup><a data-type="noteref" id="idm140203533975696-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533975696">15</a></sup> could complete testing on each new version
using the methods described earlier and achieve the same quality bar for
each incremental version. Even though ultimately only the same tests
are applied to the same code, that final software version has higher
quality in the resulting release that ships annually. This is because
in addition to the annual versions, the intermediate versions of the
code are also being tested. Using intermediates, you can unambiguously
map problems found during testing back to their underlying causes and
be confident that the whole issue, and not just the limited symptom
that was exposed, is fixed. This principle of a shorter feedback cycle
is equally effective when applied to automated test coverage.</p>

<p>If you let users try more versions of the software during the year,
the MTBF suffers because there are more opportunities for user-visible
breakage. However, you can also discover areas that would benefit from
additional test coverage. If these tests are implemented, each
improvement protects against some future failure. Careful reliability
management combines the limits on uncertainty due to test coverage
with the limits on user-visible faults in order to adjust the release
cadence. This combination maximizes the knowledge that you gain from
operations and end users. These gains drive test coverage and, in
turn, product release velocity.</p>

<p>If an SRE modifies a configuration file or adjusts an automation
tool’s strategy (as opposed to implementing a user feature), the
engineering work matches the same conceptual model. When you are defining a
release cadence based on reliability, it often makes sense to segment
the reliability budget by functionality, or (more conveniently) by
team. In such a scenario, the feature engineering team aims to achieve
a given uncertainty limit that affects their goal release
cadence. The SRE team has a separate budget with its own associated
uncertainty, and thus an upper limit on their release rate.</p>

<p>In order to remain reliable and to avoid scaling the number of SREs
supporting a service linearly, the production environment has to run
mostly unattended. To remain unattended, the environment must be
resilient against minor faults. When a major event that demands manual
SRE intervention occurs, the tools used by SRE must be suitably
tested. Otherwise, that intervention decreases confidence that
historical data is applicable to the near future. The reduction in
confidence requires waiting for an analysis of monitoring data in
order to eliminate the uncertainty incurred. Whereas the previous
discussion in <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#xref_testing_scalable-tools">“Testing Scalable Tools”</a> focused on how to meet the
opportunity of test coverage for an SRE tool, here you see that
testing determines how often it is appropriate to use that tool
against production.</p>

<p>Configuration files generally exist because changing the configuration
is faster than rebuilding a tool. This low latency is often a factor
in keeping MTTR low. However, these same files are also changed
frequently for reasons that don’t need that reduced latency. When
viewed from the point of view of reliability:</p>

<ul>
<li>
<p>A configuration file that exists to keep MTTR low, and is only
modified when there’s a failure, has a release cadence slower than
the MTBF. There can be a fair amount of uncertainty as to whether a
given manual edit is actually truly optimal without the edit
impacting the overall site reliability.</p>
</li>
<li>
<p>A configuration file that changes more than once per user-facing
application release (for example, because it holds release state)
can be a major risk if these changes are not treated the same as
application releases. If testing and monitoring coverage of that
configuration file is not considerably better than that of the user
application, that file will dominate site reliability in a negative
way.</p>
</li>
</ul>

<p>One method of handling configuration files is to make sure that every
configuration file is categorized under only one of the options in the
preceding bulleted list, and to somehow enforce that rule. Should you take
the latter strategy, make sure of the <span class="keep-together">following</span>:</p>

<ul>
<li>
<p>Each configuration file has enough test coverage to support regular
routine <span class="keep-together">editing</span>.</p>
</li>
<li>
<p>Before releases, file edits are somewhat delayed while waiting for
release testing.</p>
</li>
<li>
<p>Provide a break-glass mechanism to push the file live before
completing the testing. Since breaking the glass impairs
reliability, it’s generally a good idea to make the break noisy by
(for example) filing a bug requesting a more robust resolution for
next time.<a data-type="indexterm" data-primary="" data-startref="RTfail17" id="idm140203533960640"></a></p>
</li>
</ul>
<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before"><div class="sidebar" id="idm140203533959216">
<h5>Break-Glass and Testing</h5>
<p><a data-type="indexterm" data-primary="break-glass mechanisms" id="idm140203533957808"></a><a data-type="indexterm" data-primary="reliability testing" data-secondary="break-glass mechanisms" id="idm140203533957136"></a>You can implement a break-glass mechanism to disable release
testing. Doing so means that whoever makes a hurried manual edit isn’t
told about any mistakes until the real user impact is reported by
monitoring. It’s better to leave the tests running, associate the
early push event with the pending testing event, and (as soon as
possible) back-annotate the push with any broken tests. This way, a
flawed manual push can be quickly followed by another (hopefully less
flawed) manual push. Ideally, that break-glass mechanism automatically
boosts the priority of those release tests so that they can preempt
the routine incremental validation and coverage workload that the test
infrastructure is already processing.</p>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Integration"><div class="sect2" id="idm140203533954848">
<h2>Integration</h2>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="integration tests" id="idm140203533953712"></a><a data-type="indexterm" data-primary="integration tests" id="idm140203533952768"></a><a data-type="indexterm" data-primary="configuration management" id="idm140203533952096"></a>In addition to unit testing a configuration file to mitigate its risk
to reliability, it’s also important to consider integration testing
configuration files. The contents of the configuration file are (for
testing purposes) potentially hostile content to the interpreter
reading the configuration. Interpreted languages such as Python are
commonly used for configuration files because their interpreters can
be embedded, and some simple sandboxing is available to protect
against nonmalicious coding errors.</p>

<p>Writing your configuration files
in an interpreted language is risky, as this approach is fraught with
latent failures that are hard to definitively address. Because loading
content actually consists of executing a program, there’s no inherent
upper limit on how inefficient loading can be. In addition to any
other testing, you should pair this type of integration testing with
careful deadline checking on all integration test methods in order to
label tests that do not run to completion in a reasonable amount of
time as failed.</p>

<p><a data-type="indexterm" data-primary="Python’s safe_load" id="idm140203533949504"></a>If the configuration is instead written as text in a custom syntax,
every category of test needs separate coverage from scratch. Using an
existing syntax such as YAML in combination with a heavily tested
parser like Python’s <code>safe_load</code> removes some of the toil incurred by
the configuration file. Careful choice of syntax and parser can ensure
there’s a hard upper limit on how long the loading operation can take.
However, the implementer needs to address schema faults, and most
simple strategies for doing so don’t have an upper bound on
runtime. Even worse, these strategies tend not to be robustly unit
tested.</p>

<p><a data-type="indexterm" data-primary="protocol buffers (protobufs)" id="idm140203533947360"></a>The benefit of using protocol buffers<sup><a data-type="noteref" id="idm140203533946496-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533946496">16</a></sup> is that the schema is defined in
advance and automatically checked at load time, removing even more of
the toil, yet still offering the bounded runtime.</p>

<p><a data-type="indexterm" data-primary="SRE tools" data-secondary="writing" id="idm140203533944192"></a>The role of SRE generally includes writing systems engineering
tools<sup><a data-type="noteref" id="idm140203533943040-marker" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533943040">17</a></sup> (if no
one else is already writing them) and adding robust validation with
test coverage. All tools can behave unexpectedly due to bugs not
caught by testing, so defense in depth is advisable. When one tool
behaves unexpectedly, engineers need to be as confident as possible
that most of their other tools are working correctly and can therefore
mitigate or resolve the side effects of that misbehavior. A key
element of delivering site reliability is finding each anticipated
form of misbehavior and making sure that some test (or another tool’s
tested input validator) reports that misbehavior. The tool that finds
the problem might not be able to fix or even stop it, but should at
least report the problem before a catastrophic outage occurs.</p>

<p>For example, consider the configured list of all users (such as <em>/etc/passwd</em> on a non-networked Unix-style machine) and imagine an edit that unintentionally causes the parser to stop after parsing only half of the file. Because recently created users haven’t loaded, the machine will most likely continue to run without problem, and many users may not notice the fault. The tool that maintains home directories can easily notice the mismatch between the actual directories present and those implied by the (partial) user list and urgently report the discrepancy. This tool’s value lies in reporting the problem, and it should avoid attempting to remediate on its own (by deleting lots of user data).</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Production Probes"><div class="sect2" id="idm140203533939488">
<h2>Production Probes</h2>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="production probes" id="idm140203533938352"></a><a data-type="indexterm" data-primary="production probes" id="idm140203533937408"></a>Given that testing specifies acceptable behavior in the face of known
data, while monitoring confirms acceptable behavior in the face of
unknown user data, it would seem that major sources of risk—both the
known and the unknown—are covered by the combination of testing and
monitoring. Unfortunately, actual risk is more <span class="keep-together">complicated</span>.</p>

<p>Known good requests should work, while known bad requests should
error. Implementing both kinds of coverage as an integration test is
generally a good idea. You can replay the same bank of test requests
as a release test. Splitting the known good requests into those that
can be replayed against production and those that can’t yields three
sets of requests:</p>

<ul>
<li>
<p>Known bad requests</p>
</li>
<li>
<p>Known good requests that can be replayed against production</p>
</li>
<li>
<p>Known good requests that can’t be replayed against production</p>
</li>
</ul>

<p>You can use each set as both integration and release tests. Most of
these tests can also be used as monitoring probes.</p>

<p>It would seem to be superfluous and, in principle, pointless to deploy
such monitoring because these exact same requests have already been
tried two other ways. However, those two ways were different for a few
reasons:</p>

<ul>
<li>
<p>The release test probably wrapped the integrated server with a
frontend and a fake backend.</p>
</li>
<li>
<p>The probe test probably wrapped the release binary with a load balancing <span class="keep-together">frontend</span> and a separate scalable persistent backend.</p>
</li>
<li>
<p>Frontends and backends probably have independent release
cycles. It’s likely that the schedules for those cycles occur at
different rates (due to their adaptive release cadences).</p>
</li>
</ul>

<p>Therefore, the monitoring probe running in production is a
configuration that wasn’t previously tested.</p>

<p>Those probes should never fail, but what does it mean if they do fail?
Either the <span class="keep-together">frontend</span> API (from the load balancer) or the backend API
(to the persistent store) is not equivalent between the production and
release environments. Unless you already know why the production and
release environments aren’t equivalent, the site is likely broken.</p>

<p>The same production updater that gradually replaces the application also
gradually replaces the probes so that all four combinations of
old-or-new probes sending requests to old-or-new applications are being
continuously generated. That updater can detect when one of the four
combinations is generating errors and roll back to the last known good
state. Usually, the updater expects each newly started application
instance to be unhealthy for a short time as it prepares to start
receiving lots of user traffic. If the probes are already inspected as
part of the readiness check, the update safely fails indefinitely, and
no user traffic is ever routed to the new version.  The update remains
paused until engineers have time and inclination to diagnose the fault
condition and then encourage the production updater to cleanly roll
back.</p>

<p>This production test by probe does indeed offer protection to the
site, plus clear feedback to the engineers. The earlier that feedback
is given to engineers, the more useful it is. It’s also preferable
that the test is automated so that the delivery of warnings to
engineers is scalable.</p>

<p>Assume that each component has the older
software version that’s being replaced and the newer version that’s
rolling out (now or very soon). The newer version might be talking to
the old version’s peer, which forces it to use the deprecated API. Or
the older version might be talking to a peer’s newer version, using
the API which (at the time the older version was released) didn’t work
properly yet. But it works now, honest! You’d better hope those tests
for future compatibility (which are running as monitoring probes) had good API coverage.<a data-type="indexterm" data-primary="" data-startref="RTscale17" id="idm140203533921136"></a></p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm140203533920032">
<h5>Fake Backend Versions</h5>
<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="fake backend versions" id="idm140203533918896"></a><a data-type="indexterm" data-primary="fake backends" id="idm140203533917952"></a><a data-type="indexterm" data-primary="backends, fake" id="idm140203533917280"></a>When implementing release tests, the fake backend is often maintained
by the peer service’s engineering team and merely referenced as a build
dependency. The hermetic test that is executed by the testing infrastructure always combines the fake backend and the test frontend at the same build point in the revision control history.</p>

<p>That build dependency may be providing a runnable hermetic
binary and, ideally, the engineering team maintaining it cuts a
release of that fake backend binary at the same time they cut their main
backend application and their probes. If that backend release is available, it might
be worthwhile to include hermetic frontend release tests (without the fake backend binary) in the frontend release package.</p>

<p>Your monitoring should be aware of all release versions on both sides of a given
service interface between two peers. This setup ensures that retrieving every combination of the two releases and determining whether the test still passes doesn’t take much extra
configuration. This monitoring doesn’t have to happen continuously—you only
need to run new combinations that are the result of either team
cutting a new release. Such problems don’t have to block that new release itself.</p>

<p>On the other hand, rollout automation should ideally block the associated production rollout until the problematic combinations are no longer possible. Similarly, the peer team’s automation may consider draining (and upgrading) the replicas that haven’t yet moved from a problematic combination.</p>
</div></aside>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="idm140203533912992">
<h1>Conclusion</h1>

<p><a data-type="indexterm" data-primary="reliability testing" data-secondary="benefits of" id="idm140203533911856"></a>Testing is one of the most profitable investments engineers can make
to improve the reliability of their product. Testing isn’t an activity
that happens once or twice in the lifecycle of a project; it’s
continuous. The amount of effort required to write good tests is
substantial, as is the effort to build and maintain infrastructure
that promotes a strong testing culture. You can’t fix a problem until
you understand it, and in engineering, you can only understand a
problem by measuring it. The methodologies and techniques in this
chapter provide a solid foundation for measuring faults and
uncertainty in a software system, and help engineers reason about the
reliability of software as it’s written and released to users.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140203532182080"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532182080-marker">1</a></sup> This chapter explains how to maximize the value derived from investing engineering effort into testing. Once an engineer defines suitable tests (for a given system) in a generalized way, the remaining work is common across all SRE teams and thus may be considered shared infrastructure. That infrastructure consists of a scheduler (to share budgeted resources across otherwise unrelated projects) and executors (that sandbox test binaries to prevent them from being considered trusted). These two infrastructure components can each be considered an ordinary SRE-supported service (much like cluster scale storage), and therefore won’t  be discussed further here.</p><p data-type="footnote" id="idm140203532177296"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532177296-marker">2</a></sup> For further reading on equivalence, see <a href="http://stackoverflow.com/questions/1909280/equivalence-class-testing-vs-boundary-value-testing"><em class="hyperlink">http://stackoverflow.com/questions/1909280/equivalence-class-testing-vs-boundary-value-testing</em></a>.</p><p data-type="footnote" id="idm140203532148304"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532148304-marker">3</a></sup> See <a href="https://google.github.io/dagger/"><em class="hyperlink">https://google.github.io/dagger/</em></a>.</p><p data-type="footnote" id="idm140203532094944"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532094944-marker">4</a></sup> A standard rule of thumb is to start by having the release impact 0.1% of user traffic, and then scaling by orders of magnitude every 24 hours while varying the geographic location of servers being upgraded (then on day 2: 1%, day 3: 10%, day 4: 100%).</p><p data-type="footnote" id="idm140203532088592"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532088592-marker">5</a></sup> For instance, assuming a 24 hour interval of continuous exponential growth between 1% and 10%, <img src="https://www.safaribooksonline.com/library/view/site-reliability-engineering/9781491929117/assets/eq_12.png" alt="upper K equals StartFraction 86400 Over l n Fraction 0.1 0.01 Fraction EndFraction equals 37523" width="148" height="30"> seconds, or about 10 hours and 25 minutes.</p><p data-type="footnote" id="idm140203532083024"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203532083024-marker">6</a></sup> We’re using order here in the sense of “big O notation” order of complexity. For more context, see <a href="https://en.wikipedia.org/wiki/Big_O_notation"><em class="hyperlink">https://en.wikipedia.org/wiki/Big_O_notation</em></a>.</p><p data-type="footnote" id="idm140203534081616"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534081616-marker">7</a></sup> For more on this topic, we highly recommend <a data-type="xref" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/bibliography01.html#Bla14">[Bla14]</a> by our former coworker and ex-Googler, Mike Bland.</p><p data-type="footnote" id="idm140203534071776"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534071776-marker">8</a></sup> See <a href="https://github.com/google/bazel"><em class="hyperlink">https://github.com/google/bazel</em></a>.</p><p data-type="footnote" id="idm140203534063296"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534063296-marker">9</a></sup> For example, code under test that wraps a nontrivial API to provide a simpler and backward-compatible abstraction. The API that used to be synchronous instead returns a future. Calling argument errors still deliver an exception, but not until the future is evaluated. The code under test passes the API result directly back to the caller. Many cases of argument misuse may not be caught.</p><p data-type="footnote" id="idm140203534058384"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534058384-marker">10</a></sup> This section talks specifically about tools used by SRE that need to be scalable. However, SRE also develops and uses tools that don’t necessarily need to be scalable. The tools that don’t need to be scalable also need to be tested, but these tools are out of scope for this section, and therefore won’t be discussed here. Because their risk footprint is similar to user-facing applications, similar testing strategies are applicable on such SRE-developed tools.</p><p data-type="footnote" id="idm140203534012896"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534012896-marker">11</a></sup> See <a href="https://github.com/Netflix/SimianArmy/wiki/Chaos-Monkey"><em class="hyperlink">https://github.com/Netflix/SimianArmy/wiki/Chaos-Monkey</em></a>.</p><p data-type="footnote" id="idm140203534010992"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534010992-marker">12</a></sup> See <a href="https://github.com/aphyr/jepsen"><em class="hyperlink">https://github.com/aphyr/jepsen</em></a>.</p><p data-type="footnote" id="idm140203534008960"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203534008960-marker">13</a></sup> Even if the test run is repeated with the same random seed so that the task kills are in the same order, there is no serialization between the kills and the fake user traffic. Therefore, there’s no guarantee that the actual previously observed code path will now be exercised again.</p><p data-type="footnote" id="idm140203533994160"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533994160-marker">14</a></sup> See <a href="http://xkcd.com/303/"><em class="hyperlink">http://xkcd.com/303/</em></a>.</p><p data-type="footnote" id="idm140203533975696"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533975696-marker">15</a></sup> Perhaps acquired through <em>Mechanical Turk</em> or similar services.</p><p data-type="footnote" id="idm140203533946496"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533946496-marker">16</a></sup> See <a href="https://github.com/google/protobuf"><em class="hyperlink">https://github.com/google/protobuf</em></a>.</p><p data-type="footnote" id="idm140203533943040"><sup><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#idm140203533943040-marker">17</a></sup> Not because software engineers shouldn’t write them. Tools that cross between technology verticals and span abstraction layers tend to have weak associations with many software teams and a slightly stronger association with systems teams.</p></div></div></section></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="/site/library/view/site-reliability-engineering/9781491929117/ch16.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">16. Tracking Outages</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="/site/library/view/site-reliability-engineering/9781491929117/ch18.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">18. Software Engineering in SRE</div>
        </a>
    
  
  </div>


      
    </section>
    <div class="reading-controls-bottom">
      <ul class="interface-controls js-bitlist">
        <li class="queue-control">
            <button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491929117/chapter/ch17.html">
      <span>Add to Queue</span>
  </button>
        </li>
      </ul>
    </div>
  </div>
  <div class="js-related-container related"></div>
<section class="sbo-saved-archives"></section>



          
          
  





    
    



        
      </div>
      



  <footer class="pagefoot t-pagefoot">
    <a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" class="icon-up"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li><a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a></li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li><a href="https://www.safaribooksonline.com/blog/">Blog</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://community.safaribooksonline.com/">Feedback</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2016 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>




    

    
    
    


  

<div class="font-flyout"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="https://www.safaribooksonline.com//library/view/site-reliability-engineering/9781491929117/ch17.html#">Reset</a>
</div>
</div></body></html>