<!--[if IE]><![endif]--><!DOCTYPE html><!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/high-performance-python/9781449361747/ch06.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="859452"
  data-user-uuid="4d373bec-fada-4717-9823-769db3ed3a36"
  data-username="dchen267"
  data-account-type="B2B"
  
  data-activated-trial-date="04/25/2016"


  data-archive="9781449361747"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch06.html"
  data-epub-title="High Performance Python" data-debug=0 data-testing=0><![endif]--><!--[if gt IE 8]><!--><html class=" js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom gr__safaribooksonline_com" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/high-performance-python/9781449361747/ch06.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="859452" data-user-uuid="4d373bec-fada-4717-9823-769db3ed3a36" data-username="dchen267" data-account-type="B2B" data-activated-trial-date="04/25/2016" data-archive="9781449361747" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch06.html" data-epub-title="High Performance Python" data-debug="0" data-testing="0"><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781449361747"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900,200italic,300italic,400italic,600italic,700italic,900italic" rel="stylesheet" type="text/css"><title>6. Matrix and Vector Computation - High Performance Python</title><link rel="stylesheet" href="https://www.safaribooksonline.com/static/CACHE/css/e4b0fef39b55.css" type="text/css"><link rel="stylesheet" type="text/css" href="https://www.safaribooksonline.com/static/css/annotator.min.fd58f69f4908.css"><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"><style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content font,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}@page{margin:5px !important}#sbo-rt-content p{margin:8px 0 0;line-height:125%;text-align:left}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link{text-decoration:none;color:#8e0012}#sbo-rt-content sup{font-size:x-small;vertical-align:super}#sbo-rt-content sub{font-size:smaller;vertical-align:sub}#sbo-rt-content span.lineannotation{font-style:italic;color:#A62A2A;font-family:serif,"DejaVuSerif"}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#FFF}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content h1,#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important}#sbo-rt-content h2{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content h3{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content h4{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content h5{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section.chapter div.titlepage,#sbo-rt-content section.appendix div.titlepage,#sbo-rt-content section.preface div.titlepage{page-break-inside:avoid;page-break-after:avoid}#sbo-rt-content section.chapter>div.titlepage,#sbo-rt-content section.preface>div.titlepage,#sbo-rt-content section.appendix>div.titlepage{margin-bottom:50px}#sbo-rt-content section.chapter>div.titlepage h2.title,#sbo-rt-content section.preface>div.titlepage h2.title,#sbo-rt-content section.appendix>div.titlepage h2.title{font-size:2em;line-height:1;margin-bottom:15px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content div.toc-title{margin-bottom:30px !important}#sbo-rt-content div.part h1{font-size:2em;text-align:center;margin-top:0 !important;padding:50px 0 20px 0;border-bottom:1px solid #000}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center;-webkit-border-radius:5px;border-radius:5px;border:1px solid #DCDCDC;padding:15px 5px 15px 5px !important;margin:30px 0 30px 0 !important;max-height:100%;page-break-inside:avoid}#sbo-rt-content div.figure-title,#sbo-rt-content div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif,"DejaVuSerif";color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:30px 0 20px 0 !important;-webkit-border-radius:5px;border-radius:5px;border:1px solid #DCDCDC;background-color:#F7F7F7;font-size:90%;padding:15px !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title{font-weight:bold;font-size:1em;font-family:sans-serif,"DejaVuSans";text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif,"DejaVuSerif";color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar ol{margin-left:15px}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div.caution,#sbo-rt-content div.sidebar div.important{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content div.sidebar div.figure{border:none}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div.example{margin:10px 0 15px 0 !important}#sbo-rt-content div.example-title{font-style:italic;font-weight:normal;font-family:serif,"DejaVuSerif";margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div.example-contents pre.programlisting,#sbo-rt-content div.example-contents pre.screen{margin:0}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div.book div.titlepage h1.title{font-size:3em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content div.book div.titlepage h2.subtitle{text-align:center;color:#000;margin:0 !important;font-style:italic;font-family:serif;font-size:1.5em}#sbo-rt-content div.book div.titlepage div.author h3{font-size:2em;font-family:sans-serif,"DejaVuSans";font-weight:bold;color:#8e0012;margin:50px 0 !important;text-align:center}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif,"DejaVuSerif";font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif,"DejaVuSerif";font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif,"DejaVuSerif";margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif,"DejaVuSerif";font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif,"DejaVuSerif";font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10pt}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-family:serif,"DejaVuSerif";font-style:italic}#sbo-rt-content blockquote div.attribution{margin:5px 0 0 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p{font-style:normal}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div.footnote{font-size:90%}#sbo-rt-content div.refnamediv h2,#sbo-rt-content div.refnamediv h3,#sbo-rt-content div.refsynopsisdiv h2{font-size:1.1em;color:#000;margin-top:15px !important;margin-bottom:0 !important}#sbo-rt-content div.refentry div.refsect1 h2{font-size:1.1em;color:#000;margin-top:15px !important;margin-bottom:0 !important}#sbo-rt-content div.refsect2 h3{font-size:1em;color:#000;margin-top:10px !important;margin-bottom:0 !important}#sbo-rt-content div.refnamediv p{margin-left:15px !important}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dt span.term{font-weight:bold;font-style:italic}#sbo-rt-content dt span.term code.literal{font-style:normal;font-weight:normal}#sbo-rt-content dd{margin-left:1.5em !important}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ol{list-style-type:decimal;margin-top:8px !important;margin-bottom:8px !important;margin-left:20px !important;padding-left:25px !important}#sbo-rt-content ol ol{list-style-type:lower-alpha}#sbo-rt-content ol ol ol{list-style-type:lower-roman}#sbo-rt-content ul{list-style-type:square;margin-top:8px !important;margin-bottom:8px !important;margin-left:5px !important;padding-left:20px !important}#sbo-rt-content ul ul{list-style-type:none;padding-left:0 !important;margin-left:0 !important}#sbo-rt-content ol li,#sbo-rt-content ul li,#sbo-rt-content dd{margin-bottom:1em}#sbo-rt-content ul ul li p:before{content:"— "}#sbo-rt-content ul ul ul li p:before{content:""}#sbo-rt-content ul ul ul{list-style-type:square;margin-left:20px !important;padding-left:30px !important}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist{margin-left:20px !important;margin-bottom:10px}#sbo-rt-content table.simplelist td{border:none;font-size:90%}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content div.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content div.calloutlist img{padding:0}#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.calloutlist>dl>dd>div.orderedlist{margin-top:25pt}#sbo-rt-content div.calloutlist>dl>dd>div.orderedlist>ol.orderedlist>li{margin-bottom:25pt}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div.note,#sbo-rt-content div.warning,#sbo-rt-content div.caution,#sbo-rt-content div.important{margin:30px !important;-webkit-border-radius:5px;border-radius:5px;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip,#sbo-rt-content div.note,#sbo-rt-content div.important{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div.caution{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div.note h3,#sbo-rt-content div.warning h3,#sbo-rt-content div.caution h3,#sbo-rt-content div.important h3{font:bold 90%;font-family:sans-serif,"DejaVuSans";text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div.note h3,#sbo-rt-content div.important h3{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div.caution h3{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;-webkit-border-radius:0;border-radius:0;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px auto 30px auto !important;max-width:95%;border-collapse:collapse;border-spacing:0}#sbo-rt-content div.table,#sbo-rt-content div.informaltable{page-break-inside:avoid}#sbo-rt-content tr{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif,"DejaVuSans";color:#000;font-weight:bold}#sbo-rt-content td{padding:.3em;text-align:left;vertical-align:baseline;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title{font-weight:normal;font-style:italic;font-family:serif,"DejaVuSerif";margin:20px 0 0 0 !important;text-align:center;padding:0}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title{font-style:italic;font-weight:normal;font-family:serif,"DejaVuSerif";margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{font-weight:bold}#sbo-rt-content div.index dt{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif,"DejaVuSerif";text-align:left}
    </style><link rel="canonical" href="/library/view/high-performance-python/9781449361747/ch06.html"><meta name="description" content="Chapter&nbsp;6.&nbsp;Matrix and Vector Computation Questions you’ll be able to answer after this chapter What are the bottlenecks in vector calculations? What tools can I use to see ... "><meta property="og:title" content="6. Matrix and Vector Computation"><meta itemprop="isPartOf" content="/library/view/high-performance-python/9781449361747/"><meta itemprop="name" content="6. Matrix and Vector Computation"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/ch06.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781449361747/"><meta property="og:description" itemprop="description" content="Chapter&nbsp;6.&nbsp;Matrix and Vector Computation Questions you’ll be able to answer after this chapter What are the bottlenecks in vector calculations? What tools can I use to see ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781449361594"><meta property="og:book:author" itemprop="author" content="Ian Ozsvald"><meta property="og:book:author" itemprop="author" content="Micha Gorelick"><meta property="og:book:tag" itemprop="about" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: <%= font_size %> !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: <%= font_family %> !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: <%= column_width %>% !important; margin: 0 auto !important; }"></style><!--[if lt IE 9]><script src="/static/js/src/respond.min.cf5c9b7980e5.js"></script><![endif]--><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style></head>


<body class="reading sidenav nav-collapsed  scalefonts library" data-gr-c-s-loaded="true">

    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        




<a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg width="20" height="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z" fill="currentColor"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z" fill="currentColor"></path></g></svg><span>Queue</span></a></li><li class="search"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z" fill="currentColor"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z" fill="currentColor"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z" fill="currentColor"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z" fill="currentColor"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" viewBox="0 0 50 50" version="1.1" fill="#4A3C31"><desc>offers icon</desc><path d="M10.8 43.7L0 39 0 10.2 13.6 4.6 23.3 8.7 11.5 13.5C11 13.6 10.8 13.9 10.8 14.3L10.8 43.7 10.8 43.7Z"></path><polygon points="12.3 44.4 25 50 38 44.3 38 14.7 25.2 9.4 12.3 14.7 12.3 44.4"></polygon><path d="M36.6 4.7L50 10.2 50 39 39.5 43.6 39.5 14.3C39.5 13.8 39.2 13.6 38.8 13.5L27 8.7 36.6 4.7 36.6 4.7Z"></path><polygon points="34.8 4 25 0 15.4 3.9 25.2 7.9 34.8 4"></polygon></svg><span>Offers</span></a><ul class="flyout"><li><a href="https://www.safaribooksonline.com/oreilly-conferences/" class="l2 nav-icn"><span>Conferences</span></a></li><li><a href="https://www.safaribooksonline.com/oreilly-newsletters/" class="l2 nav-icn"><span>Newsletter</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/003o000000t5q9fAAA/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z" fill="currentColor"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z" fill="currentColor"></path></g></svg><span>Settings</span></a></li><li><a href="https://community.safaribooksonline.com/" class="l1 no-icon">Feedback</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z" fill="currentColor"></path></g></svg><span>Settings</span></a></li><li><a href="https://community.safaribooksonline.com/" class="l2">Feedback</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      High Performance Python
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781449361747/chapter/ch06.html" data-for-analytics="9781449361747:ch06.html"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/ch06.html&amp;text=High%20Performance%20Python&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/ch06.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/ch06.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%206.%20Matrix%20and%20Vector%20Computation&amp;body=https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/ch06.html%0D%0Afrom%20High%20Performance%20Python%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
      
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="/library/view/high-performance-python/9781449361747/ch05.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">5. Iterators and Generators</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="/library/view/high-performance-python/9781449361747/ch07.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">7. Compiling to C</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section class="chapter" epub:type="chapter" id="matrix_computation"><div class="titlepage"><div><div><h2 class="title">Chapter&nbsp;6.&nbsp;Matrix and Vector Computation</h2></div></div></div><div class="sidebar"><div class="sidebar-title">Questions you’ll be able to answer after this chapter</div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">
What are the bottlenecks in vector calculations?
</li><li class="listitem">
What tools can I use to see how efficiently the CPU is doing my calculations?
</li><li class="listitem">
Why is <code class="literal">numpy</code> better at numerical calulations than pure python?
</li><li class="listitem">
What is a <code class="literal">cache-miss</code>?  What is a <code class="literal">page-fault</code>?
</li><li class="listitem">
How can I track the memory allocations in my code?
</li></ul></div></div><p>Regardless of what problem you are trying to solve on a computer, you will
encounter vector computation at some point.  Vector calculations are integral to
how a computer works and how it tries to speed up runtimes of programs down at
the silicon level—the only thing the computer knows how to do is operate on
number and knowing how to do multiple of those calculations at once will speed
up your program.</p><p>In this chapter, we try to unwrap some of the complexities of this problem by
focusing on a relatively simple mathematical problem, solving the diffusion
equation, and understanding what is happening at the CPU level.  By
understanding how different python code effects the CPU and how to effectively
probe these things, we can learn how to understand other problems as well.</p><p>We will start by introducing the problem and coming up with a quick solution
using pure python.  After identifying some memory issues and trying to fix them
using pure python we will introduce numpy and identify how and why it speeds up
our code.  Then we will start doing some algorithmic changes and specialize our
code to solve the problem at hand.  By removing some of the generality of the
libraries we are using we are able to yet again gain more speed.  Finally, we
introduce some extra modules that will help facilitate this sort of process out
in the field and also explore a cautionary tale about optimizing before
profiling.</p><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="matrix_intro">Introduction to the Problem</h2></div></div></div><div class="note"><h3 class="title">Note</h3><p>The following section is meant to give a deeper understanding of the equations
we will be solving throughout the chapter.  It is not strictly necessary to
understand this section in order to approach the rest of the chapter.  If you
wish to skip this section, make sure to look at the algorithm at
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_algo1">Example&nbsp;6-1</a> and <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_algo2">Example&nbsp;6-2</a> to understand the code we will be
optimizing.</p><p>On the other hand, if you read this section and want even more explanation, read
chapter 17 of “Numerical Recipes (3rd ed.)” by Press et al..</p></div><p>In order to explore matrix and vector computation in this chapter, we will
repeatedly use the example of diffusion in fluids.  Diffusion is one of the
mechanisms that moves fluids and tries to make it be uniformly mixed.</p><p>In this section we will explore the mathematics behind the diffusion equation.
This may seem complicated, but don’t worry!  We will quickly simplify this to
make it more understandable.  Also, it is important to note that while having a
basic understanding of the final equation we are solving will be useful while
reading this chapter, it is not completely necessary; the subsequent chapters
will focus mainly on various formulations of the code, not the equation.
However, having an understanding of the equations helps gain intuition about
ways of optimizing our code.  This is true in general—understanding the
motivation behind your code and the intricacies of the algorithm will help you
gain an intuition about methods of optimization.</p><p>One simple example of diffusion is dye in water: if you put several drops of dye
into water at room temperature it will slowly move out until it fully mixes
with the water.  Since we are not stirring the water, nor is it warm enough to
create convection currents, diffusion will be the main process mixing the two
liquids.  When solving these equations numerically, we pick what we want the
initial conditions to look like and are able to evolve the initial condition
forward in time to see what it will look like at a later time (see
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_diffusion_image">Figure&nbsp;6-2</a>).</p><p>All this being said, the most important thing to know about diffusion for our
purposes is its formulation.  Stated as a partial differential equation in 1
dimension it is written as,</p><div class="equation"><a id="id664466"></a><div class="equation-title">Equation&nbsp;6-1.&nbsp;Diffusion Equation</div><div class="equation-contents"><div class="mediaobject"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/eq_0601.png" alt="Diffusion Equation" width="624" height="130" data-mfp-src="/library/view/high-performance-python/9781449361747/eq_0601.png"></div></div></div><p>In this formulation, <code class="literal">u</code> is the vector representing the quantities we are
diffusing.  For example, we could have a vector with values of 0 where there is
only water and 1 where there is only dye (and values in-between where there is
mixing).  In general, this will be a 2D or 3D matrix representing an actual area
or volume of fluid.  In this way, we could have <code class="literal">u</code> be a 3D matrix representing
the fluid in a glass and instead of simply doing the second derivative along the
<code class="literal">x</code> direction, we’d have to take it over all axes.  In addition, <code class="literal">D</code> is a
physical value that represents properties of the fluid we are simulating.  A
large value of <code class="literal">D</code> represents a fluid that can diffuse very easily.  For
simplicity, we will set <code class="literal">D = 1</code> for our code, but still include it in the
calculations.</p><div class="note"><h3 class="title">Note</h3><p>The diffusion equation is also called the heat equation.  In this case, <code class="literal">u</code>
represents the temperature of a region and <code class="literal">D</code> describes how well the material
conducts heat. Solving the equations tell us how the heat is being transfered.
So, instead of solving for how a couple drops of dye diffuses through water, we
would be solving for how the heat from several drops of hot water diffuses
through cold water.</p></div><p>What we will do is take the diffusion equation above, which is continuous in
space and time, and approximate it to discrete volumes and discrete times.  This
is done using Euler’s method.  Euler’s method simply take’s the derivative and
writes it as a difference, such that</p><div class="informalequation"><div class="mediaobject"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/eq_0602.png" alt="Diffusion Equation" width="807" height="110" data-mfp-src="/library/view/high-performance-python/9781449361747/eq_0602.png"></div></div><p>where dt is now a fixed number.  This fixed number represents the time step size,
or the resolution in time that we wish to solve this equation.  It can be
thought of as the frame rate of the movie we are trying to make.  As the
frame rate goes up (or dt goes down), we get a clearer picture of what happens.
In fact, as dt approaches zero, Euler’s approximation becomes exact.  We can thus
rewrite the above equation to figure out what <code class="literal">u(x, t+dt)</code> is given <code class="literal">u(x,t)</code>.
What this means for us is that we can start with some initial state (<code class="literal">u(x,0)</code>
representing the glass of water just as we add a drop of dye into it) and churn
through the above mechanisms to “evolve” that initial state and see what it will
look like at future times (<code class="literal">u(x,dt)</code>).  This type of problem is called an
“initial value problem” or “Cauchey Problem”.</p><p>Doing a similar trick for the derivative in <code class="literal">x</code> using the finite differences
approximation, we arrive at the final equation,</p><div class="informalequation"><div class="mediaobject"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/eq_0603.png" alt="Diffusion Equation" width="1738" height="125" data-mfp-src="/library/view/high-performance-python/9781449361747/eq_0603.png"></div></div><p>Here, similar to how <code class="literal">dt</code> represents the frame rate, <code class="literal">dx</code> represents the
resolution of the images—the smaller <code class="literal">dx</code> is the smaller a region every cell
in our matrix represents.  For simplicity, we will simply set <code class="literal">D = 1</code> and <code class="literal">dx =
1</code>.  These two values become very important when doing proper physical
simulations, however since we are simply solving the diffusion equation for
illustrative purposes they are not important to us.</p><p>Using this equation, we can solve almost any diffusion problem.  However, there
are some considerations we must make from this equation.  Firstly, we said
before that the spacial index in <code class="literal">u</code> (ie: the <code class="literal">x</code> parameter) will be represented
as the indices into a matrix.  What happens when we try to find the value at
<code class="literal">x-dx</code> when <code class="literal">x</code> is at the beginning of the matrix?  This problem is called the
boundary condition.  You can have fixed boundary conditions that say: any value
out of the bounds of my matrix will be set to 0 (or any other value).
Alternatively, you can have periodic boundary conditions that say that the
values will wrap around (ie: if your matrix has length N, the value at index -1
is the same as at N-1, and the value at N+1 is the same at index 1.  In order
words, if you are trying to access the value at index <code class="literal">i</code>, you will get the
value at index <code class="literal">(i%N)</code>).</p><p>Another consideration is how we are going to store the multiple time components
of <code class="literal">u</code>.  We could have one matrix for every time value we do our calculation
for.  At minimum, it seems that we will need two matrices; one matrix for the
current state of the fluid and one for the next state of the fluid.  As we’ll
see, there are very drastic performance considerations for this particular
question.</p><p>So, what does it look like to solve this problem in practice?  Below is some
pseudo code to illustrate the way we can use this equation to solve the problem</p><div class="example"><a id="matrix_algo1"></a><div class="example-title">Example&nbsp;6-1.&nbsp;Psudocode for Matrix Initialization for 1D Diffusion</div><div class="example-contents"><pre class="programlisting"><code class="c"># Create the initial conditions</code>
<code class="n">u</code> <code class="o">=</code> <code class="n">vector</code> <code class="n">of</code> <code class="n">length</code> <code class="n">N</code>
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">N</code><code class="p">):</code>
    <code class="n">u</code> <code class="o">=</code> <code class="mi">0</code> <code class="k">if</code> <code class="n">there</code> <code class="ow">is</code> <code class="n">water</code><code class="p">,</code> <code class="mi">1</code> <code class="k">if</code> <code class="n">there</code> <code class="ow">is</code> <code class="n">dye</code>

<code class="c"># Evolve the initial conditions</code>
<code class="n">D</code> <code class="o">=</code> <code class="mi">1</code>
<code class="n">t</code> <code class="o">=</code> <code class="mi">0</code>
<code class="n">dt</code> <code class="o">=</code> <code class="mf">0.0001</code>
<code class="k">while</code> <code class="bp">True</code><code class="p">:</code>
    <code class="k">print</code> <code class="s">"Current time is: </code><code class="si">%f</code><code class="s">"</code> <code class="o">%</code> <code class="n">t</code>
    <code class="n">unew</code> <code class="o">=</code> <code class="n">vector</code> <code class="n">of</code> <code class="n">size</code> <code class="n">N</code>

    <code class="c"># update step for every cell</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">N</code><code class="p">):</code>
        <code class="n">unew</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">+</code> <code class="n">dt</code> <code class="o">*</code> <code class="p">(</code><code class="n">u</code><code class="p">[(</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">N</code><code class="p">]</code> <code class="o">+</code> <code class="n">u</code><code class="p">[(</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">N</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">])</code>
    <code class="c"># move the updated solution into u</code>
    <code class="n">u</code> <code class="o">=</code> <code class="n">unew</code>

    <code class="n">visualize</code><code class="p">(</code><code class="n">u</code><code class="p">)</code></pre></div></div><p>This code will take some initial condition of the dye in water and tell us what
the system looks like at every 0.0001 second interval in the future.  The
results of this can be seen in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_diffusion_1d_image">Figure&nbsp;6-1</a> where we evolve a
very concentrated drop of dye (represented by the top-hat function) into the
future.  We can see how far into the future, the dye becomes well mixed to the
point where everywhere has a similar concentration of the dye.</p><div class="figure"><a id="matrix_diffusion_1d_image"></a><div class="figure-contents"><div class="mediaobject"><img style="width: 378; " src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/figures/diffusion_1d.png" alt="Example of 1D diffusion" width="1000" height="727" data-mfp-src="/library/view/high-performance-python/9781449361747/figures/diffusion_1d.png"></div></div><div class="figure-title">Figure&nbsp;6-1.&nbsp;Example of 1D diffusion</div></div><p>For the purposes of this chapter, we will be solving the 2D version of the above
equation.  All this means is that instead of operating over a vector (or in
other words, a matrix with one index), we will be operating over a 2D matrix.
The only change to the equations (and thus the subsequent code), is that we must
now also take the second derivative in the <code class="literal">y</code> direction.  This simply means
that the original equation we are working with becomes,</p><div class="equation"><a id="id342116"></a><div class="equation-title">Equation&nbsp;6-2.&nbsp;Numerical diffusion equation in 2D</div><div class="equation-contents"><div class="mediaobject"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/eq_0604.png" alt="Numerical diffusion equation in 2D" width="1193" height="142" data-mfp-src="/library/view/high-performance-python/9781449361747/eq_0604.png"></div></div></div><p>Which translates to the following pseudo code using the same methods we used
before,</p><div class="example"><a id="matrix_algo2"></a><div class="example-title">Example&nbsp;6-2.&nbsp;Algorithm for Calculating 2D Diffusion</div><div class="example-contents"><pre class="programlisting"><code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">N</code><code class="p">):</code>
    <code class="k">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">M</code><code class="p">):</code>
        <code class="n">unew</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">dt</code> <code class="o">*</code> <code class="p">(</code>                       \
            <code class="p">(</code><code class="n">u</code><code class="p">[(</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">N</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">u</code><code class="p">[(</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">N</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">])</code> <code class="o">+</code> \ <code class="c"># d^2 u / dx^2</code>
            <code class="p">(</code><code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">M</code><code class="p">]</code> <code class="o">+</code> <code class="n">u</code><code class="p">[</code><code class="n">j</code><code class="p">][(</code><code class="n">j</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">M</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">])</code>   \ <code class="c"># d^2 u / dy^2</code>
        <code class="p">)</code></pre></div></div><p>We can put all of this together and write the full python 2D diffusion code
which we will use as the basis for our benchmarks for the rest of this chapter.
While the code looks more complicated, the results are similar to that of the 1D
diffusion (as can be seen in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_diffusion_image">Figure&nbsp;6-2</a>).</p><div class="figure"><a id="matrix_diffusion_image"></a><div class="figure-contents"><div class="mediaobject"><img style="width: 378; " src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/figures/diffusion.png.jpg" alt="Example of diffusion for two sets of initial conditions" width="714" height="1000" data-mfp-src="/library/view/high-performance-python/9781449361747/figures/diffusion.png.jpg"></div></div><div class="figure-title">Figure&nbsp;6-2.&nbsp;Example of diffusion for two sets of initial conditions</div></div><div class="note"><h3 class="title">Note</h3><p>Resources for this section:
- <a class="ulink" href="http://en.wikipedia.org/wiki/Diffusion_equation" target="_top">http://en.wikipedia.org/wiki/Diffusion_equation</a>
- <a class="ulink" href="http://pauli.uni-muenster.de/tp/fileadmin/lehre/NumMethoden/WS0910/ScriptPDE/Heat.pdf" target="_top">http://pauli.uni-muenster.de/tp/fileadmin/lehre/NumMethoden/WS0910/ScriptPDE/Heat.pdf</a></p></div></div><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="_aren_8217_t_python_lists_good_enough">Aren’t python lists good enough?</h2></div></div></div><p>Let’s take python code from <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_algo1">Example&nbsp;6-1</a> with the 2D extension  and break it
up into chunks so that we can better analyse its runtime performance.  The
first step is to write out the evolution function that takes in the matrix and
returns its evolved state,</p><div class="example"><a id="matrix_pure_python"></a><div class="example-title">Example&nbsp;6-3.&nbsp;Pure Python 2D Diffusion</div><div class="example-contents"><pre class="programlisting"><code class="n">grid_shape</code> <code class="o">=</code> <code class="p">(</code><code class="mi">1024</code><code class="p">,</code> <code class="mi">1024</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mf">1.0</code><code class="p">):</code>
    <code class="n">xmax</code><code class="p">,</code> <code class="n">ymax</code> <code class="o">=</code> <code class="n">grid_shape</code>
    <code class="n">new_grid</code> <code class="o">=</code> <code class="p">[[</code><code class="mf">0.0</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">ymax</code><code class="p">)]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">xmax</code><code class="p">)]</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">xmax</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">ymax</code><code class="p">):</code>
            <code class="n">grid_xx</code> <code class="o">=</code> <code class="n">grid</code><code class="p">[(</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">xmax</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">grid</code><code class="p">[(</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">xmax</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">-</code> <code class="mf">2.0</code> <code class="o">*</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code>
            <code class="n">grid_yy</code> <code class="o">=</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">ymax</code><code class="p">]</code> <code class="o">+</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">ymax</code><code class="p">]</code> <code class="o">-</code> <code class="mf">2.0</code> <code class="o">*</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code>
            <code class="n">new_grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">D</code> <code class="o">*</code> <code class="p">(</code><code class="n">grid_xx</code> <code class="o">+</code> <code class="n">grid_yy</code><code class="p">)</code> <code class="o">*</code> <code class="n">dt</code>
    <code class="k">return</code> <code class="n">grid</code></pre></div></div><div class="note"><h3 class="title">Note</h3><p>Instead of preallocating the <code class="literal">new_grid</code> list, we could have built it up in the
for loop by using appends.  While this is noticeably faster than what we have
written, the conclusions we draw are still applicable.  We chose this method
because it is more illustrative.</p></div><p>The global variable <code class="literal">grid_shape</code> designates how big of a region we be simulating
and, as explained in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_intro">Introduction to the Problem</a>, we are using periodic boundary conditions
(which is why we use modulo for the indices).  In order to actually use this
code, we must initialize a grid and call <code class="literal">evolve</code> on it.  The following code is
a very generic initialization procedure and will be reused throughout the
chapter (its performance characteristics will not be analysed since it must only
run once, as opposed to the <code class="literal">evolve</code> function, which is called repeatedly).</p><div class="example"><a id="matrix_pure_python_run"></a><div class="example-title">Example&nbsp;6-4.&nbsp;Pure Python 2D Diffusion Initialization</div><div class="example-contents"><pre class="programlisting"><code class="k">def</code> <code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="c"># setting up initial conditions </code><a id="CO6-1"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png">
    <code class="n">grid</code> <code class="o">=</code> <code class="p">[[</code><code class="mf">0.0</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">1</code><code class="p">])]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])]</code>

    <code class="n">block_low</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">4</code><code class="p">)</code>
    <code class="n">block_high</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">5</code><code class="p">)</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code> <code class="n">block_high</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code> <code class="n">block_high</code><code class="p">):</code>
            <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="mf">0.005</code>

    <code class="c"># Evolve the initial conditions</code>
    <code class="n">start</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">grid</code> <code class="o">=</code> <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="mf">0.1</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">start</code></pre><div class="calloutlist"><dl><dt><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO6-1"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png"></a> </dt><dd><p>
The initial conditions used here are the same as the square example in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_diffusion_image">Figure&nbsp;6-2</a>.
</p></dd></dl></div></div></div><p>The values for <code class="literal">dt</code> and grid elements have been chosen to be sufficiently small
so that the algorithm is stable.  See “Numerical Recipes” for a more in-depth
treatment of this algorithm’s convergence characteristics.</p><div class="example"><a id="matrix_pure_python_lineprof"></a><div class="example-title">Example&nbsp;6-5.&nbsp;Pure Python 2D Diffusion Profiling</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>kernprof.py -lv diffusion_python.py
Wrote profile results to diffusion_python.py.lprof
Timer unit: 1e-06 s

File: diffusion_python.py
Function: evolve at line 8
Total <code class="nb">time</code>: 16.1398 s

Line <code class="c">#      Hits         Time  Per Hit   % Time  Line Contents</code>
<code class="o">==============================================================</code>
     8                                           @profile
     9                                           def evolve<code class="o">(</code>grid, dt, <code class="nv">D</code><code class="o">=</code>1.0<code class="o">)</code>:
    10        10           39      3.9      0.0      xmax, <code class="nv">ymax</code> <code class="o">=</code> grid_shape
    11   2626570      2159628      0.8     13.4      <code class="nv">new_grid</code> <code class="o">=</code> <code class="o">[[</code>0.0 <code class="k">for </code>x in xrange<code class="o">(</code>ymax<code class="o">)]</code> <code class="k">for </code>x in xrange<code class="o">(</code>xmax<code class="o">)]</code>
    12      5130         4167      0.8      0.0      <code class="k">for </code>i in xrange<code class="o">(</code>xmax<code class="o">)</code>:
    13   2626560      2126592      0.8     13.2          <code class="k">for </code>j in xrange<code class="o">(</code>ymax<code class="o">)</code>:
    14   2621440      4259164      1.6     26.4              <code class="nv">grid_xx</code> <code class="o">=</code> grid<code class="o">[(</code>i+1<code class="o">)</code>%xmax<code class="o">][</code>j<code class="o">]</code> + grid<code class="o">[(</code>i-1<code class="o">)</code>%xmax<code class="o">][</code>j<code class="o">]</code> - 2.0 * grid<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code>
    15   2621440      4196964      1.6     26.0              <code class="nv">grid_yy</code> <code class="o">=</code> grid<code class="o">[</code>i<code class="o">][(</code>j+1<code class="o">)</code>%ymax<code class="o">]</code> + grid<code class="o">[</code>i<code class="o">][(</code>j-1<code class="o">)</code>%ymax<code class="o">]</code> - 2.0 * grid<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code>
    16   2621440      3393273      1.3     21.0              new_grid<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code> <code class="o">=</code> grid<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code> + D * <code class="o">(</code>grid_xx + grid_yy<code class="o">)</code> * dt
    17        10           10      1.0      0.0      <code class="k">return </code>grid</pre></div></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title" id="_problems_with_allocating_too_much">Problems with allocating too much</h3></div></div></div><p>By using <code class="literal">line_prof</code> on the pure python evolution function, we can start to
unravel what is contributing to a possibly slow runtime.  Looking at the
profiler output at <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_lineprof">Example&nbsp;6-5</a>, we see that most of the
time spent in the function is spent doing the derivative calculation and
updating the grid.  This is what we want since this is a purely CPU bound
problem—any time spent not solving the CPU bound problem is low hanging fruit
for optimization.</p><p>However, we are also spending 20% of our time allocating the <code class="literal">new_grid</code> list.
This is a waste because the properties of <code class="literal">new_grid</code> do not change—no matter
what values we send to <code class="literal">evolve</code>, the <code class="literal">new_grid</code> list will always be the same
shape and size and contain the same values.  A simple optimization would be to
allocate this list once and simply reuse this.  This sort of optimization is
similar to moving repetitive code outside of a fast loop,</p><pre class="programlisting"><code class="kn">from</code> <code class="nn">math</code> <code class="kn">import</code> <code class="n">sin</code>

<code class="k">def</code> <code class="nf">loop_slow</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    &gt;&gt;&gt; %timeit loop_slow(int(1e4))</code>
<code class="sd">    100 loops, best of 3: 2.67 ms per loop</code>
<code class="sd">    """</code>
    <code class="n">result</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">result</code> <code class="o">+=</code> <code class="n">i</code> <code class="o">*</code> <code class="n">sin</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code> <code class="c">#</code><a id="CO7-1"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png">
    <code class="k">return</code> <code class="n">result</code>

<code class="k">def</code> <code class="nf">loop_fast</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    &gt;&gt;&gt; %timeit loop_fast(int(1e4))</code>
<code class="sd">    1000 loops, best of 3: 1.38 ms per loop</code>
<code class="sd">    """</code>
    <code class="n">result</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="n">factor</code> <code class="o">=</code> <code class="n">sin</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">result</code> <code class="o">+=</code> <code class="n">i</code> <code class="o">*</code> <code class="n">factor</code>
    <code class="k">return</code> <code class="n">result</code></pre><div class="calloutlist"><dl><dt><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO7-1"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png"></a> </dt><dd><p>
The value of <code class="literal">sin(num_iterations)</code> doesn’t change throughout the loop so there is no use recalculating it every time.
</p></dd></dl></div><p>We can do a similar transformation to our diffusion code.  In this case, we
would want to instantiate <code class="literal">new_grid</code> in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_run">Example&nbsp;6-4</a> and send
it in to our evolve function.  The evolution function will do the same as it
does now, read the <code class="literal">grid</code> list and write to the <code class="literal">new_grid</code> list.  Then, we can
simply swap <code class="literal">new_grid</code> with <code class="literal">grid</code> and continue again.</p><div class="example"><a id="matrix_pure_python_memory"></a><div class="example-title">Example&nbsp;6-6.&nbsp;Pure Python 2D Diffusion after reducing memory allocations</div><div class="example-contents"><pre class="programlisting"><code class="k">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">out</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mf">1.0</code><code class="p">):</code>
    <code class="n">xmax</code><code class="p">,</code> <code class="n">ymax</code> <code class="o">=</code> <code class="n">grid_shape</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">xmax</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">ymax</code><code class="p">):</code>
            <code class="n">grid_xx</code> <code class="o">=</code> <code class="n">grid</code><code class="p">[(</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">xmax</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">grid</code><code class="p">[(</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">xmax</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">-</code> <code class="mf">2.0</code> <code class="o">*</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code>
            <code class="n">grid_yy</code> <code class="o">=</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">ymax</code><code class="p">]</code> <code class="o">+</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">ymax</code><code class="p">]</code> <code class="o">-</code> <code class="mf">2.0</code> <code class="o">*</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code>
            <code class="n">out</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">D</code> <code class="o">*</code> <code class="p">(</code><code class="n">grid_xx</code> <code class="o">+</code> <code class="n">grid_yy</code><code class="p">)</code> <code class="o">*</code> <code class="n">dt</code>

<code class="k">def</code> <code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="c"># setting up initial conditions</code>
    <code class="n">scratch</code> <code class="o">=</code> <code class="p">[[</code><code class="mf">0.0</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">1</code><code class="p">])]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])]</code>
    <code class="n">grid</code> <code class="o">=</code> <code class="p">[[</code><code class="mf">0.0</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">1</code><code class="p">])]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])]</code>

    <code class="n">block_low</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">4</code><code class="p">)</code>
    <code class="n">block_high</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">5</code><code class="p">)</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code> <code class="n">block_high</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">xrange</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code> <code class="n">block_high</code><code class="p">):</code>
            <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="mf">0.005</code>

    <code class="n">start</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="mf">0.1</code><code class="p">,</code> <code class="n">scratch</code><code class="p">)</code>
        <code class="n">grid</code><code class="p">,</code> <code class="n">scratch</code> <code class="o">=</code> <code class="n">scratch</code><code class="p">,</code> <code class="n">grid</code>
    <code class="k">return</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">start</code></pre></div></div><p>We can see from the line profile of the modified version of the code at
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_mem_lineprof">Example&nbsp;6-7</a> that this small change has given us a
21% speedup.  This conclusion is very much similar to the conclusion made during
the discussion on <code class="literal">append</code> operations on lists: memory allocations are not cheap.
Every time we request memory in order to store a variable or a list, python must
take its time to talk to the operating system in order to allocate the new
space, and then we must iterate over the newly allocated space to initialize it
to some value.  Whenever possible, reusing space that has already been allocated
will give performance speedups.  However, be careful when implementing these
changes.  While the speedups can be substantial, as always, profile to make sure
you are achieving the results you want and are not simply polluting your
code base.</p><div class="example"><a id="matrix_pure_python_mem_lineprof"></a><div class="example-title">Example&nbsp;6-7.&nbsp;Line Profiling Python Diffusion after reducing allocations</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>kernprof.py -lv diffusion_python_memory.py
Wrote profile results to diffusion_python_memory.py.lprof
Timer unit: 1e-06 s

File: diffusion_python_memory.py
Function: evolve at line 8
Total <code class="nb">time</code>: 13.3209 s

Line <code class="c">#      Hits         Time  Per Hit   % Time  Line Contents</code>
<code class="o">==============================================================</code>
     8                                           @profile
     9                                           def evolve<code class="o">(</code>grid, dt, out, <code class="nv">D</code><code class="o">=</code>1.0<code class="o">)</code>:
    10        10           15      1.5      0.0      xmax, <code class="nv">ymax</code> <code class="o">=</code> grid_shape
    11      5130         3853      0.8      0.0      <code class="k">for </code>i in xrange<code class="o">(</code>xmax<code class="o">)</code>:
    12   2626560      1942976      0.7     14.6          <code class="k">for </code>j in xrange<code class="o">(</code>ymax<code class="o">)</code>:
    13   2621440      4059998      1.5     30.5              <code class="nv">grid_xx</code> <code class="o">=</code> grid<code class="o">[(</code>i+1<code class="o">)</code>%xmax<code class="o">][</code>j<code class="o">]</code>
                                                                       + grid<code class="o">[(</code>i-1<code class="o">)</code>%xmax<code class="o">][</code>j<code class="o">]</code>
                                                                       - 2.0 * grid<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code>
    14   2621440      4038560      1.5     30.3              <code class="nv">grid_yy</code> <code class="o">=</code> grid<code class="o">[</code>i<code class="o">][(</code>j+1<code class="o">)</code>%ymax<code class="o">]</code>
                                                                       + grid<code class="o">[</code>i<code class="o">][(</code>j-1<code class="o">)</code>%ymax<code class="o">]</code>
                                                                       - 2.0 * grid<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code>
    15   2621440      3275454      1.2     24.6              out<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code> <code class="o">=</code> grid<code class="o">[</code>i<code class="o">][</code>j<code class="o">]</code> + D
                                                                         * <code class="o">(</code>grid_xx + grid_yy<code class="o">)</code>
                                                                         * dt</pre></div></div></div></div><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="matrix_memory_fragmentation">Memory Fragmentation</h2></div></div></div><p>The python code we wrote at <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_memory">Example&nbsp;6-6</a> still has a problem
that is at the heart of using python for these sorts of vectorized operations:
python doesn’t natively support vectorization.  This happens because of two
things: python lists store pointers to the actual data and python bytecode is
not optimized for vectorization so for loops cannot predict when using
vectorization would be beneficial.</p><p>The fact that python lists store pointers means that instead of actually holding
the data we care about, lists store a location where the data can actually be
found.  For most uses, this is good because it allows us to store whatever type
of data we like inside of a list.  However, when it comes to vector and matrix
operations this is a source for a lot of performance degradation.</p><p>The degradation occurs because every time we want to fetch an element from the
<code class="literal">grid</code> matrix, we must do multiple lookups.  For example, doing <code class="literal">grid[5][2]</code>
requires us to first do a list lookup for index 5 on the list <code class="literal">grid</code>.  This will
return a pointer to where the data at that location is stored.  Then, we do
another list lookup on this returned object for the element at index 2.  Once we
have this reference, we have the location where the actual data is stored.</p><p>The overhead for one such lookup is not big and can be, in most cases,
disregarded.  However, if the data we wanted was located in one contiguous block
in memory we could move ALL of the data in one operation instead of needing 2
operations for each element.  This is one of the major points with data
fragmentation: when your data is fragmented you must move each piece over
individually instead of moving the entire block over.  This means you are
invoking more memory transfer overhead and you are forcing the CPU to wait while
data is being transfered.  We will see with <code class="literal">perf</code> just how important this is
when looking at the <code class="literal">cache-misses</code>.</p><p>This problem of getting the right data to the CPU when it is needed is related
to the “Von Neumann bottleneck”.  This refers to the fact that there is a
limited bandwidth between the memory and the CPU as a result of the tiered
memory architecture which modern computers use.  If we could move data
infinitely fast, we would not need any cache since the CPU could retrieve any
data it needed instantly.  This would be a state where the bottleneck is
non-existent.</p><p>In order to deal with this, we pre-fetch data from the RAM and fill smaller but
faster CPU caches with the data so that hopefully, when the CPU needs a piece of
data, it will be located in a location that can be read from quickly.  While
this is a severely idealized way of looking at the architecture, we can still
see some of the problems with it—how do we know what data will be needed in
the future?  The CPU does a good job with a mechanisms called branch prediction
and pipelining which try to predict the next instruction and load the relevant
memory into cache while still working on the current instruction.  However, the
best way to minimize the effects of the bottleneck is to be smart about how we
allocate our memory and how we do our calculations over our data.</p><p>Probing how well memory is being moved to the CPU can be quite hard, however in
Linux the <code class="literal">perf</code> tool can be used to get amazing amounts of insight regarding
how the CPU is dealing with the program being run.  For example, we can run
<code class="literal">perf</code> on the pure python code from <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_memory">Example&nbsp;6-6</a> and see
just how efficiently the CPU is running our code,</p><div class="example"><a id="matrix_perf_python_memory"></a><div class="example-title">Example&nbsp;6-8.&nbsp;Performance Counters for pure python 2D Diffusion with reduced memory allocations</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,<code class="se">\</code>
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,minor-faults,<code class="se">\</code>
    cs,migrations -r 3 python diffusion_python_memory.py

 Performance counter stats <code class="k">for</code> <code class="s1">'python diffusion_python_memory.py'</code> <code class="o">(</code>3 runs<code class="o">)</code>:

   329,155,359,015 cycles                    <code class="c">#    3.477 GHz                      ( +-  0.47% )</code>
    76,800,457,550 stalled-cycles-frontend   <code class="c">#   23.33% frontend cycles idle     ( +-  1.75% )</code>
    46,556,100,820 stalled-cycles-backend    <code class="c">#   14.14% backend  cycles idle     ( +-  0.77% )</code>
   598,135,111,009 instructions              <code class="c">#    1.82  insns per cycle</code>
                                             <code class="c">#    0.13  stalled cycles per insn  ( +-  0.00% )</code>
        35,497,196 cache-references          <code class="c">#    0.375 M/sec                    ( +-  0.94% )</code>
        10,716,972 cache-misses              <code class="c">#   30.191 % of all cache refs      ( +- 15.51% )</code>
   133,881,241,254 branches                  <code class="c"># 1414.067 M/sec                    ( +-  0.00% )</code>
     2,891,093,384 branch-misses             <code class="c">#    2.16% of all branches          ( +-  0.12% )</code>
      94678.127621 task-clock                <code class="c">#    0.999 CPUs utilized            ( +-  0.48% )</code>
             5,439 page-faults               <code class="c">#    0.057 K/sec                    ( +-  0.01% )</code>
             5,439 minor-faults              <code class="c">#    0.057 K/sec                    ( +-  0.01% )</code>
               125 context-switches          <code class="c">#    0.001 K/sec                    ( +-  2.55% )</code>
                 6 CPU-migrations            <code class="c">#    0.000 K/sec                    ( +- 16.67% )</code>

      94.749389121 seconds <code class="nb">time </code>elapsed                                          <code class="o">(</code> +-  0.48% <code class="o">)</code></pre></div></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title" id="_understanding_literal_perf_literal">Understanding <code class="literal">perf</code></h3></div></div></div><p>Let’s take a second to understand the various performance metrics that <code class="literal">perf</code> is
giving us and their connection to our code.  The <code class="literal">task-clock</code> metric tells us
how many clock cycles our task took.  This is different than the total runtime
because if our program took 1 second to run but used 2 CPUs then the task-clock
would be <code class="literal">1000</code> (<code class="literal">task-clock</code> is generally in milliseconds).  Conveniently,
<code class="literal">perf</code> does the calculation for us and tells us, next to this metric, how many
CPU’s were utilized.  This number isn’t exactly 1 because there were periods
where the process relied on other subsystems to do instructions for it (for
example when memory is allocated).</p><p><code class="literal">context-switches</code> and <code class="literal">CPU-migrations</code> tells us about how the program was moved
around on the motherboard.  When a <code class="literal">context-switch</code> happens, the program’s
execution is halted and another program is allowed to run instead.  This is a
<span class="emphasis"><em>very</em></span> time intensive task and is something we would like to minimize as much as
possible.  However, we don’t have too much control of when this happens.  The
kernel delegates when programs are allowed to be switched out, however we can do
things to disincentives the kernel from moving <span class="emphasis"><em>our</em></span> program.  In general, the
kernel suspends a program when it is doing IO (such as reading from memory, disk
or the network).  As we’ll see in later chapters, we can use async routines to
make sure that our program still uses the CPU even when waiting for IO, which
will let us keep running without being context-switched.  In addition, we could
set the <code class="literal">nice</code> value of our program in order to give our program priority and
stop the kernel from context switching it.  Similarly, <code class="literal">CPU-migrations</code> happen
when the program is halted and resumed on a different CPU than it was on before
in order to have all CPUs have the same utilization.  This can be seen as an
especially bad context-switch since not only is our program being temporarily
halted, but we lose whatever data we had in the L1 cache (recall that each CPU
has its own L1 cache).</p><p>A <code class="literal">page-fault</code> is part of the modern Unix memory allocation scheme.  When memory
is allocated, the kernel doesn’t do much except give the program a reference to
memory.  However, later, when the memory is first used, the operating system
throws a <code class="literal">minor page-fault</code> interrupt which pauses the program that is being run
and properly allocated the memory.  This is called a lazy allocation system.
While this method is quite an optimization over previous memory allocation
systems, minor page faults are quite an expensive operation since most of the
operations are done outside the scope of the program you are running.  There is
also a <code class="literal">major page-fault</code> which happens when the program requests data from a
device (disk, network, etc) that hasn’t been read yet.  These are even more
expensive operations since not only do they interrupt your program but they also
involve reading from whichever device the data lives on.  This sort of page
fault does not generally effect CPU-bound work however it will be a source of
pain for any program which does disk or network read/writes.</p><p>Once we have data in memory and we reference it, the data makes its way through
the various tiers of memory (see <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch01.html#understanding_pp_communication">Communications Layers</a> for a
discussion of this).  Whenever we reference data which is in our cache, the
<code class="literal">cache-references</code> metric increases.  If we did not have this data already in
cache and need to fetch it from RAM, this counts as a <code class="literal">cache-miss</code>.  We won’t
get a cache miss if we are reading data we have recently read (so that the data
is still in the cache) or data that is located <span class="emphasis"><em>near</em></span> data we have recently read
in memory since chunks of data are sent from RAM into the cache.  Cache misses
can be a source for slowdowns when it comes to CPU bound work since not only do
we need to wait to fetch the data from RAM but we also interrupt the flow of our
execution pipeline (more on this in a second).  We will be discussing how to
reduce this by optimizing the layout of data in memory later in this chapter.</p><p><code class="literal">instructions</code> tells us how many instructions our code is issuing to the CPU.
Because of pipelining, these instructions can be run several at a time which is
what the <code class="literal">insns per cycle</code> annotation tells us.  To get a better handle on this
pipelining, <code class="literal">stalled-cycles-fontend</code> and <code class="literal">stalled-cycles-backend</code> tells us how
many cycles our program was waiting around for the frontend or backend of the
pipeline to be filled.  This can happen because of a cache-miss where, a
miss-predicted branch or resource conflict. The front end of the pipeline is
responsible for fetching the next instruction from memory and decoding it into a
valid operation while the back end is responsible for actually running the
operation.  With pipelining the CPU is able to run the current operation while
fetching and preparing the next one.</p><p>A <code class="literal">branch</code> is a time in the code where the execution flow changes.  Think of an
<code class="literal">if..then</code> statement—depending on the result of the conditional we will
either be executing one section of code or another.  This is essentially a
branch in the execution of the code—the next instruction in the program could
be one of two things.  In order to optimize this, especially with regards to the
pipeline, the CPU tries to guess which direction the branch will take and
pre-load the relevant instructions.  When this prediction is incorrect, we will
get some stalled-cycles and a <code class="literal">branch-miss</code>.  Branch misses can be quite
confusing and result in many strange effects (for example some loops will run
substantially faster on sorted lists than unsorted lists simply because there will
be less branch misses).</p><div class="note"><h3 class="title">Note</h3><p>If you would like a more thorough explanation of what is going on at the CPU
level with the various performance metrics, Gurpur M. Prabhu has a fantastic
tutorial called “Computer Architecture Tutorial” at
<a class="ulink" href="http://www.cs.iastate.edu/~prabhu/Tutorial/title.html" target="_top">http://www.cs.iastate.edu/~prabhu/Tutorial/title.html</a>. It deals with the
problems at a very low level which gives a good understanding of what is going
on under the hood when you run code.</p></div></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title" id="_making_decisions_with_literal_perf_literal_s_output">Making decisions with <code class="literal">perf</code>’s output</h3></div></div></div><p>With all this in mind, the performance metrics in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_perf_python_memory">Example&nbsp;6-8</a>
are telling us that while running our code, the CPU had to reference the L1/L2
cache 35,497,196 times.  Of those references, 10,716,972 (or 30.191%) were requests
for data that weren’t in memory at the time and had to be retrieved.  From this
data we can see other things as well.  For example, we can see that each CPU
cycle we are able to perform 1.82 instructions which tells us the total speed
boost from pipelining, out of order execution and hyperthreading (or any
other CPU feature that lets you run more than one instruction per clock cycle).</p><p>Fragmentation not only increases the number of memory transfers to the CPU, but
since you don’t have multiple pieces of data ready in the CPU cache when a
calculation is requested, you cannot vectorize the calculations.  As explained
in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch01.html#understanding_pp_communication">Communications Layers</a>, vectorization of computations (or having
the CPU do multiple computations at a time) can only occur if we can fill the
CPU cache with all the relevant data.  Since the bus can only move contiguous
chunks of memory, this would only be possible if the grid data is stored
sequential in RAM.  Since the list stores pointers to data instead of the actual
data, the actual values in the grid are scattered throughout memory and cannot
be copied at once.</p><p>This problem can be alleviated by using the <code class="literal">array</code> module instead of lists.
These objects store data sequentially in memory so that a slice of the array
actually represents a continuous range in memory.  However this doesn’t
completely fix the problem, now we have data that is stored sequentially in
memory but python still does not know how to vectorize our loops.  What we would
like is any loop that does arithmetic on our array one element at a time to work
on chunks of data, but as mentioned before there is no such bytecode
optimization in python (partly due to the extremely dynamic nature of the
language).</p><p>Furthermore, because of implementation details, using the <code class="literal">array</code> type when
creating lists of data that must be iterated on is actually <span class="emphasis"><em>slower</em></span> than simply
creating a <code class="literal">list</code>.  This is because the <code class="literal">array</code> object stores a very low level
representation of the numbers it stores and this must be converted into a
python-compatible version before being returned to the user.  This extra
overhead happens every time you index an <code class="literal">array</code> type.  That implementation
decision has made the <code class="literal">array</code> object less suitable for math and more suitable
for storing fixed-type data in a more efficiently in memory.</p><div class="note"><h3 class="title">Note</h3><p>Why doesn’t having the data we want sequentially in memory automatically give us
vectorization?  Well, if we were to look at the raw machine code that our CPU is
running, multiplying two arrays of numbers by each other in a vectorized way
versus a non-vectorized way use different parts of the CPU and thus different
instructions.  In order for python to properly utilize this, we must have a
module that was created to use those special instructions.</p></div><p>Luckily, the <code class="literal">numpy</code> package has all of the features we need—it stores data
in contiguous chunks of memory and supports vectorized operations on its data.
As a result, any arithmetic we do on numpy arrays happens in chunks without us
having to explicitly loop over each element.  Not only does this make it much
easier to do matrix arithmetic this way, but it is also faster.</p><pre class="programlisting"><code class="kn">from</code> <code class="nn">array</code> <code class="kn">import</code> <code class="n">array</code>
<code class="kn">import</code> <code class="nn">numpy</code>

<code class="k">def</code> <code class="nf">norm_square_list</code><code class="p">(</code><code class="n">vector</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    &gt;&gt;&gt; vector = range(1000000)</code>
<code class="sd">    &gt;&gt;&gt; %timeit norm_square_list(vector_list)</code>
<code class="sd">    1000 loops, best of 3: 1.16 ms per loop</code>
<code class="sd">    """</code>
    <code class="n">norm</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="k">for</code> <code class="n">v</code> <code class="ow">in</code> <code class="n">vector</code><code class="p">:</code>
        <code class="n">norm</code> <code class="o">+=</code> <code class="n">v</code><code class="o">*</code><code class="n">v</code>
    <code class="k">return</code> <code class="n">norm</code>

<code class="k">def</code> <code class="nf">norm_square_list_comprehension</code><code class="p">(</code><code class="n">vector</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    &gt;&gt;&gt; vector = range(1000000)</code>
<code class="sd">    &gt;&gt;&gt; %timeit norm_square_list(vector_list)</code>
<code class="sd">    1000 loops, best of 3: 913 µs per loop</code>
<code class="sd">    """</code>
    <code class="k">return</code> <code class="nb">sum</code><code class="p">([</code><code class="n">v</code><code class="o">*</code><code class="n">v</code> <code class="k">for</code> <code class="n">v</code> <code class="ow">in</code> <code class="n">vector</code><code class="p">])</code>

<code class="k">def</code> <code class="nf">norm_square_array</code><code class="p">(</code><code class="n">vector</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    &gt;&gt;&gt; vector = array('l', range(1000000))</code>
<code class="sd">    &gt;&gt;&gt; %timeit norm_square_array(vector_array)</code>
<code class="sd">    1000 loops, best of 3: 1.44 ms per loop</code>
<code class="sd">    """</code>
    <code class="n">norm</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="k">for</code> <code class="n">v</code> <code class="ow">in</code> <code class="n">vector</code><code class="p">:</code>
        <code class="n">norm</code> <code class="o">+=</code> <code class="n">v</code><code class="o">*</code><code class="n">v</code>
    <code class="k">return</code> <code class="n">norm</code>

<code class="k">def</code> <code class="nf">norm_square_numpy</code><code class="p">(</code><code class="n">vector</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    &gt;&gt;&gt; vector = numpy.arange(1000000)</code>
<code class="sd">    &gt;&gt;&gt; %timeit norm_square_numpy(vector_numpy)</code>
<code class="sd">    10000 loops, best of 3: 30.9 µs per loop</code>
<code class="sd">    """</code>
    <code class="k">return</code> <code class="n">numpy</code><code class="o">.</code><code class="n">sum</code><code class="p">(</code><code class="n">vector</code> <code class="o">*</code> <code class="n">vector</code><code class="p">)</code> <code class="c"># </code><a id="CO8-1"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png">

<code class="k">def</code> <code class="nf">norm_square_numpy_dot</code><code class="p">(</code><code class="n">vector</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    &gt;&gt;&gt; vector = numpy.arange(1000000)</code>
<code class="sd">    &gt;&gt;&gt; %timeit norm_square_numpy_dot(vector_numpy)</code>
<code class="sd">    10000 loops, best of 3: 21.8 µs per loop</code>
<code class="sd">    """</code>
    <code class="k">return</code> <code class="n">numpy</code><code class="o">.</code><code class="n">dot</code><code class="p">(</code><code class="n">vector</code><code class="p">,</code> <code class="n">vector</code><code class="p">)</code> <code class="c"># </code><a id="CO8-2"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/2.png" alt="2" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/2.png"></pre><div class="calloutlist"><dl><dt><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO8-1"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png"></a> </dt><dd><p>
This creates two implied loops over <code class="literal">vector</code>, one to do the multiplication and one to do the sum.  These loops are similar to the loops from <code class="literal">norm_square_list_comprehension</code>, however are executed using numpy’s optimized numerical code.
</p></dd><dt><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO8-2"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/2.png" alt="2" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/2.png"></a> </dt><dd><p>
This is the prefered way of doing vector norms in numpy.  The less efficient <code class="literal">norm_square_numpy</code> code is provided for illustration.
</p></dd></dl></div><p>The simpler numpy code runs 37.54x faster than <code class="literal">norm_square_list</code> and 29.5x
faster than the “optimized” python list comprehension.  The difference in speed
between the pure python looping method and the list comprehension method shows
the benefit of doing more calculation behind the scenes rather than explicitly
doing it in your python code.  By performing calculations using python’s already
built machinery we get the speed of the native C code that python is built on.
This is also partly the same reasoning behind why we have such a drastic speed
up in the numpy code: instead of using the very generalized list structure we
have a very finely tuned and specially built object for dealing with arrays of
numbers.</p><p>In addition to lighter and more specialized machinery, the numpy object also
gives us memory locality and vectorized operations, which are incredibly
important when dealing with numerical computations.  The CPU is exceedingly fast
and most of the time simply getting it the data it needs faster is the best way
to optimize code quickly.  Running each function using the <code class="literal">perf</code> tool above
shows that the <code class="literal">array</code> and pure python functions take ~100,000,000,000
instructions while the <code class="literal">numpy</code> version take ~3,000,000,000 instructions.  In
addition, the <code class="literal">array</code> and pure python have ~80% cache misses while <code class="literal">numpy</code> has
\~55%.</p><div class="figure"><a id="matrix_norm_squared_figure"></a><div class="figure-contents"><div class="mediaobject"><img style="width: 432; " src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/figures/norm_squared.png" alt="Runtimes for the various norm squared routines with vectors of different lenghts" width="800" height="600" data-mfp-src="/library/view/high-performance-python/9781449361747/figures/norm_squared.png"></div></div><div class="figure-title">Figure&nbsp;6-3.&nbsp;Runtimes for the various norm squared routines with vectors of different lenghts</div></div><p>In the above <code class="literal">norm_square_numpy</code> code, when doing <code class="literal">vector*vector</code>, there is an
<span class="emphasis"><em>implied</em></span> loop which numpy will take care of.  The implied loop is the same loop
we have explicitly written out in the other examples: loop over all items in
<code class="literal">vector</code> and multiply that item by itself.  However, since we tell numpy to do
this instead of explicitly writing it out in python code, it can take advantage
of all the optimizations it wants.  In the background, numpy has very optimized
C code that has been specifically made to take advantage of any vectorization
the CPU has enabled.  In addition, numpy arrays are represented sequentially in
memory as low level numerical types which gives them the same space requirements
as the <code class="literal">array</code> module.</p><p>As an extra bonus, we can reformulate the problem as a dot product, which numpy
supports.  This gives us a single operation to calculate the value we want, as
opposed to first taking the product of the two vectors and then summing them.
As you can see in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_norm_squared_figure">Figure&nbsp;6-3</a>, this operation,
<code class="literal">norm_numpy_dot</code> outperforms all the others by quite a substantial margin thanks
to the specialization of the function and since we don’t need to store the
intermediate value of <code class="literal">vector*vector</code> as we did in <code class="literal">norm_numpy</code>.</p></div></div><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="_enter_numpy">Enter numpy</h2></div></div></div><p>Using what we learned before about numpy, we can easily adapt the pure python
code to be vectorized.  The only new functionality we must introduce is numpy’s
<code class="literal">roll</code> function.  This function does the same thing as our modulo-index trick,
however it does so for an entire numpy array.  In essence, it vectorizes this
re-indexing.</p><pre class="programlisting"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">([</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">3</code><code class="p">,</code><code class="mi">4</code><code class="p">],</code> <code class="mi">1</code><code class="p">)</code>
<code class="go">array([4, 1, 2, 3])</code>

<code class="gp">&gt;&gt;&gt; </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">([[</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">3</code><code class="p">],[</code><code class="mi">4</code><code class="p">,</code><code class="mi">5</code><code class="p">,</code><code class="mi">6</code><code class="p">]],</code> <code class="mi">1</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="go">array([[3, 1, 2],</code>
<code class="go">       [6, 4, 5]])</code></pre><p>The <code class="literal">roll</code> function creates a new numpy array which can be thought of as both
good and bad.  The downside is that we are taking time to allocate new space
which then needs to be filled with the appropriate data.  On the other hand,
once we have created this new rolled array we are able to vectorize operations
on it quite quickly and not suffer from cache misses from the CPU cache.  This
can substantially effect speed of the actual calculation we must do on the grid.
Later in this chapter, we will rewrite this so that we get the same benefit
without having to constantly allocate more memory.</p><p>With this additional function we can re-write the python diffusion code from
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_memory">Example&nbsp;6-6</a> using much simplified, vectorized, numpy
arrays.  In addition, we break up the calculation of the derivatives, <code class="literal">grid_xx</code>
and <code class="literal">grid_yy</code> into a separate function.</p><div class="example"><a id="matrix_numpy_naive"></a><div class="example-title">Example&nbsp;6-9.&nbsp;Initial numpy diffusion</div><div class="example-contents"><pre class="programlisting"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>

<code class="n">grid_shape</code> <code class="o">=</code> <code class="p">(</code><code class="mi">1024</code><code class="p">,</code> <code class="mi">1024</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code> <code class="o">+</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code> <code class="o">+</code> \
           <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code> <code class="o">+</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code> <code class="o">-</code> <code class="mi">4</code> <code class="o">*</code> <code class="n">grid</code>

<code class="k">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">grid</code> <code class="o">+</code> <code class="n">dt</code> <code class="o">*</code> <code class="n">D</code> <code class="o">*</code> <code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="n">grid</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">)</code>

    <code class="n">block_low</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">4</code><code class="p">)</code>
    <code class="n">block_high</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">5</code><code class="p">)</code>
    <code class="n">grid</code><code class="p">[</code><code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">,</code> <code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">]</code> <code class="o">=</code> <code class="mf">0.005</code>

    <code class="n">start</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">grid</code> <code class="o">=</code> <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="mf">0.1</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">start</code></pre></div></div><p>Immediately we see that the above code is much shorter.  This is generally a
good indication of performance since we are doing a lot of the heavy lifting
outside of the python interpreter and hopefully inside of a module specially
built for performance solving a particular problem (however this should always
be tested).  One of the assumptions here is that numpy is using better memory
management in order to give the CPU the data it needs faster.  However, since
whether or not this happens relies on the actual implementation of numpy, let’s
profile the above code and see whether our hypothesis is correct.</p><div class="example"><a id="matrix_perf_numpy"></a><div class="example-title">Example&nbsp;6-10.&nbsp;Performance Counters for numpy 2D Diffusion</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,<code class="se">\</code>
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,minor-faults,<code class="se">\</code>
    cs,migrations -r 3 python diffusion_numpy.py

 Performance counter stats <code class="k">for</code> <code class="s1">'python diffusion_numpy.py'</code> <code class="o">(</code>3 runs<code class="o">)</code>:

    10,194,811,718 cycles                    <code class="c">#    3.332 GHz                      ( +-  0.35% )</code>
     4,435,850,419 stalled-cycles-frontend   <code class="c">#   43.51% frontend cycles idle     ( +-  0.86% )</code>
     2,055,861,567 stalled-cycles-backend    <code class="c">#   20.17% backend  cycles idle     ( +-  0.89% )</code>
    15,165,151,844 instructions              <code class="c">#    1.49  insns per cycle</code>
                                             <code class="c">#    0.29  stalled cycles per insn  ( +-  0.01% )</code>
       346,798,311 cache-references          <code class="c">#  113.362 M/sec                    ( +-  0.06% )</code>
           519,793 cache-misses              <code class="c">#    0.150 % of all cache refs      ( +- 10.23% )</code>
     3,506,887,927 branches                  <code class="c"># 1146.334 M/sec                    ( +-  0.01% )</code>
         3,681,441 branch-misses             <code class="c">#    0.10% of all branches          ( +-  0.47% )</code>
       3059.219862 task-clock                <code class="c">#    0.999 CPUs utilized            ( +-  3.13% )</code>
           751,707 page-faults               <code class="c">#    0.246 M/sec</code>
           751,707 minor-faults              <code class="c">#    0.246 M/sec</code>
                 8 context-switches          <code class="c">#    0.003 K/sec                    ( +-  7.22% )</code>
                 1 CPU-migrations            <code class="c">#    0.000 K/sec                    ( +- 57.74% )</code>

       3.061883218 seconds <code class="nb">time </code>elapsed                                          <code class="o">(</code> +-  3.13% <code class="o">)</code></pre></div></div><p>This shows that the simple change to numpy has given us a 40x speedup over
the pure python implementation with reduced memory allocations
(<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_perf_python_memory">Example&nbsp;6-8</a>).  How was this achieved?</p><p>First of all, we can thank the vectorization that numpy gives.  Although the
numpy version seems to be running less instructions per cycle, each of the
instructions is able to do much more work.  That is to say, one vectorized
instruction can multiply 4 (or more) numbers in an array together instead of
having to do 4 independent multiplication instructions.  Overall this results in
less total instructions necessary to solve the same problem.</p><p>There are also several other factors that contribute to the numpy version having
less absolute number of instructions needed to solve the diffusion problem.  One
of them has to do with the full python API being available when running the pure
python version, but not necessarily there for the numpy version (for example,
the pure python grids could be appended to, but not the numpy version).  Even
though we weren’t explicitly using this functionality, there is overhead in
providing a system where they <span class="emphasis"><em>could</em></span> be available.  Since numpy can make the
assumption that the data being stored is always going to be numbers, everything
regarding the arrays can be optimized for operations over numbers.  We will
continue on the track of removing necessary functionality in favor of
performance when we talk about cython in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch07.html#compiling-cython">Cython</a> where it is even
possible to remove list bounds checking to speed up list lookups.</p><p>Normally the number of instructions doesn’t necissarily correlate to performance
because the program with less instructions may not issue them efficiently or
they may be slow instructions.  However, we see that in addition to reducing the
number of instructions, the numpy version has also reduced a large inefficency,
cache misses (0.15% cache misses instead of 30.2%).  As explained in
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_memory_fragmentation">Memory Fragmentation</a>, cache misses slow down computations because the
CPU must wait for data to be retrieved from slower memory instead of having it
immediately available in its cache.  In fact, memory fragmentation is such a
dominant effect that if we disable vectorization
<sup>[<a id="matrix_numpy_novec" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#ftn.matrix_numpy_novec" epub:type="noteref" class="footnote">14</a>]</sup>
(<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_perf_numpy_novec">Example&nbsp;6-11</a>) in numpy but keep everything else we still see a
sizable speed increase compared to the pure python version.</p><div class="example"><a id="matrix_perf_numpy_novec"></a><div class="example-title">Example&nbsp;6-11.&nbsp;Performance Counters for numpy 2D Diffusion without Vectorization</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,<code class="se">\</code>
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,minor-faults,<code class="se">\</code>
    cs,migrations -r 3 python diffusion_numpy.py

 Performance counter stats <code class="k">for</code> <code class="s1">'python diffusion_numpy.py'</code> <code class="o">(</code>3 runs<code class="o">)</code>:

    48,923,515,604 cycles                    <code class="c">#    3.413 GHz                      ( +-  0.07% )</code>
    24,901,979,501 stalled-cycles-frontend   <code class="c">#   50.90% frontend cycles idle     ( +-  0.10% )</code>
     6,585,982,510 stalled-cycles-backend    <code class="c">#   13.46% backend  cycles idle     ( +-  0.08% )</code>
    53,208,756,117 instructions              <code class="c">#    1.09  insns per cycle</code>
                                             <code class="c">#    0.47  stalled cycles per insn  ( +-  0.00% )</code>
        83,436,665 cache-references          <code class="c">#    5.821 M/sec                    ( +-  0.26% )</code>
         1,211,229 cache-misses              <code class="c">#    1.452 % of all cache refs      ( +-  9.55% )</code>
     4,428,225,111 branches                  <code class="c">#  308.926 M/sec                    ( +-  0.01% )</code>
         3,716,789 branch-misses             <code class="c">#    0.08% of all branches          ( +-  0.21% )</code>
      14334.244888 task-clock                <code class="c">#    0.999 CPUs utilized            ( +-  0.99% )</code>
           751,185 page-faults               <code class="c">#    0.052 M/sec                    ( +-  0.00% )</code>
           751,185 minor-faults              <code class="c">#    0.052 M/sec                    ( +-  0.00% )</code>
                24 context-switches          <code class="c">#    0.002 K/sec                    ( +-  2.41% )</code>
                 5 CPU-migrations            <code class="c">#    0.000 K/sec                    ( +- 16.54% )</code>

      14.345794896 seconds <code class="nb">time </code>elapsed                                          <code class="o">(</code> +-  0.99% <code class="o">)</code></pre></div></div><p>This shows us that the dominant effect in our 40x speedup when introducing
numpy is not the vectorized instruction set but rather the memory locality and
memory fragmentation.  In fact, we can see from the above experiment that
vectorization gives us a \~6x speedup.<sup>[<a id="matrix_cpu_warning" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#ftn.matrix_cpu_warning" epub:type="noteref" class="footnote">15</a>]</sup></p><p>This realization that memory issues are the dominant effect in slowing down our
code doesn’t come as too much of a shock.  Computers are very well designed to
exactly the calculation we are requesting them to do with the problem—multiply and add numbers together.  The bottleneck is in getting those numbers
to the CPU fast enough to see it do the calculations as fast as it can.</p><div class="sect2"><div class="titlepage"><div><div><h3 class="title" id="_memory_allocations_and_in_place_operations">Memory Allocations and In-place Operations</h3></div></div></div><p>In order to optimize the memory dominated effects, let us try using the same
method we used in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_memory">Example&nbsp;6-6</a> in order to reduce the number of
allocations we make in our numpy code.  Allocations are quite a bit worse than
the cache misses we discussed previously.  Instead of simply having to find the
right data in RAM when it is not found in cache, an allocation also must make a
request to the operating system for an available chunk of data and then reserve
it.  The request to the operating system is quite a lot more overhead than
simply filling a cache—while filling a cache miss is a hardware routine that
is optimized on the motherboard, allocating memory  requires talking to another
process, the kernel, in order to complete.</p><p>In order to remove the allocations in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_naive">Example&nbsp;6-9</a> we will
pre-allocate some scratch space at the beginning of the code and then only use
in-place operations.  In-place operations, such as <code class="literal">+=</code>, <code class="literal">*=</code>, etc., reuse one
of the inputs as its output.  This means that we don’t need to allocate space
in order to store the result of the calculation.</p><p>To show this explicitly, we will look at how the <code class="literal">id</code> of a numpy array changes
as we perform operations on it.  The <code class="literal">id</code> is a good way of tracking this for
numpy arrays since the id has to do with what section of memory is being
reference.  If two numpy arrays have the same id then they are referencing the
same section of memory <sup>[<a id="id609491" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#ftn.id609491" epub:type="noteref" class="footnote">16</a>]</sup>.</p><div class="example"><a id="matrix_numpy_inplace_example1"></a><div class="example-title">Example&nbsp;6-12.&nbsp;In-place operations reducing memory allocations</div><div class="example-contents"><pre class="programlisting"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">array1</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">))</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">array2</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">))</code>
<code class="gp">&gt;&gt;&gt; </code><code class="nb">id</code><code class="p">(</code><code class="n">array1</code><code class="p">)</code>
<code class="go">140199765947424  # </code><a id="CO9-1"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png">
<code class="gp">&gt;&gt;&gt; </code><code class="n">array1</code> <code class="o">+=</code> <code class="n">array2</code>
<code class="gp">&gt;&gt;&gt; </code><code class="nb">id</code><code class="p">(</code><code class="n">array1</code><code class="p">)</code>
<code class="go">140199765947424  # </code><a id="CO9-2"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/2.png" alt="2" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/2.png">
<code class="gp">&gt;&gt;&gt; </code><code class="n">array1</code> <code class="o">=</code> <code class="n">array1</code> <code class="o">+</code> <code class="n">array2</code>
<code class="gp">&gt;&gt;&gt; </code><code class="nb">id</code><code class="p">(</code><code class="n">array1</code><code class="p">)</code>
<code class="go">140199765969792  # </code><a id="CO9-3"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/3.png" alt="3" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/3.png"></pre><div class="calloutlist"><dl><dt><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO9-1"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png"></a> <a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO9-2"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/2.png" alt="2" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/2.png"></a> </dt><dd><p>
These two ID’s are the same since we are doing an in-place operation.  This means that the memory address of <code class="literal">array1</code> does not change, we are simply changing the data contained within it.
</p></dd><dt><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO9-3"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/3.png" alt="3" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/3.png"></a> </dt><dd><p>
Here, the memory address has change.  When doing <code class="literal">array1 + array2</code>, a new memory address is allocated and filled with the result of the computation.  This does have benefits however, for when the original data needs to be preserved (ie: <code class="literal">array3 = array1 + array2</code> allows you to keep using <code class="literal">array1</code> and <code class="literal">array2</code>, while in-place operations destroy some of the original data).
</p></dd></dl></div></div></div><p>Furthermore, we see an expected slowdown from the non-in-place operation.  For
small numpy arrays, this overhead can be as large as 50% of the total
computation time.  For larger computations, the speedup is more in the single
percent region, this still represents a lot of time if this is happening
millions of times.</p><div class="example"><a id="matrix_numpy_inplace_benchmark"></a><div class="example-title">Example&nbsp;6-13.&nbsp;In-place operations reducing memory allocations</div><div class="example-contents"><pre class="programlisting"><code class="gp">&gt;&gt;&gt; </code><code class="o">%%</code><code class="n">timeit</code> <code class="n">array1</code><code class="p">,</code> <code class="n">array2</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">)),</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">))</code>
<code class="gp">... </code><code class="n">array1</code> <code class="o">=</code> <code class="n">array1</code> <code class="o">+</code> <code class="n">array2</code>
<code class="gp">...</code>
<code class="go">100000 loops, best of 3: 3.03 us per loop</code>

<code class="gp">&gt;&gt;&gt; </code><code class="o">%%</code><code class="n">timeit</code> <code class="n">array1</code><code class="p">,</code> <code class="n">array2</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">)),</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">))</code>
<code class="gp">... </code><code class="n">array1</code> <code class="o">+=</code> <code class="n">array2</code>
<code class="gp">...</code>
<code class="go">100000 loops, best of 3: 2.42 us per loop</code></pre></div></div><p>The downside is that rewriting our code from <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_naive">Example&nbsp;6-9</a> to use
in place operations is not very complicated, but it does make the resulting code
a bit harder to read.  In <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1">Example&nbsp;6-14</a> we can see the results of
this refactoring.  We instantiate <code class="literal">grid</code> and <code class="literal">scratch</code> vectors and we constantly
swap them with each other.  <code class="literal">grid</code> is the current information we know about the
system and, after running <code class="literal">evolve</code>, <code class="literal">scratch</code> contains the updated information.</p><div class="example"><a id="matrix_numpy_memory1"></a><div class="example-title">Example&nbsp;6-14.&nbsp;Making most numpy operations inplace</div><div class="example-contents"><pre class="programlisting"><code class="k">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="n">np</code><code class="o">.</code><code class="n">copyto</code><code class="p">(</code><code class="n">out</code><code class="p">,</code> <code class="n">grid</code><code class="p">)</code>
    <code class="n">out</code> <code class="o">*=</code> <code class="o">-</code><code class="mi">4</code>
    <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
    <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
    <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
    <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">out</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="n">out</code> <code class="o">*=</code> <code class="n">D</code> <code class="o">*</code> <code class="n">dt</code>
    <code class="n">out</code> <code class="o">+=</code> <code class="n">grid</code>

<code class="k">def</code> <code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="n">scratch</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">)</code>
    <code class="n">grid</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">)</code>

    <code class="n">block_low</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">4</code><code class="p">)</code>
    <code class="n">block_high</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="o">.</code><code class="mi">5</code><code class="p">)</code>
    <code class="n">grid</code><code class="p">[</code><code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">,</code> <code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">]</code> <code class="o">=</code> <code class="mf">0.005</code>

    <code class="n">start</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="mf">0.1</code><code class="p">,</code> <code class="n">scratch</code><code class="p">)</code>
        <code class="n">grid</code><code class="p">,</code> <code class="n">scratch</code> <code class="o">=</code> <code class="n">scratch</code><code class="p">,</code> <code class="n">grid</code>        <code class="c"># </code><a id="CO10-1"></a><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png">
    <code class="k">return</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">start</code></pre></div></div><div class="calloutlist"><dl><dt><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#CO10-1"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/callouts/1.png" alt="1" width="12" height="12" data-mfp-src="/library/view/high-performance-python/9781449361747/callouts/1.png"></a> </dt><dd><p>
Since the output of <code class="literal">evolve</code> gets stored in the output vector <code class="literal">scratch</code>, we must swap these two variables so that, for the next iteration of the loop, <code class="literal">grid</code> has the most updated information.  This swap operation is quite cheap because only the references to the data are changed, not the data itself.
</p></dd></dl></div><p>It is important to remember that since we want each operation to be in place,
whenever we do a vector operation we must have it be on its own line.  This can
make something as simple as <code class="literal">A = A*B + C</code> become quite convoluted.  Since
Python has a heavy emphasis on readability, we should make sure that the changes
we have made give us sufficient speedups to be justified.</p><div class="example"><a id="matrix_numpy_memory1_perf"></a><div class="example-title">Example&nbsp;6-15.&nbsp;Performance metrics for numpy with inplace memory operations</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,<code class="se">\</code>
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,minor-faults,<code class="se">\</code>
    cs,migrations -r 3 python diffusion_numpy_memory.py

 Performance counter stats <code class="k">for</code> <code class="s1">'python diffusion_numpy_memory.py'</code> <code class="o">(</code>3 runs<code class="o">)</code>:

     7,864,072,570 cycles                    <code class="c">#    3.330 GHz                      ( +-  0.02% )</code>
     3,055,151,931 stalled-cycles-frontend   <code class="c">#   38.85% frontend cycles idle     ( +-  0.05% )</code>
     1,368,235,506 stalled-cycles-backend    <code class="c">#   17.40% backend  cycles idle     ( +-  0.09% )</code>
    13,257,488,848 instructions              <code class="c">#    1.69  insns per cycle</code>
                                             <code class="c">#    0.23  stalled cycles per insn  ( +-  0.00% )</code>
       239,195,407 cache-references          <code class="c">#  101.291 M/sec                    ( +-  0.03% )</code>
         2,886,525 cache-misses              <code class="c">#    1.207 % of all cache refs      ( +-  0.56% )</code>
     3,166,506,861 branches                  <code class="c"># 1340.903 M/sec                    ( +-  0.00% )</code>
         3,204,960 branch-misses             <code class="c">#    0.10% of all branches          ( +-  0.28% )</code>
       2361.473922 task-clock                <code class="c">#    0.999 CPUs utilized            ( +-  4.69% )</code>
             6,527 page-faults               <code class="c">#    0.003 M/sec                    ( +-  0.01% )</code>
             6,527 minor-faults              <code class="c">#    0.003 M/sec                    ( +-  0.01% )</code>
                 6 context-switches          <code class="c">#    0.003 K/sec                    ( +- 10.53% )</code>
                 2 CPU-migrations            <code class="c">#    0.001 K/sec                    ( +- 79.54% )</code>

       2.363727876 seconds <code class="nb">time </code>elapsed                                          <code class="o">(</code> +-  4.68% <code class="o">)</code></pre></div></div><p>Comparing the performance metrics from <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1_perf">Example&nbsp;6-15</a> and
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_perf_numpy">Example&nbsp;6-10</a>, we see that removing the spurious allocations sped up our
code 29%.  This comes partly from a reduction in the number of cache misses,
but mostly from a reduction in page faults.</p></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title" id="matrix_selective_optimizations">Selective optimizations: finding what needs to be fixed</h3></div></div></div><p>Looking at the code from <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1">Example&nbsp;6-14</a>, it seems like we have
addressed most of the issues at hand: we have reduced CPU burden by using numpy
and we have reduced the number of allocations necessary to solve the problem.
However, there is always more investigation.  If we do a line profile on that
code (<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory_lineprof">Example&nbsp;6-16</a>), we see that the majority of our work is
done within the <code class="literal">laplace</code> function.  In fact, 93% of time <code class="literal">evolve</code> takes to run
is spent in <code class="literal">laplace</code>.</p><div class="example"><a id="matrix_numpy_memory_lineprof"></a><div class="example-title">Example&nbsp;6-16.&nbsp;Line profiling shows that <code class="literal">laplace</code> is taking too much time</div><div class="example-contents"><pre class="programlisting"><code class="n">Wrote</code> <code class="n">profile</code> <code class="n">results</code> <code class="n">to</code> <code class="n">diffusion_numpy_memory</code><code class="o">.</code><code class="n">py</code><code class="o">.</code><code class="n">lprof</code>
<code class="n">Timer</code> <code class="n">unit</code><code class="p">:</code> <code class="mf">1e-06</code> <code class="n">s</code>

<code class="n">File</code><code class="p">:</code> <code class="n">diffusion_numpy_memory</code><code class="o">.</code><code class="n">py</code>
<code class="n">Function</code><code class="p">:</code> <code class="n">laplacian</code> <code class="n">at</code> <code class="n">line</code> <code class="mi">8</code>
<code class="n">Total</code> <code class="n">time</code><code class="p">:</code> <code class="mf">3.67347</code> <code class="n">s</code>

<code class="n">Line</code> <code class="c">#      Hits         Time  Per Hit   % Time  Line Contents</code>
<code class="o">==============================================================</code>
     <code class="mi">8</code>                                           <code class="nd">@profile</code>
     <code class="mi">9</code>                                           <code class="k">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="mi">10</code>       <code class="mi">500</code>       <code class="mi">162009</code>    <code class="mf">324.0</code>      <code class="mf">4.4</code>      <code class="n">np</code><code class="o">.</code><code class="n">copyto</code><code class="p">(</code><code class="n">out</code><code class="p">,</code> <code class="n">grid</code><code class="p">)</code>
    <code class="mi">11</code>       <code class="mi">500</code>       <code class="mi">111044</code>    <code class="mf">222.1</code>      <code class="mf">3.0</code>      <code class="n">out</code> <code class="o">*=</code> <code class="o">-</code><code class="mi">4</code>
    <code class="mi">12</code>       <code class="mi">500</code>       <code class="mi">464810</code>    <code class="mf">929.6</code>     <code class="mf">12.7</code>      <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
    <code class="mi">13</code>       <code class="mi">500</code>       <code class="mi">432518</code>    <code class="mf">865.0</code>     <code class="mf">11.8</code>      <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
    <code class="mi">14</code>       <code class="mi">500</code>      <code class="mi">1261692</code>   <code class="mf">2523.4</code>     <code class="mf">34.3</code>      <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
    <code class="mi">15</code>       <code class="mi">500</code>      <code class="mi">1241398</code>   <code class="mf">2482.8</code>     <code class="mf">33.8</code>      <code class="n">out</code> <code class="o">+=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>

<code class="n">File</code><code class="p">:</code> <code class="n">diffusion_numpy_memory</code><code class="o">.</code><code class="n">py</code>
<code class="n">Function</code><code class="p">:</code> <code class="n">evolve</code> <code class="n">at</code> <code class="n">line</code> <code class="mi">17</code>
<code class="n">Total</code> <code class="n">time</code><code class="p">:</code> <code class="mf">3.97768</code> <code class="n">s</code>

<code class="n">Line</code> <code class="c">#      Hits         Time  Per Hit   % Time  Line Contents</code>
<code class="o">==============================================================</code>
    <code class="mi">17</code>                                           <code class="nd">@profile</code>
    <code class="mi">18</code>                                           <code class="k">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">out</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="mi">19</code>       <code class="mi">500</code>      <code class="mi">3691674</code>   <code class="mf">7383.3</code>     <code class="mf">92.8</code>      <code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="mi">20</code>       <code class="mi">500</code>       <code class="mi">111687</code>    <code class="mf">223.4</code>      <code class="mf">2.8</code>      <code class="n">out</code> <code class="o">*=</code> <code class="n">D</code> <code class="o">*</code> <code class="n">dt</code>
    <code class="mi">21</code>       <code class="mi">500</code>       <code class="mi">174320</code>    <code class="mf">348.6</code>      <code class="mf">4.4</code>      <code class="n">out</code> <code class="o">+=</code> <code class="n">grid</code></pre></div></div><p>There could be many reasons why <code class="literal">laplace</code> is so slow, however there are two main
high level issue to consider.  First, it looks like the calls <code class="literal">np.roll</code> are
allocating new vectors (this can be verified by looking at the documentation for
the function).  This means that even though we removed 7 memory allocations in
our previous refactoring, there are still 4 outstanding allocations.
Furthermore, <code class="literal">np.roll</code> is a very generalized function that has a lot of code to
deal with special cases.  Since we know exactly what we want to do (move just
the first column of data to be the last in every dimension), we can re-write
this function to eliminate most of the spurious code.  We could even merge the
<code class="literal">np.roll</code> logic with the add operation that happens with the rolled data to make
a very specialized <code class="literal">roll_add</code> function that does exactly what we want with the
least number of allocations and extra logic.</p><p><a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory2">Example&nbsp;6-17</a> shows what this refactoring would look like.  All we
need to do is create our new <code class="literal">roll_add</code> function and have <code class="literal">laplacian</code> use it.
Since numpy supports fancy indexing, implementing such a function is just a
matter of not jumbling up the indices.  However, as stated before, while this
code may be more performant it is much less readable.</p><div class="warning" epub:type="warning"><h3 class="title">Warning</h3><p>Notice the extra work that has gone into having an informative docstring for the
function in addition to full tests.  Whenever taking a route similar to this
one, it is important to maintain the readability of the code and these steps go
a long way to making sure your code is always doing what it was intended to do
and that future programmers can modify your code and know what things do and
when things are not working.</p></div><div class="example"><a id="matrix_numpy_memory2"></a><div class="example-title">Example&nbsp;6-17.&nbsp;Creating our own roll function</div><div class="example-contents"><pre class="programlisting"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>

<code class="k">def</code> <code class="nf">roll_add</code><code class="p">(</code><code class="n">rollee</code><code class="p">,</code> <code class="n">shift</code><code class="p">,</code> <code class="n">axis</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    Given a matrix, rollee, and an output matrix, out, this function will</code>
<code class="sd">    perform the calculation:</code>

<code class="sd">        &gt;&gt;&gt; out += np.roll(rollee, shift, axis=axis)</code>

<code class="sd">    This is done with the following assumptions:</code>
<code class="sd">        * rollee is 2D</code>
<code class="sd">        * shift will only ever be +1 or -1</code>
<code class="sd">        * axis will only ever be 0 or 1 (also implied by the first assumption)</code>

<code class="sd">    Using these assumptions, we are able to speed up this function by avoiding</code>
<code class="sd">    extra machinery that numpy uses to generalize the `roll` function and also</code>
<code class="sd">    by making this operation intrinsically in-place.</code>
<code class="sd">    """</code>
    <code class="k">if</code> <code class="n">shift</code> <code class="o">==</code> <code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[</code><code class="mi">1</code><code class="p">:,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="p">:]</code>
        <code class="n">out</code><code class="p">[</code><code class="mi">0</code> <code class="p">,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code>  <code class="p">:]</code>
    <code class="k">elif</code> <code class="n">shift</code> <code class="o">==</code> <code class="o">-</code><code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[</code><code class="mi">1</code><code class="p">:,</code> <code class="p">:]</code>
        <code class="n">out</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code> <code class="p">,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code>  <code class="p">:]</code>
    <code class="k">elif</code> <code class="n">shift</code> <code class="o">==</code> <code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">1</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code> <code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
        <code class="n">out</code><code class="p">[:,</code> <code class="mi">0</code> <code class="p">]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code>  <code class="o">-</code><code class="mi">1</code><code class="p">]</code>
    <code class="k">elif</code> <code class="n">shift</code> <code class="o">==</code> <code class="o">-</code><code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">1</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[:,</code> <code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">:]</code>
        <code class="n">out</code><code class="p">[:,</code>  <code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code>  <code class="mi">0</code><code class="p">]</code>

<code class="k">def</code> <code class="nf">test_roll_add</code><code class="p">():</code>
    <code class="n">rollee</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">asarray</code><code class="p">([[</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">],[</code><code class="mi">3</code><code class="p">,</code><code class="mi">4</code><code class="p">]])</code>
    <code class="k">for</code> <code class="n">shift</code> <code class="ow">in</code> <code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">axis</code> <code class="ow">in</code> <code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">):</code>
            <code class="n">out</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">asarray</code><code class="p">([[</code><code class="mi">6</code><code class="p">,</code><code class="mi">3</code><code class="p">],[</code><code class="mi">9</code><code class="p">,</code><code class="mi">2</code><code class="p">]])</code>
            <code class="n">expected_result</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">rollee</code><code class="p">,</code> <code class="n">shift</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="n">axis</code><code class="p">)</code> <code class="o">+</code> <code class="n">out</code>
            <code class="n">roll_add</code><code class="p">(</code><code class="n">rollee</code><code class="p">,</code> <code class="n">shift</code><code class="p">,</code> <code class="n">axis</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
            <code class="k">assert</code> <code class="n">np</code><code class="o">.</code><code class="n">all</code><code class="p">(</code><code class="n">expected_result</code> <code class="o">==</code> <code class="n">out</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="n">np</code><code class="o">.</code><code class="n">copyto</code><code class="p">(</code><code class="n">out</code><code class="p">,</code> <code class="n">grid</code><code class="p">)</code>
    <code class="n">out</code> <code class="o">*=</code> <code class="o">-</code><code class="mi">4</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code></pre></div></div><p>If we look at the performance counters in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory2_perf">Example&nbsp;6-18</a> for this
re-write, we see that it is considerably faster than <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1">Example&nbsp;6-14</a>
(70% faster) however most of the counters are about the same.  The number of
page faults went down, but not by 70%.  Similarly, cache-misses and
cache-references went down, but not enough to account for the entire speedup.
One of the most important metrics here is the <code class="literal">instructions</code> metric.</p><p>The <code class="literal">instructions</code> metric counts how many CPU instructions had to be issued to
run the program.  In other words, how many things the CPU had to do.  Somehow,
the change to the customized <code class="literal">roll_add</code> function reduced the total number of
instructions necessary by about 2.86x.  This is because instead of having to rely
on the entire machinery of numpy to roll our matrix, we are able to create
shorter and simpler machinery that can take advantages of assumptions on our
data (namely that our data is 2 dimensional and we will only ever be rolling by
1).  This theme of trimming out unnecessary machinery in both numpy and python
in general will continue in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch07.html#compiling-cython">Cython</a>.</p><div class="example"><a id="matrix_numpy_memory2_perf"></a><div class="example-title">Example&nbsp;6-18.&nbsp;Performance metrics for numpy with inplace memory operations and custom laplace function</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,<code class="se">\</code>
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,minor-faults,<code class="se">\</code>
    cs,migrations -r 3 python diffusion_numpy_memory2.py

 Performance counter stats <code class="k">for</code> <code class="s1">'python diffusion_numpy_memory2.py'</code> <code class="o">(</code>3 runs<code class="o">)</code>:

     4,303,799,244 cycles                    <code class="c">#    3.108 GHz                      ( +-  0.32% )</code>
     2,814,678,053 stalled-cycles-frontend   <code class="c">#   65.40% frontend cycles idle     ( +-  0.49% )</code>
     1,635,172,736 stalled-cycles-backend    <code class="c">#   37.99% backend  cycles idle     ( +-  0.63% )</code>
     4,631,882,411 instructions              <code class="c">#    1.08  insns per cycle</code>
                                             <code class="c">#    0.61  stalled cycles per insn  ( +-  0.00% )</code>
       272,151,957 cache-references          <code class="c">#  196.563 M/sec                    ( +-  0.57% )</code>
         2,835,948 cache-misses              <code class="c">#    1.042 % of all cache refs      ( +-  2.45% )</code>
       621,565,054 branches                  <code class="c">#  448.928 M/sec                    ( +-  0.01% )</code>
         2,905,879 branch-misses             <code class="c">#    0.47% of all branches          ( +-  0.63% )</code>
       1384.555494 task-clock                <code class="c">#    0.999 CPUs utilized            ( +-  7.82% )</code>
             5,559 page-faults               <code class="c">#    0.004 M/sec                    ( +-  0.01% )</code>
             5,559 minor-faults              <code class="c">#    0.004 M/sec                    ( +-  0.01% )</code>
                 6 context-switches          <code class="c">#    0.004 K/sec                    ( +- 19.25% )</code>
                 3 CPU-migrations            <code class="c">#    0.002 K/sec                    ( +- 85.44% )</code>

       1.386148918 seconds <code class="nb">time </code>elapsed                                          <code class="o">(</code> +-  7.83% <code class="o">)</code></pre></div></div></div></div><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="_numexpr_making_inplace_operations_faster_and_easier">numexpr: making inplace operations faster and easier</h2></div></div></div><p>One downfall of numpy’s optimization of vector operations is that it only occurs
on one operation at a time.  That is to say, when doing the operation <code class="literal">A*B + C</code>
with numpy vectors, first the entire <code class="literal">A*B</code> operation completes, the data is
stored in a temporary vector, then this new vector is added with <code class="literal">C</code>.  The
in-place version of the diffusion code in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1">Example&nbsp;6-14</a> shows this
quite explicitly.</p><p>However, there are many modules that can help with this.  <code class="literal">numexpr</code> is a module
that can take an entire vector expression and compile it into very efficient
code that is optimized to minimize cache misses and temporary space used.  In
addition the expressions can utilize multiple CPU cores (see <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch09.html">Chapter&nbsp;9</a>
for more information) and specialized instructions for Intel chips to maximize
the speedup.</p><p>It is very easy to change code to use <code class="literal">numexpr</code>: all it takes are expressions
written as strings with references to local variables.  The expression is
compiled behind the scenes (and cached so that calls to the same expression
don’t incur the same cost of compilation) and run using optimized code.
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_numexpr">Example&nbsp;6-19</a> shows the simplicity of changing the <code class="literal">evolve</code> function
to use <code class="literal">numexpr</code>.  In that case, we chose to use the <code class="literal">out</code> parameter of the
<code class="literal">evaluate</code> function so that <code class="literal">numexpr</code> doesn’t allocate a new vector to return
the result of the calculation to.</p><div class="example"><a id="matrix_numpy_numexpr"></a><div class="example-title">Example&nbsp;6-19.&nbsp;Using numexpr to further optimize large matrix operations</div><div class="example-contents"><pre class="programlisting"><code class="kn">from</code> <code class="nn">numexpr</code> <code class="kn">import</code> <code class="n">evaluate</code>

<code class="k">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">scratch</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">scratch</code><code class="p">)</code>
    <code class="n">evaluate</code><code class="p">(</code><code class="s">"scratch*D*dt+grid"</code><code class="p">,</code> <code class="n">out</code><code class="o">=</code><code class="n">scratch</code><code class="p">)</code></pre></div></div><p>An important feature of <code class="literal">numexpr</code> is its consideration of CPU caches.  It
specifically moves data around so that the various CPU caches have the correct
data in order to minimize cache misses.  When we run <code class="literal">perf</code> on the updated code
(<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_numexpr_perf">Example&nbsp;6-20</a>), we see a speedup.  However, if we look at the
performance on a smaller, 512x512, grid (<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_figure_all_perf">Figure&nbsp;6-4</a>) we see a
~15% decrease in speed.  Why is this?</p><div class="example"><a id="matrix_numpy_numexpr_perf"></a><div class="example-title">Example&nbsp;6-20.&nbsp;Performance metrics for numpy with inplace memory operations, custom laplace function and numexpr</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,<code class="se">\</code>
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,minor-faults,<code class="se">\</code>
    cs,migrations -r 3 python diffusion_numpy_memory2_numexpr.py

 Performance counter stats <code class="k">for</code> <code class="s1">'python diffusion_numpy_memory2_numexpr.py'</code> <code class="o">(</code>3 runs<code class="o">)</code>:

     5,940,414,581 cycles                    <code class="c">#    1.447 GHz                      ( +-  0.48% )</code>
     3,706,635,857 stalled-cycles-frontend   <code class="c">#   62.40% frontend cycles idle     ( +-  0.73% )</code>
     2,321,606,960 stalled-cycles-backend    <code class="c">#   39.08% backend  cycles idle     ( +-  0.93% )</code>
     6,909,546,082 instructions              <code class="c">#    1.16  insns per cycle</code>
                                             <code class="c">#    0.54  stalled cycles per insn  ( +-  0.01% )</code>
       261,136,786 cache-references          <code class="c">#   63.628 M/sec                    ( +-  0.64% )</code>
        11,623,783 cache-misses              <code class="c">#    4.451 % of all cache refs      ( +-  8.54% )</code>
       627,319,686 branches                  <code class="c">#  152.851 M/sec                    ( +-  0.03% )</code>
         8,443,876 branch-misses             <code class="c">#    1.35% of all branches          ( +-  3.24% )</code>
       4104.127507 task-clock                <code class="c">#    1.364 CPUs utilized            ( +-  4.04% )</code>
             9,786 page-faults               <code class="c">#    0.002 M/sec                    ( +-  0.01% )</code>
             9,786 minor-faults              <code class="c">#    0.002 M/sec                    ( +-  0.01% )</code>
             8,701 context-switches          <code class="c">#    0.002 M/sec                    ( +-  1.11% )</code>
                60 CPU-migrations            <code class="c">#    0.015 K/sec                    ( +- 15.26% )</code>

       3.009811418 seconds <code class="nb">time </code>elapsed                                          <code class="o">(</code> +-  3.86% <code class="o">)</code></pre></div></div><p>Much of the extra machinery we are bringing into our program with ‘numexpr`
deals with cache considerations.  When our grid size is small and all the data
we need for our calculation fits in cache, this extra machinery simply adds
extra instructions that don’t help performance.  In addition, compiling the
vector operation that we encoded as a string adds a large overhead.  When the
total runtime of the program is small, this overhead can be quite noticeable.
However, as we increase the grid size, we should expect to see <code class="literal">numexpr</code> better
utilize our cache than native numpy.  In addition, <code class="literal">numexpr</code> utilizes multiple
cores to do its calculation and tried so saturate each of the cores’ cache.
When the size of the grid is small, the extra overhead of managing the multiple
cores overwhelms any possible increase in speed.</p><p>The particular computer we are running the code on has a 20480 KB cache (Intel®
Xeon® E5-2680).  Since we are operating on two arrays, one for input and one for
output, we can easily do the calculation for the size of the grid that will fill
up our cache.  The number of grid elements we can store in total is <code class="literal">20480KB /
64bit = 2,560,000</code>.  Since we have two grids, this number is split between two
objects (so each one can be at most <code class="literal">2,560,000 / 2 = 1,280,000</code> elements.
Finally, taking the square root of this number gives us the size of the grid
that uses that many grid elements.  All in all, this means that approximately
two 2D arrays of size 1131x1131 would fill up the cache
(<span class="inlinemediaobject"><img src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/inleq_0605.png" alt="" width="300" height="26" data-mfp-src="/library/view/high-performance-python/9781449361747/inleq_0605.png"></span>).  In practice however, we do
not get to fill up the cache ourselves (other programs will fill up parts of the
cache), so realistically we can probably fit two 800x800 vectors.  Looking at
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_table_all_perf">Table&nbsp;6-1</a> we see that when the grid size jumps from 512x512 to
1024x1024, the <code class="literal">numexpr</code> code starts to outperform pure numpy.</p></div><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="_a_cautionary_tale_verify_optimizations_scipy">A Cautionary Tale: Verify “optimizations” (scipy)</h2></div></div></div><p>An important thing to take away from this chapter is the approach we took to
every optimization: profile to the code to get a sense of what is going on, come
up with a possible solution to fix slow parts, profile to make sure the fix
actually worked.  Although this sounds straight forward, things can get
complicated quickly as we saw with how the performance of <code class="literal">numexpr</code> depended
greatly on the size of the grid we are considering.</p><p>However, this doesn’t always work as expected.  While writing the code for this
chapter, this author saw that the <code class="literal">laplacian</code> function was the slowest routine
and hypothesised that the <code class="literal">scipy</code> routine would be considerably faster.  This
thinking came from the fact that laplacians are a common operation in image
analysis and probably have a very optimized library to speed up the calls.
Scipy has an image submodule, so we must be in luck!</p><div class="example"><a id="matrix_numpy_scipy"></a><div class="example-title">Example&nbsp;6-21.&nbsp;Using scipy’s laplace filter</div><div class="example-contents"><pre class="programlisting"><code class="kn">from</code> <code class="nn">scipy.ndimage.filters</code> <code class="kn">import</code> <code class="n">laplace</code>

<code class="k">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="n">laplace</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">,</code> <code class="n">mode</code><code class="o">=</code><code class="s">'wrap'</code><code class="p">)</code></pre></div></div><p>The implementation was quite simple (<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_scipy">Example&nbsp;6-21</a>) and required little
thought about the intricacies of implementing the periodic boundary conditions
(or “wrap” condition as scipy calls it).  Ease of implementation is quite
important and definitely won this method some points before considering
performance.  However once we benchmark the scipy code we get the revelation:
this method has no substantial speedup compared to the code it was based off of
(<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1">Example&nbsp;6-14</a>).  In fact, as we increase the grid size, this method
starts performing worse (<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_figure_all_perf">Figure&nbsp;6-4</a>).</p><div class="example"><a id="matrix_numpy_scipy_perf"></a><div class="example-title">Example&nbsp;6-22.&nbsp;Performance Metrics for diffusion with scipy’s laplace function</div><div class="example-contents"><pre class="programlisting"><code class="nv">$ </code>perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,<code class="se">\</code>
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,minor-faults,<code class="se">\</code>
    cs,migrations -r 3 python diffusion_scipy.py

 Performance counter stats <code class="k">for</code> <code class="s1">'python diffusion_scipy.py'</code> <code class="o">(</code>3 runs<code class="o">)</code>:

     6,573,168,470 cycles                    <code class="c">#    2.929 GHz                      ( +-  0.11% )</code>
     3,574,258,872 stalled-cycles-frontend   <code class="c">#   54.38% frontend cycles idle     ( +-  0.21% )</code>
     2,357,614,687 stalled-cycles-backend    <code class="c">#   35.87% backend  cycles idle     ( +-  0.26% )</code>
     9,850,025,585 instructions              <code class="c">#    1.50  insns per cycle</code>
                                             <code class="c">#    0.36  stalled cycles per insn  ( +-  0.01% )</code>
       415,930,123 cache-references          <code class="c">#  185.361 M/sec                    ( +-  0.24% )</code>
         3,188,390 cache-misses              <code class="c">#    0.767 % of all cache refs      ( +-  1.75% )</code>
     1,608,887,891 branches                  <code class="c">#  717.006 M/sec                    ( +-  0.01% )</code>
         4,017,205 branch-misses             <code class="c">#    0.25% of all branches          ( +-  0.40% )</code>
       2243.897843 task-clock                <code class="c">#    0.994 CPUs utilized            ( +-  9.26% )</code>
             7,319 page-faults               <code class="c">#    0.003 M/sec</code>
             7,319 minor-faults              <code class="c">#    0.003 M/sec                    ( +-  0.00% )</code>
                12 context-switches          <code class="c">#    0.005 K/sec                    ( +- 52.20% )</code>
                 1 CPU-migrations            <code class="c">#    0.000 K/sec                    ( +- 57.74% )</code>

       2.258396667 seconds <code class="nb">time </code>elapsed                                          <code class="o">(</code> +-  9.67% <code class="o">)</code></pre></div></div><p>Comparing the performance metrics of the scipy version of the code with that of
our custom laplacian function (<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory2_perf">Example&nbsp;6-18</a>), we can start to
get some indication as to why we aren’t getting the speedup we were expecting
from this re-write.</p><p>The metrics that stand out the most are <code class="literal">page-faults</code> and <code class="literal">instructions</code>.  All
of these values are substantially large for the scipy version.  The increase
<code class="literal">page-faults</code> shows us that while the scipy laplacian function has support for
in place operations, it is still allocating a lot of memory.  In fact, the number
of page faults in the scipy version is larger than our first rewrite of the
numpy code (<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1_perf">Example&nbsp;6-15</a>).</p><p>Most importantly however is the <code class="literal">instructions</code> metric.  This shows us that the
scipy code is requesting the CPU does over double the amount of work than our
custom laplacian code.  Even though these instructions are more optimized (as we
can see with the higher <code class="literal">insns per cycle</code> which says how many instructions the
CPU can do in one clock cycle) the extra optimization doesn’t win out over the
sheer number of added instructions.  This could be in part due to the fact that
the scipy code is written very generally so that it can process all sorts of
inputs with different boundary conditions which requires extra code and thus
more instructions.  We can see this in fact by the high number of <code class="literal">branches</code>
that the scipy code requires.</p></div><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="_wrap_up_4">Wrap Up</h2></div></div></div><p>Looking back on our optimizations there seems to be two main routes we took:
reducing the time to get data to the CPU and reducing the amount of work that
the CPU had to do.  <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_figure_all_perf">Figure&nbsp;6-4</a> shows how all of these methods
compared to each other and we can see the three bands of performance that
correspond to these two methods:  the lower band coming from our pure python
implementation, the middle band coming from our reduction of allocations and the
third band coming from reducing the work done by our process.</p><div class="figure"><a id="matrix_figure_all_perf"></a><div class="figure-contents"><div class="mediaobject"><img style="width: 432; " src="https://www.safaribooksonline.com/library/view/high-performance-python/9781449361747/figures/matrix_method_speed.png" alt="Summary of speedups from the methods attempted in this chapter" width="1000" height="727" data-mfp-src="/library/view/high-performance-python/9781449361747/figures/matrix_method_speed.png"></div></div><div class="figure-title">Figure&nbsp;6-4.&nbsp;Summary of speedups from the methods attempted in this chapter</div></div><p>Some things to take away from this is that you should always take care of any
administrative things the code must do during initialization.  This would
involve allocating memory, or reading configuration from a file, or even
pre computing some values that will be needed throughout the lifetime of the
program.  This is important for two reasons—first you are reducing the total
number of times this must happen by doing it once beforehand and knowing that
you can use those resources without too much penalty in the future.  Secondly,
you are not disrupting the flow of the program and allowing it to pipeline more
efficiently and keep the caches filled with more pertinent data.</p><p>We also learned more about the importance of data locality and how important
simply getting data to the CPU is.  CPU caches can be quite complicated and
often times it is best to allow the various mechanisms designed to optimize them
take care of the issue.  However, understanding what is happening and doing all
that is possible to optimize how memory is taken care of can make all the
difference.  For example, by understanding how caches work we are able to
understand that the decrease in performance that leads to a saturated speedup no
matter the grid size in <a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_figure_all_perf">Figure&nbsp;6-4</a> can probably be attributed to
the L3 cache being filled up by our grid.  This means that we start not
benefiting from the tiered memory approach to solving the Von Neumann
bottleneck.</p><p>Another important lesson is the use of external libraries.  Python is fantastic
for its fast development, ease of use and readability which allows you to write
and debug code faster, but to tune performance down to the CPU external
libraries are essential.  These external libraries can be extremely fast,
because they can be written in lower level languages, but still since they
interface with python you can also still write code fast.</p><p>Finally, we learned the importance of benchmarking everything and forming
hypothesis about performance before running the experiment.  By forming a
hypothesis before running the benchmark we are able to form conditions to tell
us whether our optimization actually worked.  Was this change able to speedup
runtime?  Did it reduce the number of allocations?  Are the number of cache
misses lower?  Optimizations can be an art at times because of the vast
complexity of computer systems so having a quantitative probe into what is
actually happening can help enormously.</p><p>Lastly, we realize how much of an art this sort of optimization can be.  As a
result, a lot of care must be taken care of to make sure that the optimizations
generalize to different computers (the assumptions and benchmarks you do may be
dependant on the architecture of the computer you are running on, how the
modules you are using were compiled, etc).  In addition, when making these
optimizations it is incredibly important to consider other developers and how
the changes will effect the readability of your code.  For example, in
<a class="xref" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory2">Example&nbsp;6-17</a> we realized that it would take a potentially vague
solution so care was taken to make sure that the code was fully documented and
tested to not only help us, but also help other people in the team.</p><div class="table"><a id="matrix_table_all_perf"></a><div class="table-title">Table&nbsp;6-1.&nbsp;Performance of all schemes for various dataset sizes</div><div class="table-contents"><table style="width: 40%; border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col class="col_1"><col class="col_2"><col class="col_3"><col class="col_4"><col class="col_5"><col class="col_6"><col class="col_7"><col class="col_8"><col class="col_9"><col class="col_10"><col class="col_11"><col class="col_12"></colgroup><thead><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "> Method                                                </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " colspan="2">256x256          </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " colspan="2"> 512x512         </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " colspan="2"> 1024x1024       </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " colspan="2"> 2048x2048       </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " colspan="2"> 4096x4096         </td><td style="border-bottom: 0.5pt solid ; ">&nbsp;</td></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>runtime</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>speedup</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>runtime</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>speedup</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>runtime</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>speedup</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>runtime</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>speedup</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>runtime</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>speedup</p></td><td style="border-bottom: 0.5pt solid ; "><p></p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><a class="link" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_run">python</a></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>2.32s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.00x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>9.49s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.00x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>39.00s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.00x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>155.02s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.00x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>617.35s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.00x</p></td><td style="border-bottom: 0.5pt solid ; "><p></p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><a class="link" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_pure_python_memory">python+memory</a></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>2.56s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.90x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>10.26s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.93x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>40.87s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.95x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>162.88s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.95x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>650.26s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.95x</p></td><td style="border-bottom: 0.5pt solid ; "><p></p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><a class="link" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_naive">numpy</a></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.07s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>32.33x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.28s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>33.56x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>1.61s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>24.25x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>11.28s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>13.74x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>45.47s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>13.58x</p></td><td style="border-bottom: 0.5pt solid ; "><p></p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><a class="link" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory1">numpy+memory</a></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.05s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>42.63x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.22s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>42.75x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>1.05s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>37.13x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>6.95s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>22.30x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>28.14s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>21.94x</p></td><td style="border-bottom: 0.5pt solid ; "><p></p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><a class="link" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_memory2">numpy+memory+laplace</a></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.03s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>77.98x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.12s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>78.91x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.53s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>73.90x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>2.68s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>57.90x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>10.57s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>58.43x</p></td><td style="border-bottom: 0.5pt solid ; "><p></p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><a class="link" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_numexpr">numpy+memory+laplace+numexpr</a></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.04s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>65.01x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.13s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>74.27x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>0.50s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>78.27x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>2.42s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>64.18x</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>9.54s</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>64.75x</p></td><td style="border-bottom: 0.5pt solid ; "><p></p></td></tr><tr><td style="border-right: 0.5pt solid ; "><p><a class="link" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_scipy">numpy+memory+scipy</a></p></td><td style="border-right: 0.5pt solid ; "><p>0.05s</p></td><td style="border-right: 0.5pt solid ; "><p>42.43x</p></td><td style="border-right: 0.5pt solid ; "><p>0.19s</p></td><td style="border-right: 0.5pt solid ; "><p>51.28x</p></td><td style="border-right: 0.5pt solid ; "><p>1.22s</p></td><td style="border-right: 0.5pt solid ; "><p>32.09x</p></td><td style="border-right: 0.5pt solid ; "><p>6.06s</p></td><td style="border-right: 0.5pt solid ; "><p>25.58x</p></td><td style="border-right: 0.5pt solid ; "><p>30.31s</p></td><td style="border-right: 0.5pt solid ; "><p>20.37x</p></td><td><p></p></td></tr></tbody></table></div></div><p>In the next chapter we will talk about how to create your
own external modules that can be finely tuned to solve specific problems with
much greater efficiencies.  This allows us to follow the rapid prototyping
method of making our programs—first solve the problem with slow code,
identify the elements which are slow, find ways to make those elements faster.
By profiling often and only trying to optimize sections of code we <span class="emphasis"><em>know</em></span> are
slow, we can save ourselves time while still making our programs run as fast as
possible.</p></div><div class="footnotes" epub:type="footnotes"><br><hr style="width: 100; align: left;"><div class="footnote" epub:type="footnote" id="ftn.matrix_numpy_novec"><p><sup>[<a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_numpy_novec" class="simpara">14</a>] </sup>This is done by compiling numpy with the <code class="literal">-O0</code> flag.  For this experiment we built numpy 1.8.0 with: <code class="literal">$ OPT='-O0' FOPT='-O0'
BLAS=None LAPACK=None ATLAS=None python setup.py build</code></p></div><div class="footnote" epub:type="footnote" id="ftn.matrix_cpu_warning"><p><sup>[<a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#matrix_cpu_warning" class="simpara">15</a>] </sup>This is very contingent on what CPU is being used.</p></div><div class="footnote" epub:type="footnote" id="ftn.id609491"><p><sup>[<a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#id609491" class="simpara">16</a>] </sup>This is not strictly true since two numpy
arrays can reference the same section of memory but use different striding
information in order to represent the same data in different ways.  These two
numpy arrays will have different id’s.  There are many subtleties to the id
structure of numpy arrays which are out of scope of this discussion.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-0" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#">Copy</a></li>
		
		<li class="add-highlight"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#">Add Highlight</a></li>
		<li class="add-note"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#">
			
				Add Note
			
		</a></li>
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="/library/view/high-performance-python/9781449361747/ch05.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">5. Iterators and Generators</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="/library/view/high-performance-python/9781449361747/ch07.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">7. Compiling to C</div>
        </a>
    
  
  </div>


      
    </section>
    <div class="reading-controls-bottom">
      <ul class="interface-controls js-bitlist">
        <li class="queue-control">
            <button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781449361747/chapter/ch06.html" data-for-analytics="9781449361747:ch06.html">
      <span>Add to Queue</span>
  </button>
        </li>
      </ul>
    </div>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  





    
    



        
      </div>
      



  <footer class="pagefoot t-pagefoot">
    <a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" class="icon-up"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li><a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a></li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li><a href="https://www.safaribooksonline.com/blog/">Blog</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://community.safaribooksonline.com/">Feedback</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2016 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>

<div class="font-flyout"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="https://www.safaribooksonline.com//library/view/high-performance-python/9781449361747/ch06.html#">Reset</a>
</div>
</div>


    

    
    
  

<div class="annotator-notice"></div></body><span class="gr__tooltip"><span class="gr__tooltip-content"></span><i class="gr__tooltip-logo"></i><span class="gr__triangle"></span></span></html>